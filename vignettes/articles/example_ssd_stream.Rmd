---
title: 'Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment'
author: "Javier Sanchez Alvarez"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float: true
    embed-resources: true
    self-contained-math: true
vignette: >
  %\VignetteIndexEntry{example_ssd_stream}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE
)
```

# Introduction
This document runs a discrete event simulation model in the context of a late oncology model to show how the random stream functions can be used to generate a model using random numbers in quick steps.

## Main options

```{r setup}
library(WARDEN)

library(dplyr)
library(ggplot2)
library(kableExtra)
library(purrr)

```

```{r main_opt, results='hide', message=FALSE}
options(scipen = 999)
options(digits=3)
options(tibble.print_max = 50)
```

# General inputs with delayed execution

We generate random stream of numbers using the `random_stream()` function, which generates a stream of (in this case) 100 random numbers to be used for specific objects, so as to ensure clarity and to make sure each object follows its own random stream of numbers. 


```{r input_delayed}
#We don't need to use sensitivity_inputs here, so we don't add that object

#Put objects here that do not change on any patient or intervention loop
common_all_inputs <-add_item(
                      util.sick = 0.8,
                      util.sicker = 0.5,
                      cost.sick = 3000,
                      cost.sicker = 7000,
                      cost.int = 1000,
                      coef_noint = log(0.2),
                      HR_int = 0.8,
                      drc = 0.035, #different values than what's assumed by default
                      drq = 0.035) #different values than what's assumed by default


#Put objects here that do not change as we loop through treatments for a patient
common_pt_inputs <- add_item(input = {
  rnd_stream_a <- random_stream(100) #arbitrary amount of random numbers to be used, should be >= max number of calls that use that random number (e.g., if item/event A requires 5 random numbers due to repeated calls, then at least 5 numbers should be generated )
  rnd_stream_b <- random_stream(100)
  common_luck <- runif(1)
  fl.sick  <- 1
  q_default  <- util.sick
  })

#Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s)
unique_pt_inputs <- add_item(c_default = cost.sick + if(arm=="int"){cost.int}else{0}) 

```

# Events
## Add Initial Events
We pull a value from the random stream using `draw_n()` function from the random stream object `rnd_stream_a` in a similar way to what we would do with R6 objects. This will automatically pull a value and remove it from the pending list of random numbers, so the next time we call that function it will provide a new number, saving a few lines of code in which we would need to assign the value (e.g., `rnd_used_a <- vector_of_random_values[1]; vector_of_random_values <- vector_of_random_values[-1]`) reducing the risk of human mistakes + making the code clearer.

```{r model_evts}
init_event_list <- 
  add_tte(arm=c("noint","int"), evts = c("sick","sicker","death") ,input={ 
    sick <- 0
    sicker <- qexp(rnd_stream_a$draw_n(),exp(coef_noint + ifelse(arm=="int",log(HR_int),0))) #use draw_n to automatically use the random number and update it in rnd_stream_a
    death <-  max(0.0000001,qnorm(rnd_stream_b$draw_n(), mean=12, sd=3))
  })

```

## Add Reaction to Those Events
We use in this case a luck adjustment as we update the death time to event using the `luck_adj()` function. The parameters go from mean 12 to 10, and sd from 3 to 2, so we update the currently used random number (obtained through `random_n` and then we redraw the time to event. 

```{r model_reaction}
evt_react_list <-
  add_reactevt(name_evt = "sick",
               input = {}) %>%
  add_reactevt(name_evt = "sicker",
               input = {
                 q_default <- util.sicker
                 c_default <- cost.sicker + if(arm=="int"){cost.int}else{0}
                 fl.sick <- 0 
                 
                 #We perform a luck adjustment randomly but being slightly more likely in the "noint" arm
                 if((common_luck + ifelse(arm=="noint", 0.1,0) ) >0.7){
                    rnd_stream_b$random_n <- luck_adj(prevsurv = 1 - pnorm(q=curtime,12,3),
                                                      cursurv = 1 - pnorm(q=curtime,8,2),
                                                      luck = rnd_stream_b$random_n,
                                                      condq = FALSE)
                    modify_event(c(
                      death = max(curtime,qnorm(rnd_stream_b$random_n, mean=8, sd=2))
                    ))
                    }
                 
                 
               }) %>%
  add_reactevt(name_evt = "death",
               input = {
                 q_default <- 0
                 c_default <- 0
                 curtime <- Inf
               }) 

```

# Costs and Utilities
Costs and utilities are introduced below. However, it's worth noting that the model is able to run without costs or utilities.

Utilities/Costs/Other outputs are defined by declaring which object belongs to utilities/costs/other outputs, and whether they need to be discounted continuously or discretely (instantaneous). These will be passed to the `run_sim()` function.

## Utilities

```{r utilities}

util_ongoing <- "q_default"

```
## Costs

```{r costs}

cost_ongoing <- "c_default"

```

# Model
## Model Execution

```{r model_run}
#Logic is: per patient, per intervention, per event, react to that event.
results <- run_sim(  
  npats=1000,                               # number of patients to be simulated
  n_sim=1,                                  # number of simulations to run
  psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)  
  arm_list = c("int", "noint"),             # intervention list
  common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation
  common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention
  unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions
  init_event_list = init_event_list,        # initial event list
  evt_react_list = evt_react_list,          # reaction of events
  util_ongoing_list = util_ongoing,
  cost_ongoing_list = cost_ongoing,
  ipd = 1
)
```
# Post-processing of Model Outputs
## Summary of Results


```{r post-processing_summary}


summary_results_det(results[[1]][[1]]) #print first simulation

summary_results_sim(results[[1]])

summary_results_sens(results)

psa_ipd <- bind_rows(map(results[[1]], "merged_df")) 

psa_ipd[1:10,] %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))


```

We can check what has been the absolute number of events per strategy.

```{r post-processing_analysis,echo=FALSE, message=FALSE}

psa_ipd %>% group_by(arm,evtname) %>% summarise(n=n()) %>% arrange(arm,-n)%>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

## Plots

We now use the data output to plot the histograms/densities of the simulation. 

```{r post-processing_plots1, fig.width=10, fig.height=8}

data_plot <- results[[1]][[1]]$merged_df %>%
  filter(evtname != "sick") %>%
  group_by(arm,evtname,simulation) %>%
  mutate(median = median(evttime)) %>%
  ungroup()

ggplot(data_plot) +
  geom_density(aes(fill = arm, x = evttime),
               alpha = 0.7) +
  geom_vline(aes(xintercept=median,col=arm)) +
  facet_wrap( ~ evtname, scales = "free") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0, 0)) +
  theme_bw()

```

We can also plot the patient level incremental QALY/costs.

```{r post-processing_plots, fig.width=10, fig.height=8, message=FALSE}

data_qaly_cost<- psa_ipd[,.SD[1],by=.(pat_id,arm,simulation)][,.(arm,qaly=total_qalys,cost=total_costs,pat_id,simulation)]
data_qaly_cost[,ps_id:=paste(pat_id,simulation,sep="_")]


mean_data_qaly_cost <- data_qaly_cost %>% group_by(arm) %>% summarise(across(where(is.numeric),mean))

ggplot(data_qaly_cost,aes(x=qaly, y = cost, col = arm)) + 
  geom_point(alpha=0.15,shape = 21) +
  geom_point(data=mean_data_qaly_cost, aes(x=qaly, y = cost, fill = arm), shape = 21,col="black",size=3) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0, 0)) +
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = .5))

```

# Sensitivity Analysis
## Inputs

We leave `common_pt_inputs` untouched, as those should not change per sensitivity analysis to ensure results are fully comparable across simulations and analyses.

```{r dsa_inputs}
#Load some data
df_par <- list(parameter_name = c("util.sick","util.sicker","cost.sick","cost.sicker","cost.int","coef_noint","HR_int"),
                              base_value = c(0.8,0.5,3000,7000,1000,log(0.2),0.8),
                              DSA_min = c(0.6,0.3,1000,5000,800,log(0.1),0.5),
                              DSA_max = c(0.9,0.7,5000,9000,2000,log(0.4),0.9),
                              PSA_dist = c("rnorm","rbeta_mse","rgamma_mse","rgamma_mse","rgamma_mse","rnorm","rlnorm"),
                              a = list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)),
                              b = lapply(list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)), function(x) abs(x/10)),
                              scenario_1=c(0.6,0.3,1000,5000,800,log(0.1),0.5),
                              scenario_2=c(0.9,0.7,5000,9000,2000,log(0.4),0.9)
                              )

sensitivity_inputs <-add_item(
            pos_indicator = sens - n_sensitivity*floor((sens-1)/n_sensitivity), # which position to use to put the value 1 in indicator
            indicators = append(rep(0, length(df_par$parameter_name))[-pos_indicator],1,pos_indicator-1) #vector of indicators, value 0 everywhere except at sens, where it takes value 1
                              )

common_all_inputs <-add_item(
            pick_val_v(base        = df_par[["base_value"]],
                       psa         = pick_psa(df_par[["PSA_dist"]],rep(1,length(df_par[["PSA_dist"]])),df_par[["a"]],df_par[["b"]]),
                       sens        = df_par[[sens_name_used]],
                       psa_ind     = psa_bool,
                       sens_ind    = sensitivity_bool,
                       indicator   = indicators,
                       names_out   = df_par[["parameter_name"]]
                       )
            )

```
## Model Execution

```{r run_dsa}
results <- run_sim(  
  npats=100,                               # number of patients to be simulated
  n_sim=1,                                  # number of simulations to run
  psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)  
  arm_list = c("int", "noint"),             # intervention list
  common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation
  common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention
  unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions
  init_event_list = init_event_list,        # initial event list
  evt_react_list = evt_react_list,          # reaction of events
  util_ongoing_list = util_ongoing,
  cost_ongoing_list = cost_ongoing,
  sensitivity_inputs = sensitivity_inputs,
  sensitivity_names = c("DSA_min","DSA_max"),
  sensitivity_bool = TRUE,
  n_sensitivity = length(df_par$parameter_name),
  input_out = c(df_par[["parameter_name"]])
)

```

## Check results
We briefly check below that indeed the engine has been changing the corresponding parameter value.
```{r dsa_check}

data_sensitivity <- bind_rows(map_depth(results,2, "merged_df"))

#Check mean value across iterations as PSA is off
data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c("util.sick","util.sicker","cost.sick","cost.sicker","cost.int","coef_noint","HR_int"),mean)

```

## Model Execution, probabilistic DSA
The model is executed as before, just activating the psa_bool option

```{r run_dsa_psa}
results <- run_sim(  
  npats=100,                               
  n_sim=6,                                  
  psa_bool = TRUE,                         
  arm_list = c("int", "noint"),             
  common_all_inputs = common_all_inputs,    
  common_pt_inputs = common_pt_inputs,      
  unique_pt_inputs = unique_pt_inputs,      
  init_event_list = init_event_list,        
  evt_react_list = evt_react_list,          
  util_ongoing_list = util_ongoing,
  cost_ongoing_list = cost_ongoing,
  sensitivity_inputs = sensitivity_inputs,
  sensitivity_names = c("DSA_min","DSA_max"),
  sensitivity_bool = TRUE,
  n_sensitivity = length(df_par$parameter_name),
  input_out = c(df_par[["parameter_name"]])
)

```


## Check results
We briefly check below that indeed the engine has been changing the corresponding parameter value.
```{r dsa_check_psa}

data_sensitivity <- bind_rows(map_depth(results,2, "merged_df"))

#Check mean value across iterations as PSA is off
data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c("util.sick","util.sicker","cost.sick","cost.sicker","cost.int","coef_noint","HR_int"),mean)

```
