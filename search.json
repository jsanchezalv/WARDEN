[{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"document makes use code provided Degeling et al. (2025) use simmer original approach, showcase model written WARDEN instead using simmer, reflecting advantages disadvantages approach. Note model used resource constrained, implies WARDEN can used replicate model. see alternative approach taken model design simplify code reduce number events defined. document made modifications ensure random numbers used cloned patient across arms, way able reduce number simulations needed achieve convergence.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"","code":"library(WARDEN) library(flexsurv) #> Loading required package: survival library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows library(purrr) library(tidyr)  rllogiscure <- function(n = 1, cure, shape, scale) ifelse(runif(n) < cure, Inf, flexsurv::rllogis(n = n, shape = shape, scale = scale))  qllogiscure <- function(q1=0.5,q2=0.5, cure, shape, scale) ifelse(q1 < cure, Inf, flexsurv::qllogis(q2, shape = shape, scale = scale))  #Load the data directly  df_survival_models <- data.frame(   d_RF_R_1_low_dist = \"llogis cure\",   d_RF_R_1_low_cure = 0.488186991523229,   d_RF_R_1_low_shape = 1.77977114896326,   d_RF_R_1_low_scale = 1.38283630454774,   d_RF_R_1_high_dist = \"llogis cure\",   d_RF_R_1_high_cure = 0.214810267441731,   d_RF_R_1_high_shape = 1.77977114896326,   d_RF_R_1_high_scale = 0.789492793640768,   d_RF_R_2_low_dist = \"llogis cure\",   d_RF_R_2_low_cure = 0.65641085001312,   d_RF_R_2_low_shape = 1.77977114896326,   d_RF_R_2_low_scale = 1.58521155099032,   d_RF_R_2_high_dist = \"llogis cure\",   d_RF_R_2_high_cure = 0.353984786085761,   d_RF_R_2_high_shape = 1.77977114896326,   d_RF_R_2_high_scale = 0.905033438728147,   d_RF_D_dist = \"gompertz\",   d_RF_D_shape = 0.100559042221505,   d_RF_D_rate = 0.00665743407339234,   d_R_D_1_dist = \"llogis\",   d_R_D_1_shape = 1.485045044099,   d_R_D_1_scale = 1.00935168932233,   d_R_D_2_dist = \"llogis\",   d_R_D_2_shape = 1.44829250447263,   d_R_D_2_scale = 0.810984232666931 )  fit_RF_R <- list()  fit_RF_R$coefficients <- c(theta = -0.0472608287028634, shape = 0.576484788040251, scale = 0.324136683094238,  `rxLev+5FU` = 0.694601105199585, node4 = -1.24890939590147, `scale(rxLev+5FU)` = 0.136581185984944,  `scale(node4)` = -0.560501256173105)  fit_RF_R$cov <- structure(c(0.0196583147504792, 0.00156218752250396, -0.00257474768797604,  -0.016302156542927, -0.0100195566305646, 0.00134971798565362,  0.00170701620954217, 0.00156218752250396, 0.00365083117648361,  -0.00128500487043069, -0.000244113496363589, 2.02965101911069e-05,  -0.000143663350415706, 0.000680998903126475, -0.00257474768797604,  -0.00128500487043069, 0.0092867442776243, 0.00151695259640943,  0.00133526552969664, -0.00625680296067579, -0.00661478811857714,  -0.016302156542927, -0.000244113496363589, 0.00151695259640943,  0.0338463064763289, -0.0025154671522777, -0.00322763710020272,  -9.12647224737586e-05, -0.0100195566305646, 2.02965101911069e-05,  0.00133526552969664, -0.0025154671522777, 0.0454732545912484,  0.00012107663391756, -0.00307943086438432, 0.00134971798565362,  -0.000143663350415706, -0.00625680296067579, -0.00322763710020272,  0.00012107663391756, 0.0148872736561986, 0.000478467611046574,  0.00170701620954217, 0.000680998903126475, -0.00661478811857714,  -9.12647224737586e-05, -0.00307943086438432, 0.000478467611046574,  0.0149353581264385), dim = c(7L, 7L), dimnames = list(c(\"theta\",  \"shape\", \"scale\", \"rxLev+5FU\", \"node4\", \"scale(rxLev+5FU)\", \"scale(node4)\" ), c(\"theta\", \"shape\", \"scale\", \"rxLev+5FU\", \"node4\", \"scale(rxLev+5FU)\",  \"scale(node4)\")))  fit_R_D <- list()  fit_R_D$coefficients <-c(shape = 0.395445104521237, scale = 0.00930823299238263, `rxLev+5FU` = -0.218814899889124,  `shape(rxLev+5FU)` = -0.0250598251068813)  fit_R_D$cov <- structure(c(0.00464605840970939, -0.000117142438483793, 0.000117142438483891,  -0.00464605840970939, -0.000117142438483793, 0.00796369089713632,  -0.00796369089713637, 0.000117142438483782, 0.000117142438483891,  -0.00796369089713637, 0.0198528324519912, 0.000147891836828856,  -0.00464605840970939, 0.000117142438483782, 0.000147891836828856,  0.0112399289334457), dim = c(4L, 4L), dimnames = list(c(\"shape\",  \"scale\", \"rxLev+5FU\", \"shape(rxLev+5FU)\"), c(\"shape\", \"scale\",  \"rxLev+5FU\", \"shape(rxLev+5FU)\"))) options(scipen = 999) options(digits=3) options(tibble.print_max = 50)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"one-to-one-conversion","dir":"Articles","previous_headings":"","what":"“One to one conversion”","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"first way create model copying approach taken original paper. reformulate structure get outcomes simplifying model structure thanks WARDEN per cycle outcome recording.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"inputs","dir":"Articles","previous_headings":"“One to one conversion”","what":"Inputs","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"model, need load inputs, set initial TTE, event reactions, utilities/costs, etc. ’ll first replicate deterministic analysis, redo inputs use probabilistic analysis, showcasing well pick_val_v function can used everything done . Thanks new add_item2, loading inputs fundamentally .","code":"common_all_inputs <-add_item2(input = {                       drc         <- 0.04                        drq         <- 0.015                       p_highrisk  <- 0.6                       d_BS_shape <- df_survival_models$d_RF_D_shape                       d_BS_rate  <- df_survival_models$d_RF_D_rate                       d_TTR_cure_1_low  <- df_survival_models$d_RF_R_1_low_cure                                              d_TTR_cure_1_high <- df_survival_models$d_RF_R_1_high_cure                       d_TTR_cure_2_low  <- df_survival_models$d_RF_R_2_low_cure                       d_TTR_cure_2_high <- df_survival_models$d_RF_R_2_high_cure                                              d_TTR_shape_1_low  <- df_survival_models$d_RF_R_1_low_shape                       d_TTR_shape_1_high <- df_survival_models$d_RF_R_1_high_shape                       d_TTR_shape_2_low  <- df_survival_models$d_RF_R_2_low_shape                       d_TTR_shape_2_high <- df_survival_models$d_RF_R_2_high_shape                                              d_TTR_scale_1_low  <- df_survival_models$d_RF_R_1_low_scale                       d_TTR_scale_1_high <- df_survival_models$d_RF_R_1_high_scale                       d_TTR_scale_2_low  <- df_survival_models$d_RF_R_2_low_scale                       d_TTR_scale_2_high <- df_survival_models$d_RF_R_2_high_scale                                              # Adjuvant treatment costs                       c_adjuvant_cycle_1 <- 5000                       c_adjuvant_cycle_2 <- 15000                                              # Utility during adjuvant treatment                       u_adjuvant <- 0.70                                              # Other adjuvant treatment parameters                       t_adjuvant_cycle      <- 3/52 # in years                       n_max_adjuvant_cycles <- 10                                              # Probability of toxicities during a cycle                       # - conditional on treatment arm                       p_tox_1 <- 0.20                       p_tox_2 <- 0.40                                              # Costs of toxicities                       c_tox <- 2000                                              # Disutility of toxicities                       u_dis_tox <- 0.10                                                                     ## DISEASE MONITORING                                              # Cost of a monitoring cycle                       c_monitor <- 1000                                              # Utility while free of recurrence                       u_diseasefree <- 0.80                                              # Other disease monitoring parameters                       t_monitor_cycle      <- 1 # in years                       n_max_monitor_cycles <- 5                                                                     ## RECURRENCE OF DISEASE                                              # Log-logistic distribution for the time-to-death due to cancer after recurrence                    (TTD)                       # - conditional on treatment arm                       d_TTD_shape_1 <- df_survival_models$d_R_D_1_shape                       d_TTD_shape_2 <- df_survival_models$d_R_D_2_shape                                              d_TTD_scale_1 <- df_survival_models$d_R_D_1_scale                       d_TTD_scale_2 <- df_survival_models$d_R_D_2_scale                                              # Cost of treatment for advanced disease                       c_advanced <- 40000                                              # Utility during advanced disease                       u_advanced <- 0.60                        })     #Put objects here that do not change as we loop through treatments for a patient #We preload the random numbers to clone them across arms for a given patient common_pt_inputs <- add_item2(input={     HighRisk <- as.integer(runif(1) < p_highrisk)        random_adv <- runif(1)     random_tox <- runif(10) #max of 10 instances     random_cure1 <- runif(1)     random_cure2 <- runif(1) })   unique_pt_inputs <- add_item2(input = {     AdjuvantCycles <- 0     MonitorCycles <- 0     Toxicities <- 0     n_tox <- 0     q_total <- u_adjuvant     p_toxicity <- if(arm == \"one\") {p_tox_1} else {p_tox_2}     c_adjuvant_cycle <- if(arm == \"one\") {c_adjuvant_cycle_1} else {c_adjuvant_cycle_2}  })"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"add-initial-events","dir":"Articles","previous_headings":"“One to one conversion” > Events","what":"Add Initial Events","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"initialize event times original code. interested replicating final results, focus key events interactions. relabeled “TTR” “advanced”.","code":"init_event_list <-    add_tte(arm=c(\"one\",\"two\"), evts = c(\"trt_cycle\",\"monitor_cycle\",\"advanced\",\"death\") , other_inp =\"fl_adv\",input={     trt_cycle <- 0     monitor_cycle <- t_monitor_cycle   # Sampling BS, we don't need to use the random number as the seed is reset before this chunk is executed automatically   death <- rgompertz(n = 1, shape = d_BS_shape, rate = d_BS_rate)      # Sampling TTR conditional on arm and HighRisk   if(arm == \"one\" & HighRisk == 0) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_1_low,                              shape  = d_TTR_shape_1_low,                              scale  = d_TTR_scale_1_low)   } else if(arm == \"one\" & HighRisk == 1) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_1_high,                              shape  = d_TTR_shape_1_high,                              scale  = d_TTR_scale_1_high)   } else if(arm == \"two\" & HighRisk == 0) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_2_low,                              shape  = d_TTR_shape_2_low,                              scale  = d_TTR_scale_2_low)   } else if(arm == \"two\" & HighRisk == 1) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_2_high,                              shape  = d_TTR_shape_2_high,                              scale  = d_TTR_scale_2_high)   } else {      stop(\"This should not happen in selecting the advanced distribution!\");   }           })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"“One to one conversion” > Events","what":"Add Reaction to Those Events","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"’s interesting note paper mention Toxicities accumulate (true “global” level), local value Toxicities ’s executing adjustment QALYs Costs stays 0 1 (.e., toxicity disutility lasts treatment cycle). sake replication, keep interpretation .","code":"evt_react_list <-   add_reactevt(name_evt = \"trt_cycle\",                input = {                    AdjuvantCycles <- AdjuvantCycles + 1                                        Toxicities <- if(random_tox[AdjuvantCycles] < p_toxicity){1} else{0}                    n_tox <- n_tox + Toxicities                                                            cost_adj <- c_adjuvant_cycle + Toxicities*c_tox                    q_total <- u_adjuvant - Toxicities*u_dis_tox                       #we create new treatment cycle if possible, if not we call monitoring at end of cycle                    if(AdjuvantCycles<n_max_adjuvant_cycles){                      new_event(list(trt_cycle = t_adjuvant_cycle + curtime))                    } else{                      modify_event(list(monitor_cycle = t_adjuvant_cycle + curtime))                    }                                    }) %>%   add_reactevt(name_evt = \"monitor_cycle\",                input = {                  MonitorCycles <- MonitorCycles + 1                  cost_monitor <- c_monitor                  q_total <- u_diseasefree                                    if(MonitorCycles<n_max_monitor_cycles){                   new_event(list(monitor_cycle = curtime + t_monitor_cycle))                  }                }) %>%   add_reactevt(name_evt = \"advanced\",                input = {                  modify_event(list(trt_cycle = Inf, monitor_cycle = Inf)) #remove the trt_cycle and monitor_cycle event                                    # Sample TTD based on arm                 if(arm == \"one\") {                   TTD <- qllogis(random_adv,                                  shape = d_TTD_shape_1,                                  scale = d_TTD_scale_1)                 } else if(arm == \"two\") {                   TTD <- qllogis(random_adv,                                  shape = d_TTD_shape_2,                                  scale = d_TTD_scale_2)                 } else {                    stop(\"This should not happen in selecting the TTD distribution!\");                 }                 final_TTD <- TTD+curtime                 # Check whether TTD is lower than BS, if not correct to BS.                  if(cur_evtlist[[\"death\"]] > final_TTD){                    modify_event(list(death = final_TTD))                   }                 q_total <- u_advanced                 cost_advanced <- c_advanced                                  })%>%   add_reactevt(name_evt = \"death\",                input = {                  curtime   <- Inf #exits simulation, no need to remove other evts                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"“One to one conversion”","what":"Costs and Utilities","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"","code":"util_ongoing <- \"q_total\"  cost_instant <- c(\"cost_adj\",\"cost_monitor\",\"cost_advanced\")"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"model-execution","dir":"Articles","previous_headings":"“One to one conversion” > Model","what":"Model Execution","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"sake reducing running times vignette, pre-run results, leave small run showcase results.","code":"results <- run_sim(     npats=5000,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"one\", \"two\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_instant_list = cost_instant,   ipd = 2 ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 11.42s #> Time to run analysis 1: 11.42s #> Total time to run: 11.42s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"summary-of-example-results","dir":"Articles","previous_headings":"“One to one conversion” > Post-processing of Model Outputs","what":"Summary of Example Results","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"","code":"summary_results_det(results[[1]][[1]], arm =\"two\") #print first simulation #>                            one       two #> costs                 77004.39 170643.81 #> dcosts                93639.42      0.00 #> lys                       8.41     10.74 #> dlys                      2.33      0.00 #> qalys                     6.41      8.35 #> dqalys                    1.94      0.00 #> ICER                  40207.55        NA #> ICUR                  48287.58        NA #> INMB                   3320.73        NA #> costs_undisc          79161.60 173625.80 #> dcosts_undisc         94464.20      0.00 #> lys_undisc                9.86     12.78 #> dlys_undisc               2.92      0.00 #> qalys_undisc              7.56      9.97 #> dqalys_undisc             2.42      0.00 #> ICER_undisc           32354.46        NA #> ICUR_undisc           39051.82        NA #> INMB_undisc           26483.04        NA #> cost_adj              49310.73 148203.86 #> dcost_adj             98893.13      0.00 #> cost_adj_undisc       49792.60 149675.00 #> dcost_adj_undisc      99882.40      0.00 #> cost_advanced         25461.82  19651.38 #> dcost_advanced        -5810.44      0.00 #> cost_advanced_undisc  26944.00  20904.00 #> dcost_advanced_undisc -6040.00      0.00 #> cost_monitor           2231.84   2788.57 #> dcost_monitor           556.73      0.00 #> cost_monitor_undisc    2425.00   3046.80 #> dcost_monitor_undisc    621.80      0.00 #> q_total                   6.41      8.35 #> dq_total                  1.94      0.00 #> q_total_undisc            7.56      9.97 #> dq_total_undisc           2.42      0.00  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))   psa_ipd[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"rethinking-the-approach","dir":"Articles","previous_headings":"","what":"Rethinking the Approach","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"can rethink bit general approach. Thanks WARDEN per cycle discounting, treatment cycles monitoring events replaced simpler approach similar outcomes. suggested approach already mentioned original paper. , just declare inputs characteristics cycles (.e., cycle length maximum amount cycles), keep events needed (just need start event monitoring starting event, need keep cycles). toxicities, just calculate many toxicities patient , use proportion calculate average cost apply cycles. simplifies modelling, number events, increases running speed (roughly twice fast) providing model structure.","code":"unique_pt_inputs2 <- add_item2(input = {     n_tox <- 0     q_total <- u_adjuvant     p_toxicity <- if(arm == \"one\") {p_tox_1} else {p_tox_2}     #this is for the rethinking approach     cost_tox <- 0     cost_monitor <- 0     cost_adj <- 0          cost_tox_cycle_l <- t_adjuvant_cycle     cost_tox_cycle_starttime <- 0     cost_tox_max_cycles <- n_max_adjuvant_cycles          cost_adj_cycle_l <- t_adjuvant_cycle     cost_adj_cycle_starttime <- 0     cost_adj_max_cycles <- n_max_adjuvant_cycles          cost_monitor_cycle_l <- t_monitor_cycle     cost_monitor_cycle_starttime <- t_monitor_cycle     cost_monitor_max_cycles <- n_max_monitor_cycles          c_adjuvant_cycle <- if(arm == \"one\") {c_adjuvant_cycle_1} else {c_adjuvant_cycle_2}  })   init_event_list <-    add_tte(arm=c(\"one\",\"two\"), evts = c(\"start\",\"monitoring\",\"advanced\",\"death\") ,input={     start <- 0        # Sampling BS   death <- rgompertz(n = 1, shape = d_BS_shape, rate = d_BS_rate)      # Sampling TTR conditional on arm and HighRisk   if(arm == \"one\" & HighRisk == 0) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_1_low,                              shape  = d_TTR_shape_1_low,                              scale  = d_TTR_scale_1_low)   } else if(arm == \"one\" & HighRisk == 1) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_1_high,                              shape  = d_TTR_shape_1_high,                              scale  = d_TTR_scale_1_high)   } else if(arm == \"two\" & HighRisk == 0) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_2_low,                              shape  = d_TTR_shape_2_low,                              scale  = d_TTR_scale_2_low)   } else if(arm == \"two\" & HighRisk == 1) {     advanced <- qllogiscure(q1 = random_cure1,                             q2 = random_cure2,                             cure   = d_TTR_cure_2_high,                              shape  = d_TTR_shape_2_high,                              scale  = d_TTR_scale_2_high)   } else {      stop(\"This should not happen in selecting the TTR distribution!\")   }      #we can already tell if monitoring event will occur or not   monitoring <- if(t_adjuvant_cycle*(n_max_adjuvant_cycles + 1) > min(death,advanced)){Inf}else{t_adjuvant_cycle*(n_max_adjuvant_cycles + 1)}   })    evt_react_list <-   add_reactevt(name_evt = \"start\",                input = {                   #how many toxic events will we have?                    n_cycles_tobedone <- min(10,min(cur_evtlist) %/% t_adjuvant_cycle)                    n_tox <- ifelse(n_cycles_tobedone ==0, 0,sum(random_tox[1:n_cycles_tobedone] < p_toxicity))                    #calculate the proportion out of maximum possible                    prop_tox <- n_tox/(n_cycles_tobedone)                    prop_tox <- if(is.na(prop_tox)){0}else{prop_tox}                                        cost_tox <- prop_tox*c_tox                    cost_adj <- c_adjuvant_cycle                     q_total <- u_adjuvant - prop_tox*u_dis_tox                                       }) %>%   add_reactevt(name_evt = \"monitoring\",                input = {                  cost_adj <- 0                  cost_tox <- 0                   cost_monitor <- c_monitor                  cost_monitor_cycle_starttime <- curtime                   q_total <- u_diseasefree                                  }) %>%   add_reactevt(name_evt = \"advanced\",                input = {                                    cost_adj <- 0                  cost_tox <- 0                  cost_monitor <- 0                   # Sample TTD based on arm                 if(arm == \"one\") {                   TTD <- flexsurv::qllogis(random_adv,                                  shape = d_TTD_shape_1,                                  scale = d_TTD_scale_1)                 } else if(arm == \"two\") {                   TTD <- flexsurv::qllogis(random_adv,                                  shape = d_TTD_shape_2,                                  scale = d_TTD_scale_2)                 } else {                    stop(\"This should not happen in selecting the TTD distribution!\")                 }                 final_TTD <- TTD+curtime                 # Check whether TTD is lower than BS, if not correct to BS.                  if(cur_evtlist[[\"death\"]] > final_TTD){                    modify_event(list(death = final_TTD))                   }                                    cost_advanced <- c_advanced                  q_total <- u_advanced                })%>%   add_reactevt(name_evt = \"death\",                input = {                  curtime <- Inf #exits simulation, no need to remove other evts                })   util_ongoing <- \"q_total\"  cost_instant <- c(\"cost_advanced\")  cost_cycle <- c(\"cost_tox\",\"cost_adj\",\"cost_monitor\")  results2 <- run_sim(     npats=5000,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"one\", \"two\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs2,   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_instant_list = cost_instant,   cost_cycle_list = cost_cycle,   ipd = 2,   input_out = c(\"n_tox\") ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 5.78s #> Time to run analysis 1: 5.78s #> Total time to run: 5.79s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_colon_degeling.html","id":"summary-of-results","dir":"Articles","previous_headings":"Rethinking the Approach","what":"Summary of Results","title":"Degeling et al. (2025) using WARDEN instead of simmer","text":"can check speed convergence. Note making sure random numbers “cloned” per patient across arms means convergence occurs faster original paper, can save computation time, ensures stability outcomes. plotted observations simulation run simmer 3 different seeds (display Monte Carlo error) WARDEN (original, reworked reworked two different seeds). ’s noticeable stability ICER achieved faster WARDEN, due use cloning random numbers, means ~30,000 simulations suffice achieve stability. differences simulations seem relatively large, reality cloning random numbers approach can seen ICER remains within 2% final value already 10,000 simulations. running times original WARDEN approach comparable simmer shown paper, even simmer uses C++ implementation back-end. using reworked approach, WARDEN able cut running time half. computer simmer took 220 300 seconds run 100,000 simulations. WARDEN, “one one” approach took around 200 seconds. reworked approach took 100 seconds. # Probabilistic Case now use thepick_val_v function. just showcase , run sake saving computation time.","code":"#>                                    one       two #> costs                         76883.17 170501.47 #> dcosts                        93618.31      0.00 #> lys                               8.41     10.74 #> dlys                              2.33      0.00 #> qalys                             6.41      8.35 #> dqalys                            1.94      0.00 #> ICER                          40198.49        NA #> ICUR                          48312.83        NA #> INMB                           3269.32        NA #> costs_undisc                  79128.05 173593.84 #> dcosts_undisc                 94465.79      0.00 #> lys_undisc                        9.86     12.78 #> dlys_undisc                       2.92      0.00 #> qalys_undisc                      7.55      9.97 #> dqalys_undisc                     2.42      0.00 #> ICER_undisc                   32355.01        NA #> ICUR_undisc                   39076.12        NA #> INMB_undisc                   26408.28        NA #> cost_adj                      45641.06 140680.89 #> dcost_adj                     95039.83      0.00 #> cost_adj_cycle_l                  0.20      0.19 #> dcost_adj_cycle_l                 0.00      0.00 #> cost_adj_cycle_starttime          0.00      0.00 #> dcost_adj_cycle_starttime         0.00      0.00 #> cost_adj_max_cycles              34.36     33.60 #> dcost_adj_max_cycles             -0.76      0.00 #> cost_adj_undisc               46087.00 142077.00 #> dcost_adj_undisc              95990.00      0.00 #> cost_advanced                 25461.82  19651.38 #> dcost_advanced                -5810.44      0.00 #> cost_advanced_undisc          26944.00  20904.00 #> dcost_advanced_undisc         -6040.00      0.00 #> cost_monitor                   2107.02   2648.68 #> dcost_monitor                   541.66      0.00 #> cost_monitor_cycle_l              3.44      3.36 #> dcost_monitor_cycle_l            -0.08      0.00 #> cost_monitor_cycle_starttime      2.72      2.62 #> dcost_monitor_cycle_starttime    -0.10      0.00 #> cost_monitor_max_cycles          17.18     16.80 #> dcost_monitor_max_cycles         -0.38      0.00 #> cost_monitor_undisc            2387.80   3017.60 #> dcost_monitor_undisc            629.80      0.00 #> cost_tox                       3673.27   7520.52 #> dcost_tox                      3847.25      0.00 #> cost_tox_cycle_l                  0.20      0.19 #> dcost_tox_cycle_l                 0.00      0.00 #> cost_tox_cycle_starttime          0.00      0.00 #> dcost_tox_cycle_starttime         0.00      0.00 #> cost_tox_max_cycles              34.36     33.60 #> dcost_tox_max_cycles             -0.76      0.00 #> cost_tox_undisc                3709.25   7595.24 #> dcost_tox_undisc               3885.99      0.00 #> n_tox                             1.81      3.74 #> dn_tox                            1.93      0.00 #> q_total                           6.41      8.35 #> dq_total                          1.94      0.00 #> q_total_undisc                    7.55      9.97 #> dq_total_undisc                   2.42      0.00 thetaToProb <- function(x) unname(exp(x) / (1 + exp(x)))  #Uncertainty is only assumed on TTR, utility, toxicities, TTD and certain costs  l_inputs<- list(parameter_name = list(\"m_TTR\",                                       \"u_adjuvant\",                                       \"p_tox_1\",                                        \"p_tox_2\",                                       \"c_tox\",                                       \"u_dis_tox\",                                       \"u_diseasefree\",                                       \"m_TTD\",                                       \"c_advanced\",                                       \"u_advanced\"),                  base_value = list(                    c(df_survival_models$d_RF_R_1_low_cure,                     df_survival_models$d_RF_R_1_high_cure,                     df_survival_models$d_RF_R_2_low_cure,                     df_survival_models$d_RF_R_2_high_cure,                     df_survival_models$d_RF_R_1_low_shape,                     df_survival_models$d_RF_R_1_high_shape,                     df_survival_models$d_RF_R_2_low_shape,                     df_survival_models$d_RF_R_2_high_shape,                     df_survival_models$d_RF_R_1_low_scale,                     df_survival_models$d_RF_R_1_high_scale,                     df_survival_models$d_RF_R_2_low_scale,                     df_survival_models$d_RF_R_2_high_scale),                     0.7,                     0.2,                     0.4,                     2000,                     0.1,                     0.8,                     c(df_survival_models$d_R_D_1_shape,                     df_survival_models$d_R_D_2_shape,                     df_survival_models$d_R_D_1_scale,                     df_survival_models$d_R_D_2_scale),                     40000,                     0.6),                  PSA_dist = list(\"mvrnorm\",                                  \"rlnorm\",                                  \"rbeta\",                                  \"rbeta\",                                  \"rgamma\",                                  \"rlnorm\",                                  \"rlnorm\",                                  \"mvrnorm\",                                  \"rgamma\",                                  \"rlnorm\"),                  a=list(fit_RF_R$coefficients,                         -0.35738872,                         0.1*500,                         0.2*500,10000,                         -2.30756026,                         -0.2237682,                         fit_R_D$coefficients,                         200000,                         -0.51165826),                  b=list(fit_RF_R$cov,                         0.03778296,                         (1-0.1)*500,                         (1-0.2)*500,                         5,                         0.09975135,                         0.0353443,                         fit_R_D$cov,                         5,0.04080783),                  n=list(1,1,1,1,1,1,1,1,1,1),                  psa_indicators = list(1,1,1,1,1,1,1,1,1,1)                  )  common_all_inputs2 <-add_item2(input = {                         drc         <- 0.04                        drq         <- 0.015                       p_highrisk  <- 0.6                                              pick_val_v(                         base= l_inputs[[\"base_value\"]],                         psa = pick_psa(                             l_inputs[[\"PSA_dist\"]],                             l_inputs[[\"n\"]],                             l_inputs[[\"a\"]],                             l_inputs[[\"b\"]]),                         psa_ind     = psa_bool,                         sens_ind    = FALSE,                          names_out   = l_inputs[[\"parameter_name\"]],                         indicator   = rep(1,10),                          indicator_psa = l_inputs[[\"psa_indicators\"]],                         deploy_env = TRUE                       )                                                d_BS_shape <- df_survival_models$d_RF_D_shape                       d_BS_rate  <- df_survival_models$d_RF_D_rate                       d_TTR_cure_1_low  <- thetaToProb(m_TTR[\"theta\"])                       d_TTR_cure_1_high <- thetaToProb(m_TTR[\"theta\"]+ m_TTR[\"node4\"])                       d_TTR_cure_2_low  <- thetaToProb(m_TTR[\"theta\"]+ m_TTR[\"rxLev+5FU\"])                       d_TTR_cure_2_high <- thetaToProb(m_TTR[\"theta\"]+ m_TTR[\"rxLev+5FU\"] + m_TTR[\"node4\"])                       d_TTR_shape_1_low  <- exp(m_TTR[\"shape\"])                       d_TTR_shape_1_high <- exp(m_TTR[\"shape\"])                       d_TTR_shape_2_low  <- exp(m_TTR[\"shape\"])                       d_TTR_shape_2_high <- exp(m_TTR[\"shape\"])                       d_TTR_scale_1_low  <- exp(m_TTR[\"scale\"])                       d_TTR_scale_1_high <- exp(m_TTR[\"scale\"]+ m_TTR[\"scale(node4)\"])                       d_TTR_scale_2_low  <- exp(m_TTR[\"scale\"]+ m_TTR[\"scale(rxLev+5FU)\"])                       d_TTR_scale_2_high <- exp(m_TTR[\"scale\"]+ m_TTR[\"scale(rxLev+5FU)\"] + m_TTR[\"scale(node4)\"])                        # Adjuvant treatment costs                       c_adjuvant_cycle_1 <- 5000                       c_adjuvant_cycle_2 <- 15000                                              # Other adjuvant treatment parameters                       t_adjuvant_cycle      <- 3/52 # in years                       n_max_adjuvant_cycles <- 10                                                                    ## DISEASE MONITORING                                              # Cost of a monitoring cycle                       c_monitor <- 1000                                              # Other disease monitoring parameters                       t_monitor_cycle      <- 1 # in years                       n_max_monitor_cycles <- 5                                                                     ## RECURRENCE OF DISEASE                                              # Log-logistic distribution for the time-to-death due to cancer after recurrence                    (TTD)                       # - conditional on treatment arm                       d_TTD_shape_1 <- exp(m_TTD[\"shape\"])                       d_TTD_shape_2 <- exp(m_TTD[\"shape\"] + m_TTD[\"shape(rxLev+5FU)\"])                                              d_TTD_scale_1 <- exp(m_TTD[\"scale\"])                       d_TTD_scale_2 <- exp(m_TTD[\"scale\"] + m_TTD[\"rxLev+5FU\"])                        })    results_psa <- run_sim_parallel(     npats=1000,                               # number of patients to be simulated   n_sim=5,                                  # number of simulations to run   psa_bool = TRUE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"one\", \"two\"),             # intervention list   common_all_inputs = common_all_inputs2,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs2,   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_instant_list = cost_instant,   cost_cycle_list = cost_cycle,   ipd = 3,   ncores = 1 #for github pages to work, could be set to min(future::availableCores(omit=1),4) ) #> Analysis number: 1 #> Loading required package: foreach #>  #> Attaching package: 'foreach' #> The following objects are masked from 'package:purrr': #>  #>     accumulate, when #> Simulation number: 1 #> Data aggregated across events and patients by selecting the last value for input_out numeric items and then averaging across patients. Only last value of non-numeric and length > 1 items in simulation is displayed. #> Simulation number: 2 #> Simulation number: 3 #> Simulation number: 4 #> Simulation number: 5 #> Time to run analysis 1: 6.69s #> Total time to run: 6.7s    summary_results_sim(results_psa[[1]], arm =\"two\")  #>                                                    one #> costs                          75,042 (72,611; 76,518) #> dcosts                         91,894 (88,448; 94,004) #> lys                                  8.48 (7.61; 9.22) #> dlys                                 2.21 (1.28; 3.57) #> qalys                                6.53 (5.75; 7.15) #> dqalys                               1.83 (1.06; 2.89) #> ICER                           47,471 (25,299; 73,664) #> ICUR                           57,348 (31,093; 88,616) #> INMB                            -609 (-39,893; 56,060) #> costs_undisc                   77,315 (74,609; 78,985) #> dcosts_undisc                  92,708 (88,869; 95,069) #> lys_undisc                           9.95 (8.86; 10.9) #> dlys_undisc                          2.78 (1.61; 4.49) #> qalys_undisc                         7.69 (6.73; 8.46) #> dqalys_undisc                        2.28 (1.33; 3.62) #> ICER_undisc                    38,238 (20,226; 59,058) #> ICUR_undisc                    46,395 (24,942; 71,456) #> INMB_undisc                   21,248 (-27,465; 92,243) #> cost_adj                       46,079 (45,551; 46,697) #> dcost_adj                      95,023 (93,972; 96,851) #> cost_adj_cycle_l                       0.2 (0.19; 0.2) #> dcost_adj_cycle_l               -0.004 (-0.01; -0.002) #> cost_adj_cycle_starttime                      0 (0; 0) #> dcost_adj_cycle_starttime                     0 (0; 0) #> cost_adj_max_cycles                  34.4 (33.6; 34.9) #> dcost_adj_max_cycles            -0.778 (-1.73; -0.267) #> cost_adj_undisc                46,531 (45,996; 47,158) #> dcost_adj_undisc               95,972 (94,906; 97,828) #> cost_advanced                  24,760 (22,763; 26,467) #> dcost_advanced                 -5,292 (-8,423; -3,356) #> cost_advanced_undisc           26,269 (23,987; 28,191) #> dcost_advanced_undisc          -5,523 (-9,075; -3,402) #> cost_monitor                      2,183 (2,076; 2,271) #> dcost_monitor                           477 (322; 669) #> cost_monitor_cycle_l                 3.44 (3.37; 3.48) #> dcost_monitor_cycle_l          -0.078 (-0.173; -0.027) #> cost_monitor_cycle_starttime         2.71 (2.67; 2.74) #> dcost_monitor_cycle_starttime  -0.094 (-0.149; -0.059) #> cost_monitor_max_cycles              17.2 (16.8; 17.4) #> dcost_monitor_max_cycles       -0.389 (-0.867; -0.133) #> cost_monitor_undisc               2,475 (2,348; 2,581) #> dcost_monitor_undisc                    556 (373; 783) #> cost_tox                          2,020 (1,784; 2,257) #> dcost_tox                         1,686 (1,413; 1,983) #> cost_tox_cycle_l                       0.2 (0.19; 0.2) #> dcost_tox_cycle_l               -0.004 (-0.01; -0.002) #> cost_tox_cycle_starttime                      0 (0; 0) #> dcost_tox_cycle_starttime                     0 (0; 0) #> cost_tox_max_cycles                  34.4 (33.6; 34.9) #> dcost_tox_max_cycles            -0.778 (-1.73; -0.267) #> cost_tox_undisc                   2,040 (1,802; 2,280) #> dcost_tox_undisc                  1,703 (1,427; 2,003) #> q_total                              6.53 (5.75; 7.15) #> dq_total                             1.83 (1.06; 2.89) #> q_total_undisc                       7.69 (6.73; 8.46) #> dq_total_undisc                      2.28 (1.33; 3.62) #>                                                      two #> costs                         166,937 (164,827; 169,604) #> dcosts                                          0 (0; 0) #> lys                                    10.7 (10.1; 11.2) #> dlys                                            0 (0; 0) #> qalys                                  8.35 (7.98; 8.74) #> dqalys                                          0 (0; 0) #> ICER                                        NaN (NA; NA) #> ICUR                                        NaN (NA; NA) #> INMB                                        NaN (NA; NA) #> costs_undisc                  170,023 (167,696; 172,895) #> dcosts_undisc                                   0 (0; 0) #> lys_undisc                               12.7 (12; 13.4) #> dlys_undisc                                     0 (0; 0) #> qalys_undisc                            9.96 (9.5; 10.4) #> dqalys_undisc                                   0 (0; 0) #> ICER_undisc                                 NaN (NA; NA) #> ICUR_undisc                                 NaN (NA; NA) #> INMB_undisc                                 NaN (NA; NA) #> cost_adj                      141,102 (139,724; 143,331) #> dcost_adj                                       0 (0; 0) #> cost_adj_cycle_l                        0.19 (0.19; 0.2) #> dcost_adj_cycle_l                               0 (0; 0) #> cost_adj_cycle_starttime                        0 (0; 0) #> dcost_adj_cycle_starttime                       0 (0; 0) #> cost_adj_max_cycles                      33.6 (33; 34.2) #> dcost_adj_max_cycles                            0 (0; 0) #> cost_adj_undisc               142,503 (141,105; 144,765) #> dcost_adj_undisc                                0 (0; 0) #> cost_advanced                    19,468 (17,953; 20,937) #> dcost_advanced                                  0 (0; 0) #> cost_advanced_undisc             20,746 (19,007; 22,390) #> dcost_advanced_undisc                           0 (0; 0) #> cost_monitor                        2,660 (2,584; 2,758) #> dcost_monitor                                   0 (0; 0) #> cost_monitor_cycle_l                    3.36 (3.3; 3.42) #> dcost_monitor_cycle_l                           0 (0; 0) #> cost_monitor_cycle_starttime           2.61 (2.58; 2.64) #> dcost_monitor_cycle_starttime                   0 (0; 0) #> cost_monitor_max_cycles                16.8 (16.5; 17.1) #> dcost_monitor_max_cycles                        0 (0; 0) #> cost_monitor_undisc                 3,030 (2,938; 3,141) #> dcost_monitor_undisc                            0 (0; 0) #> cost_tox                            3,706 (3,605; 3,970) #> dcost_tox                                       0 (0; 0) #> cost_tox_cycle_l                        0.19 (0.19; 0.2) #> dcost_tox_cycle_l                               0 (0; 0) #> cost_tox_cycle_starttime                        0 (0; 0) #> dcost_tox_cycle_starttime                       0 (0; 0) #> cost_tox_max_cycles                      33.6 (33; 34.2) #> dcost_tox_max_cycles                            0 (0; 0) #> cost_tox_undisc                     3,743 (3,641; 4,010) #> dcost_tox_undisc                                0 (0; 0) #> q_total                                8.35 (7.98; 8.74) #> dq_total                                        0 (0; 0) #> q_total_undisc                          9.96 (9.5; 10.4) #> dq_total_undisc                                 0 (0; 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example in Early Breast Cancer","text":"document runs discrete event simulation model context early breast cancer show functions can used generate model steps. running DES, ’s important consider speed. Simulation based models can computationally expensive, means using efficient coding can substantial impact performance.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Example in Early Breast Cancer","text":"","code":"library(WARDEN)  library(purrr) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"model-concept","dir":"Articles","previous_headings":"Introduction","what":"Model Concept","title":"Example in Early Breast Cancer","text":"Patients start early breast cancer, draw times event. Patients also draw probability going metastatic breast cancer going remission. go remission, can metastatic recurrence. point time can die, depending risk disease stage.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"load-data","dir":"Articles","previous_headings":"Introduction","what":"Load Data","title":"Example in Early Breast Cancer","text":"dummy data costs utility generated .","code":"#Utilities df_util <- data.frame( name = c(\"util.idfs.ontx\" ,\"util.idfs.offtx\" ,\"util.remission\" ,\"util.recurrence\" ,\"util.mbc.progression.mbc\" ,\"util.mbc.pps\"),                          value = c(0.75, 0.8,0.9,0.7,0.6,0.5),                          se=rep(0.02,6),                          stringsAsFactors = FALSE )   #Costs df_cost <- data.frame( name = c(\"cost.idfs.tx\" ,\"cost.recurrence\" ,\"cost.mbc.tx\" ,\"cost.tx.beva\" ,\"cost.idfs.txnoint\",                                   \"cost.idfs\",\"cost.mbc.progression.mbc\",\"cost.mbc.pps\",\"cost.2ndline\",\"cost.ae\"),                          value = c(40000,5000,3000,10000,30000,                                    10000,20000,30000,20000,1000),                          stringsAsFactors = FALSE ) %>%   mutate(se= value/5)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Example in Early Breast Cancer","text":"Initial inputs flags used model can defined . can define inputs common patients (common_all_inputs) within simulation, inputs unique patient independently treatment (e.g. natural death, defined common_pt_inputs), inputs unique patient treatment (unique_pt_inputs). Items can included add_item function, can used subsequent items (e.g. , define sex_pt use nat.os.s get background mortality patient). inputs generated events reaction events executed. Furthermore, program first executes common_all_inputs, common_pt_inputs unique_pt_inputs. one use items generated common_all_inputs unique_pt_inputs. flag fl.remission drawn using Bernoulli distribution probability 0.8. means 80% patients remission, 20% go early metastatic BC. Note also modeled differently using time remission time early metastatic BC, comparing choosing pathway depending one smaller. also define specific utilities costs used model. strongly recommended assign unnamed objects going processed model. case, affected. However, keeping name extracting value e.g. util.remission (e.g. using one bracket instead two util_v[[\"util.remission\"]]) may cause outputs model change names, depending use. R works: correspond named list named vector/element, R concatenates, case end generating qaly.util.remission output model instead just qaly). However unlikely occur times, inputs intermediary (.e., utilities/costs appear ongoing_inputs ), cause trouble.","code":"#Each patient is identified through \"i\" #Items used in the model should be unnamed numeric/vectors! otherwise if they are processed by model it can lead to strangely named outcomes #In this case, util_v is a named vector, but it's not processed by the model. We extract unnamed numerics from it.  #Put objects here that do not change on any patient or intervention loop common_all_inputs <- add_item2(input={    #utilities         pick_val_v(             base =  df_util$value,             psa = MASS::mvrnorm(1,df_util$value,diag(df_util$se^2)),             sens = df_util$value,             psa_ind = psa_bool,             sens_ind = sensitivity_bool,             indicator = rep(0, nrow(df_util)),             names_out =df_util$name,             deploy_env=TRUE         )   #costs         pick_val_v(             base =  df_cost$value,             psa = rgamma_mse(1,df_cost$value,df_cost$se),             sens = df_cost$value,             psa_ind = psa_bool,             sens_ind = sensitivity_bool,             indicator = rep(0, nrow(df_cost)),             names_out =df_cost$name,             deploy_env=TRUE         )         }) #Put objects here that do not change as we loop through interventions for a patient common_pt_inputs <- add_item2(input={     sex_pt <- ifelse(rbinom(1,1,p=0.01),\"male\",\"female\")     nat.os.s <- rcond_gompertz(1,                                shape=if(sex_pt==\"male\"){0.102}else{0.115},                                rate=if(sex_pt==\"male\"){0.000016}else{0.0000041},                                lower_bound = 50)      fl.remission <- rbinom(1,1,0.8) #80% probability of going into remission     }) #in years, for a patient who is 50yo  #Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s) #common across arm but changes per pt could be implemented here (if (arm==)... ) unique_pt_inputs <- add_item2(input={     fl.idfs.ontx              <- 1     fl.idfs                   <- 1     fl.mbcs.ontx              <- 1     fl.mbcs.progression.mbc   <- 1     fl.tx.beva                <- 1       fl.mbcs                   <- 0     fl.mbcs_2ndline           <- 0     fl.recurrence             <- 0     q_default <- if (fl.idfs==1) {         util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)      } else if (fl.idfs==0 & fl.mbcs==0) {         util.remission * fl.remission + fl.recurrence*util.recurrence     } else if (fl.mbcs==1) {         util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps     }     c_default <- if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}     c_ae <- 0 })"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example in Early Breast Cancer","text":"Events added add_tte function. use function twice, one per intervention. must define several arguments: one indicate intervention, one define names events used, one define names objects created like store (optional, maybe generate intermediate input event want save) actual input generate time event. Events objects automatically initialized Inf. draw times event patients. chunk bit complex, ’s worth spending bit time explaining . init_event_list object populated using add_tte function twice, one “int” strategy “noint” strategy. first declare start time 0. proceed generate actual time event. use draw_tte() function generate time event using log-normal distribution event variables interest. One always aware competing risks interact . abstracted type corrections , recommended understanding affect results look competing risks/semi-competing risks literature. Note model, initial list events start, ttot, ttot.beva, progression.mbc, os, idfs, ttot.early, remission, recurrence start.early.mbc. However, , non-initial events can defined reactions part seen section .","code":"init_event_list <-    add_tte(arm=\"int\",                evts = c(\"start\",\"ttot\", \"ttot.beva\",\"progression.mbc\", \"os\",\"idfs\",\"ttot.early\",\"remission\",\"recurrence\",\"start.early.mbc\",\"ae\",\"2ndline_mbc\"),                other_inp = c(\"os.early\",\"os.mbc\"),                input={ #intervention     start <- 0          #Early          idfs <- draw_tte(1,'lnorm',coef1=2, coef2=log(0.2))      ttot.early <- min(draw_tte(1,'lnorm',coef1=2, coef2=log(0.2)),idfs)     ttot.beva <- draw_tte(1,'lnorm',coef1=2, coef2=log(0.2))          os.early <- draw_tte(1,'lnorm',coef1=3, coef2=log(0.2))           #if patient has remission, check when will recurrence happen     if (fl.remission) {        recurrence <- idfs +draw_tte(1,'lnorm',coef1=2, coef2=log(0.2))       remission <- idfs              #if recurrence happens before death       if (min(os.early,nat.os.s)>recurrence) {                   #Late metastatic (after finishing idfs and recurrence)                  os.mbc <- draw_tte(1,'lnorm',coef1=0.8, coef2=log(0.2)) + idfs  +  recurrence                   progression.mbc <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + idfs +  recurrence                   ttot <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + idfs +  recurrence                         }            } else{ #If early metastatic       start.early.mbc <- draw_tte(1,'lnorm',coef1=2.3, coef2=log(0.2))              idfs <- ifelse(start.early.mbc<idfs,start.early.mbc,idfs)       ttot.early <- min(ifelse(start.early.mbc<idfs,start.early.mbc,idfs),ttot.early)              os.mbc <- draw_tte(1,'lnorm',coef1=0.8, coef2=log(0.2)) + start.early.mbc              progression.mbc <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + start.early.mbc              ttot <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + start.early.mbc            }          os <- min(os.mbc,os.early,nat.os.s)         }) %>%  add_tte(arm=\"noint\",                        evts = c(\"start\",\"ttot\", \"ttot.beva\",\"progression.mbc\", \"os\",\"idfs\",\"ttot.early\",\"remission\",\"recurrence\",\"start.early.mbc\"),                        other_inp = c(\"os.early\",\"os.mbc\"),                                               input={  #reference strategy     start <- 0      #Early          idfs <- draw_tte(1,'lnorm',coef1=2, coef2=log(0.2),beta_tx = 1.2)      ttot.early <- min(draw_tte(1,'lnorm',coef1=2, coef2=log(0.2),beta_tx = 1.2),idfs)          os.early <- draw_tte(1,'lnorm',coef1=3, coef2=log(0.2),beta_tx = 1.2)           #if patient has remission, check when will recurrence happen     if (fl.remission) {        recurrence <- idfs +draw_tte(1,'lnorm',coef1=2, coef2=log(0.2))       remission <- idfs              #if recurrence happens before death       if (min(os.early,nat.os.s)>recurrence) {                   #Late metastatic (after finishing idfs and recurrence)                  os.mbc <- draw_tte(1,'lnorm',coef1=0.8, coef2=log(0.2)) + idfs  +  recurrence                   progression.mbc <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + idfs +  recurrence                   ttot <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + idfs +  recurrence                }            } else{ #If early metastatic       start.early.mbc <- draw_tte(1,'lnorm',coef1=2.3, coef2=log(0.2))              idfs <- ifelse(start.early.mbc<idfs,start.early.mbc,idfs)       ttot.early <- min(ifelse(start.early.mbc<idfs,start.early.mbc,idfs),ttot.early)              os.mbc <- draw_tte(1,'lnorm',coef1=0.8, coef2=log(0.2)) + start.early.mbc              progression.mbc <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + start.early.mbc              ttot <- draw_tte(1,'lnorm',coef1=0.5, coef2=log(0.2)) + start.early.mbc                   }         os <- min(os.mbc,os.early,nat.os.s)        })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Example in Early Breast Cancer","text":"initial times events defined, also need declare events react affect . , use evt_react_list object add_reactevt function. function just needs state event affected, actual reaction (usually setting flags 1 0, creating new/adjusting events). series objects can used context help reactions. Apart global objects flags defined , can also use curtime current event time, prevtime time previous event, cur_evtlist named vector events yet happen patient, arm current treatment loop, evt current event processed, expresses patient iteration, simulation specific simulation (relevant number simulations greater 1). Furthermore, one can also call input/item created create new ones. example, even modify cost/utility item changing directly, e.g. modify_item(list(cost.idfs.tx=500)). functions add/modify events inputs use lists. Whenever several inputs/events added modified, ’s recommended group within one function, reduces computation cost. rather use two modify_event list one element, ’s better group single modify_event list two elements. new_eventallows generate events add vector events. accepts one event. modify_event allows modify events (e.g. delay death). adding event, name events time events must defined. using modify_event, one must indicate events affected new times events. event specified exist already occurred, ignored. modify_event create_if_null = TRUE argument also generate events don’t exist. Note one potentially omit part modeling set init_event_list actually define new events dynamically reactions (\"ae\" event). However, can impact computation time, possible ’s always better use init_event_list. modify/create items, WARDEN now allows assign directly code, without need use modify_item modify_item_seq, allows code run faster (~30-35% faster comparing modify_item_seq, 15-20% comparing modify_item). However, two functions, modify_item modify_item_seq, still available user keep working, allow modify add items. Elements defined within function evaluated sequentially modify_item (.e. defining modify_item(list(fl.new = 1, var1 = fl.new * 5))) give error fl.new defined outside function), modify_item_seq sequentially slightly bigger computational cost, left choices user. Note one can modify costs/utilities using construction type_name_category, type either “qaly” “cost”, name name (e.g., “default”) category category used (e.g., “instant”), one pass cost_default_instant modify cost. list relevant functions used within add_reactevt : model run curtime set Inf, event terminates model (case, os), modify curtime set Inf. Finally, note two different ways accumulating continuous outcomes, backwards (.e., example , set q_default = util.sick sicker event, modify q_default value death event) forwards (example ). option can modified run_sim function using accum_backwards argument, assumes forwards default.","code":"evt_react_list <-   add_reactevt(name_evt = \"start\",                input = {}) %>%   add_reactevt(name_evt = \"ttot\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                  fl.mbcs.ontx <-  0 #Flag that patient is now off-treatment                                  }) %>%   add_reactevt(name_evt = \"ttot.beva\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                 fl.tx.beva <- 0 #Flag that patient is now off-treatment                                  }) %>%   add_reactevt(name_evt = \"progression.mbc\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                  fl.mbcs.progression.mbc <- 0                  fl.mbcs_2ndline <- 1 #Flag that patient is progressed and going in 2nd line                                    new_event(list(\"2ndline_mbc\" = curtime + draw_tte(1,'exp', log(0.08))/12))                                  }) %>%   add_reactevt(name_evt = \"idfs\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}                  fl.idfs <- 0                                  }) %>%   add_reactevt(name_evt = \"ttot.early\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}                  fl.idfs.ontx <- 0                  fl.tx.beva <- 0 #Flag that patient is now off-treatment                                    n_ae <- rpois(1,lambda=0.25*(curtime -prevtime)) #1 AE every 4 years                                    if (n_ae>0) {                    new_event(rep(list(\"ae\" = curtime + 0.0001),n_ae))                  }                }) %>%   add_reactevt(name_evt = \"remission\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.recurrence * fl.recurrence                  fl.remission <- 1                                  }) %>%   add_reactevt(name_evt = \"recurrence\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.recurrence * fl.recurrence                  fl.recurrence <- 1                  fl.remission <- 0                  fl.mbcs <- 1                  fl.mbcs.progression.mbc <- 1 #ad-hoc for plot                                  }) %>%   add_reactevt(name_evt = \"start.early.mbc\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.recurrence * fl.recurrence                  fl.mbcs <- 1                  fl.mbcs.progression.mbc <- 1                                  }) %>%   add_reactevt(name_evt = \"2ndline_mbc\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                  fl.mbcs_2ndline <- 0                                    n_ae <- rpois(1,lambda=0.25*(curtime -prevtime)) #1 AE every 4 years                                    if (n_ae>0) {                    new_event(rep(list(\"ae\" = curtime + 0.0001),n_ae))                  }                }) %>%   add_reactevt(name_evt = \"ae\",                input = {                                                     q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                  c_ae <- cost.ae                                    modify_event(list(\"os\" =max(cur_evtlist[[\"os\"]] - 0.125,curtime +0.0001) ))#each AE brings forward death by 1.5 months                }) %>%   add_reactevt(name_evt = \"os\",                input = {                  q_default <- if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                  c_default <- cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                  fl.tx.beva <- 0                  fl.mbcs.ontx <- 0                  fl.idfs <- 0                  fl.mbcs <- 0                  curtime <- Inf                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Example in Early Breast Cancer","text":"Costs utilities introduced . However, ’s worth noting model able run without costs utilities. Utilities/Costs/outputs defined declaring object belongs utilities/costs/outputs, whether need discounted continuously discretely (instantaneous). passed run_sim function. ## Utilities","code":"util_ongoing <- \"q_default\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example in Early Breast Cancer","text":"","code":"cost_ongoing <- \"c_default\"  cost_instant <-  \"c_ae\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example in Early Breast Cancer","text":"model can run using function run_sim . must define number patients simulated, number simulations, whether want run PSA , strategy list, inputs, events reactions defined , utilities, costs also want extra output level ipd data desired exported. worth noting psa_bool argument run PSA automatically, rather additional input/flag model use reference determine whether want use deterministic stochastic input. , also defined common_all_inputs first item defined, result . However, recommend defined run_sim. Note distribution chosen, number events interaction events can substantial impact running time model.","code":"#Logic is: per patient, per intervention, per event, react to that event. results <- run_sim(     npats=2000,                              # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   cost_instant_list = cost_instant,   input_out = c(                            # list of additional outputs (Flags, etc) that the user wants to export for each patient and event                 \"os.early\",                 \"os.mbc\",                 \"nat.os.s\",                 \"sex_pt\"                 )           ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 2.56s #> Time to run analysis 1: 2.56s #> Total time to run: 2.56s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example in Early Breast Cancer","text":"model run, can use results summarize using summary_results_det print results last simulation (nsim=1, ’s deterministic case), summary_results_sim show PSA results (confidence intervals). can also use individual patient data generated simulation, collect plot psa_ipd object. can also check absolute number events per strategy.","code":"summary_results_det(results[[1]][[1]])  #>                         int      noint #> costs             425085.10  239762.47 #> dcosts                 0.00  185322.64 #> lys                   13.59      12.18 #> dlys                   0.00       1.42 #> qalys                 10.87       9.72 #> dqalys                 0.00       1.15 #> ICER                     NA  130546.62 #> ICUR                     NA  161203.00 #> INMB                     NA -127841.50 #> costs_undisc      486788.91  267144.88 #> dcosts_undisc          0.00  219644.03 #> lys_undisc            17.71      15.29 #> dlys_undisc            0.00       2.41 #> qalys_undisc          14.31      12.31 #> dqalys_undisc          0.00       2.00 #> ICER_undisc              NA   90969.21 #> ICUR_undisc              NA  109662.26 #> INMB_undisc              NA -119498.35 #> c_ae                 482.41     591.72 #> dc_ae                  0.00    -109.31 #> c_ae_undisc          588.50     701.50 #> dc_ae_undisc           0.00    -113.00 #> c_default         424602.70  239170.75 #> dc_default             0.00  185431.95 #> c_default_undisc  486200.41  266443.38 #> dc_default_undisc      0.00  219757.03 #> nat.os.s              34.45      34.45 #> dnat.os.s              0.00       0.00 #> os.early              20.40      16.95 #> dos.early              0.00       3.45 #> os.mbc                21.73      19.41 #> dos.mbc                0.00       2.33 #> q_default             10.87       9.72 #> dq_default             0.00       1.15 #> q_default_undisc      14.31      12.31 #> dq_default_undisc      0.00       2.00  summary_results_sim(results[[1]]) #>                                                int #> costs                   425,085 (425,085; 425,085) #> dcosts                                    0 (0; 0) #> lys                           13.59 (13.59; 13.59) #> dlys                                      0 (0; 0) #> qalys                         10.87 (10.87; 10.87) #> dqalys                                    0 (0; 0) #> ICER                                  NaN (NA; NA) #> ICUR                                  NaN (NA; NA) #> INMB                                  NaN (NA; NA) #> costs_undisc            486,789 (486,789; 486,789) #> dcosts_undisc                             0 (0; 0) #> lys_undisc                    17.71 (17.71; 17.71) #> dlys_undisc                               0 (0; 0) #> qalys_undisc                  14.31 (14.31; 14.31) #> dqalys_undisc                             0 (0; 0) #> ICER_undisc                           NaN (NA; NA) #> ICUR_undisc                           NaN (NA; NA) #> INMB_undisc                           NaN (NA; NA) #> c_ae                       482.41 (482.41; 482.41) #> dc_ae                                     0 (0; 0) #> c_ae_undisc                   588.5 (588.5; 588.5) #> dc_ae_undisc                              0 (0; 0) #> c_default         424,602.7 (424,602.7; 424,602.7) #> dc_default                                0 (0; 0) #> c_default_undisc  486,200.4 (486,200.4; 486,200.4) #> dc_default_undisc                         0 (0; 0) #> nat.os.s                      34.45 (34.45; 34.45) #> dnat.os.s                                 0 (0; 0) #> os.early                         20.4 (20.4; 20.4) #> dos.early                                 0 (0; 0) #> os.mbc                        21.73 (21.73; 21.73) #> dos.mbc                                   0 (0; 0) #> q_default                     10.87 (10.87; 10.87) #> dq_default                                0 (0; 0) #> q_default_undisc              14.31 (14.31; 14.31) #> dq_default_undisc                         0 (0; 0) #>                                              noint #> costs                   239,762 (239,762; 239,762) #> dcosts                  185,323 (185,323; 185,323) #> lys                           12.18 (12.18; 12.18) #> dlys                             1.42 (1.42; 1.42) #> qalys                            9.72 (9.72; 9.72) #> dqalys                           1.15 (1.15; 1.15) #> ICER                    130,547 (130,547; 130,547) #> ICUR                    161,203 (161,203; 161,203) #> INMB                 -127,841 (-127,841; -127,841) #> costs_undisc            267,145 (267,145; 267,145) #> dcosts_undisc           219,644 (219,644; 219,644) #> lys_undisc                    15.29 (15.29; 15.29) #> dlys_undisc                   2.414 (2.414; 2.414) #> qalys_undisc                  12.31 (12.31; 12.31) #> dqalys_undisc                 2.003 (2.003; 2.003) #> ICER_undisc                90,969 (90,969; 90,969) #> ICUR_undisc             109,662 (109,662; 109,662) #> INMB_undisc          -119,498 (-119,498; -119,498) #> c_ae                       591.72 (591.72; 591.72) #> dc_ae                   -109.31 (-109.31; -109.31) #> c_ae_undisc                   701.5 (701.5; 701.5) #> dc_ae_undisc                     -113 (-113; -113) #> c_default         239,170.8 (239,170.8; 239,170.8) #> dc_default        185,431.9 (185,431.9; 185,431.9) #> c_default_undisc  266,443.4 (266,443.4; 266,443.4) #> dc_default_undisc       219,757 (219,757; 219,757) #> nat.os.s                      34.45 (34.45; 34.45) #> dnat.os.s                                 0 (0; 0) #> os.early                      16.95 (16.95; 16.95) #> dos.early                     3.453 (3.453; 3.453) #> os.mbc                        19.41 (19.41; 19.41) #> dos.mbc                       2.325 (2.325; 2.325) #> q_default                        9.72 (9.72; 9.72) #> dq_default                       1.15 (1.15; 1.15) #> q_default_undisc              12.31 (12.31; 12.31) #> dq_default_undisc             2.003 (2.003; 2.003)  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))   psa_ipd[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_eBC.html","id":"plots","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Plots","title":"Example in Early Breast Cancer","text":"now use data output plot histograms/densities simulation.  can also plot patient level QALY/costs. Note several clusters distribution patients according QALY/costs based pathway took (early metastatic vs. remission cure recurrence).","code":"data_plot <- results[[1]][[1]]$merged_df %>%   filter(evtname != \"start\") %>%   group_by(arm,evtname,simulation) %>%   mutate(median = median(evttime)) %>%   ungroup()  #Density ggplot(data_plot) +   geom_density(aes(fill = arm, x = evttime),                  alpha = 0.7) +   geom_vline(aes(xintercept=median,col=arm)) +   facet_wrap( ~ evtname, scales = \"free_y\") +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw() data_qaly_cost<- psa_ipd[,.SD[1],by=.(pat_id,arm,simulation)][,.(arm,qaly=total_qalys,cost=total_costs,pat_id,simulation)] data_qaly_cost[,ps_id:=paste(pat_id,simulation,sep=\"_\")]   mean_data_qaly_cost <- data_qaly_cost %>% group_by(arm) %>% summarise(across(where(is.numeric),mean))  ggplot(data_qaly_cost,aes(x=qaly, y = cost, col = arm)) +    geom_point(alpha=0.15,shape = 21) +   geom_point(data=mean_data_qaly_cost, aes(x=qaly, y = cost, fill = arm), shape = 21,col=\"black\",size=3) +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw()+   theme(axis.text.x = element_text(angle = 90, vjust = .5))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example with IPD trial data","text":"document runs discrete event simulation model using simulated individual patient data (IPD) show functions can used generate model IPD trial available.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"packages-and-main-options","dir":"Articles","previous_headings":"","what":"Packages and main options","title":"Example with IPD trial data","text":"","code":"library(WARDEN) library(dplyr) library(survival) library(survminer) library(kableExtra) library(tidyr) library(purrr) library(flexsurv) options(scipen = 999) options(tibble.print_max = 50)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"model-concept","dir":"Articles","previous_headings":"","what":"Model concept","title":"Example with IPD trial data","text":"model represented . patients start progression-free state may move progressed state. point time can die, depending risk disease stage. Patients may also experience disease event accelerates progression.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"generate-dummy-ipd-trial-data-and-fit-survival-models","dir":"Articles","previous_headings":"","what":"Generate dummy IPD trial data and fit survival models","title":"Example with IPD trial data","text":"dummy IPD trial data generated using sim_adtte() function flexsurvPlus package. Parametric survival models fit dummy OS TTP IPD. using flexsurv package fit parametric survival models.","code":"#Generate dummy IPD tte.df <- WARDEN::tte.df  #Change data frame to wide format tte.df <- tte.df %>% select(-PARAM) %>% pivot_wider(names_from = PARAMCD, values_from = c(AVAL,CNSR))   #Derive Time to Progression Variable from OS and PFS tte.df <- tte.df %>% mutate(   AVAL_TTP = AVAL_PFS,   CNSR_TTP = ifelse(AVAL_PFS == AVAL_OS & CNSR_PFS==0 & CNSR_OS==0,1,CNSR_PFS),   Event_OS = 1-CNSR_OS,   Event_PFS = 1-CNSR_PFS,   Event_TTP = 1-CNSR_TTP   )  #Add baseline characteristics (sex and age) to time to event data IPD <- tte.df %>% mutate(   SEX = rbinom(500,1,0.5),   AGE = rnorm(500,60,8) ) #Plot simulated OS and TTP curves  #Overall survival km.est.OS <- survfit(Surv(AVAL_OS/365.25, Event_OS) ~ ARMCD, data = IPD) #KM curve  OS.fit <- flexsurvreg(formula = Surv(AVAL_OS/365.25, Event_OS) ~ ARMCD, data = IPD, dist = \"Weibull\") #Fit Weibull model to the OS data OS.fit #> Call: #> flexsurvreg(formula = Surv(AVAL_OS/365.25, Event_OS) ~ ARMCD,  #>     data = IPD, dist = \"Weibull\") #>  #> Estimates:  #>         data mean  est     L95%    U95%    se      exp(est)  L95%    U95%   #> shape       NA     1.1346  0.9764  1.3185  0.0870      NA        NA      NA #> scale       NA     3.1523  2.5170  3.9479  0.3620      NA        NA      NA #> ARMCDB  0.5000     0.3066  0.0183  0.5949  0.1471  1.3588    1.0185  1.8129 #>  #> N = 500,  Events: 150,  Censored: 350 #> Total time at risk: 623.0253 #> Log-likelihood = -360.0964, df = 3 #> AIC = 726.1929  ggsurvplot(OS.fit, title=\"Overall survival\",            legend.labs = c(\"Reference\",\"Intervention\"),            risk.table = TRUE) #Time to progression km.est.TTP <- survfit(Surv(AVAL_TTP/365.25, Event_TTP) ~ ARMCD, data = IPD) #KM curve  TTP.fit <- flexsurvreg(formula = Surv(AVAL_TTP/365.25, Event_TTP) ~ ARMCD, data = IPD, dist = \"Weibull\") #Fit Weibull model to the TTP data TTP.fit #> Call: #> flexsurvreg(formula = Surv(AVAL_TTP/365.25, Event_TTP) ~ ARMCD,  #>     data = IPD, dist = \"Weibull\") #>  #> Estimates:  #>         data mean  est     L95%    U95%    se      exp(est)  L95%    U95%   #> shape       NA     1.3757  1.2590  1.5033  0.0622      NA        NA      NA #> scale       NA     0.5865  0.5310  0.6478  0.0297      NA        NA      NA #> ARMCDB  0.5000     1.0992  0.9277  1.2707  0.0875  3.0016    2.5286  3.5632 #>  #> N = 500,  Events: 328,  Censored: 172 #> Total time at risk: 358.9897 #> Log-likelihood = -269.0387, df = 3 #> AIC = 544.0774  ggsurvplot(TTP.fit, title=\"Time to progression\",            legend.labs = c(\"Reference\",\"Intervention\"),            risk.table = TRUE)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"define-des-model-inputs","dir":"Articles","previous_headings":"","what":"Define DES model inputs","title":"Example with IPD trial data","text":"Inputs variables used model defined . can define inputs common patients (common_all_inputs) within simulation, inputs unique patient independently treatment (e.g. natural death, defined common_pt_inputs), inputs unique patient treatment (unique_pt_inputs). Items can included add_item function, can used subsequent items. inputs generated events reaction events executed. Furthermore, program first executes common_all_inputs, common_pt_inputs unique_pt_inputs. one use items generated common_all_inputs unique_pt_inputs.","code":"#Define variables that do not change on any patient or intervention loop common_all_inputs <- add_item(    #Parameters from the survival models   OS.scale = as.numeric(OS.fit$coef[2]),   OS.shape = as.numeric(OS.fit$coef[1]),   OS.coef.int = as.numeric(OS.fit$coef[3]), #Intervention effect    TTP.scale = as.numeric(TTP.fit$coef[2]),   TTP.shape = as.numeric(TTP.fit$coef[1]),   TTP.coef.int = as.numeric(TTP.fit$coef[3]), #Intervention effect      #Utilities   util.PFS = 0.6, #Utility while in progression-free state   util.PPS = 0.4, #Utility while in progressed state   disutil.PAE = -0.02, #One-off disutility of progression-accelerating event    #Costs   cost.drug.int = 85000, #Annual intervention cost   cost.drug.ref = 29000, #Annual cost of reference treatment   cost.admin.SC = 150, #Unit cost for each SC administration   cost.admin.oral = 300, #One-off cost for oral administration   cost.dm.PFS = 3000, #Annual disease-management cost in progression-free state   cost.dm.PPS = 5000, #Annual disease-management cost in progressed state   cost.ae.int = 2200, #Annual adverse event costs for intervention   cost.ae.ref = 1400 #Annual adverse event costs for reference treatment     )   #Define variables that do not change as we loop through interventions for a patient common_pt_inputs <- add_item(   #Patient baseline characteristics   Sex = as.numeric(IPD[i,\"SEX\"]), #Record sex of individual patient. 0 = Female; 1 =Male   BLAge = as.numeric(IPD[i,\"AGE\"]), #Record patient age at baseline      #Draw time to non-disease related death from a conditional Gompertz distribution   nat.death = rcond_gompertz(1,shape=if(Sex==1){0.102}else{0.115},                                rate=if(Sex==1){0.000016}else{0.0000041},                                lower_bound = BLAge) # Baseline Age in years   )   #Define variables that change as we loop through treatments for each patient. unique_pt_inputs <- add_item(   fl.int  = 0, #Flag to determine if patient is on intervention. Initialized as 0, but will be changed to current arm in the Start event.   fl.prog = 0, #Flag to determine if patient has progressed. All patients start progression-free   fl.ontx = 1, #Flag to determine if patient is on treatment. All patients start on treatment   fl.PAE = 0,  #Flag to determine if progression-accelerating event occurred   pfs.time = NA, #Recording of time at progression   q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),   q_default_inst = 0,   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref},   c_default_inst = 0 )"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example with IPD trial data","text":"define now possible events can occur intervention reference arm respectively using add_tte() function. patients intervention arm can treatment discontinuation, patients arms can progression, progression-accelerating death event. seed argument used draw_tte() function uses item ensure event times specific patient can replicated updated later time points.","code":"init_event_list <-    #Events applicable to intervention   add_tte(arm=c(\"int\",\"ref\"),           evts = c(\"Start\",                    \"TxDisc\",                    \"Progression\",                    \"PAE\",                    \"Death\"),                input={     Start <- 0     Progression <- draw_tte(1,'weibull',coef1=TTP.shape, coef2= TTP.scale + ifelse(arm==\"int\",TTP.coef.int,0),seed = as.numeric(paste0(1,i,simulation)))     TxDisc <- Inf #Treatment discontinuation will occur at progression     Death <- min(draw_tte(1,'weibull',coef1=OS.shape, coef2= OS.scale + ifelse(arm==\"int\",OS.coef.int,0), seed = as.numeric(paste0(42,i,simulation))), nat.death) #Death occurs at earliest of disease-related death or non-disease-related death     PAE <- draw_tte(1,'exp',coef1=-log(1-ifelse(arm==\"int\",0.05,0.15))) #Occurrence of the progression-accelerating event has a 5% or 15% probability for the intervention arm   })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"add-event-reactions","dir":"Articles","previous_headings":"Events","what":"Add Event Reactions","title":"Example with IPD trial data","text":"Reactions individual event defined following using add_reactevt() function. Patients intervention arm discontinue treatment progression. Occurrence progression-accelerated event results earlier progression (occurred yet). Note use seed argument draw_tte() function ensures seed used original updated draw time progression. mentioned , user can choose whether use modify_item, modify_item_seq just use assignments. leave example using modify_item showcase .","code":"evt_react_list <-   add_reactevt(name_evt = \"Start\",                input = {                  modify_item(list(fl.int = ifelse(arm==\"int\",1,0),                                   q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),                                   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref},                                   c_default_inst = cost.admin.oral                                   ))                }) %>%   add_reactevt(name_evt = \"TxDisc\",                input = {                  modify_item(list(q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),                                   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref},                                   \"fl.ontx\"= 0))                }) %>%   add_reactevt(name_evt = \"Progression\",                input = {                  modify_item(list(q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),                                   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref},                                   \"pfs.time\"=curtime,\"fl.prog\"= 1))                  if(arm==\"int\"){modify_event(list(\"TxDisc\" = curtime))} #Trigger treatment discontinuation at progression                }) %>%   add_reactevt(name_evt = \"Death\",                input = {                  modify_item(list(q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),                                   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref},                                   \"curtime\"=Inf))                 }) %>%   add_reactevt(name_evt = \"PAE\",                input = {                  modify_item(list(\"fl.PAE\"= 1,                                   q_default = ifelse(fl.prog == 0, util.PFS, util.PPS),                                   q_default_inst = disutil.PAE,                                   c_default = ifelse(fl.prog == 0,cost.dm.PFS,cost.dm.PPS) + if(arm==\"int\"){(cost.drug.int + cost.admin.SC * 12 + cost.ae.int) * fl.ontx}else{cost.drug.ref + cost.ae.ref}))                                    if(fl.prog == 0){ #Event only accelerates progression if progression has not occurred yet                  modify_event(list(                    \"Progression\"=max(draw_tte(1,'weibull',coef1=TTP.shape, coef2= TTP.scale + TTP.coef.int*fl.int, beta_tx = 1.2, seed = as.numeric(paste0(1,i,simulation))),curtime))) #Occurrence of event accelerates progression by a factor of 1.2                  }                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Example with IPD trial data","text":"Costs utilities introduced .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"utilities","dir":"Articles","previous_headings":"Costs and Utilities","what":"Utilities","title":"Example with IPD trial data","text":"","code":"util_ongoing <- \"q_default\"  util_instant <- \"q_default_inst\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example with IPD trial data","text":"","code":"cost_ongoing <- \"c_default\"  cost_instant <- \"c_default_inst\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example with IPD trial data","text":"model executed event reactions inputs previously defined patient simulated data set.","code":"#Logic is: per patient, per intervention, per event, react to that event. results <- run_sim(     npats=as.numeric(nrow(IPD)),              # Simulating the number of patients for which we have IPD   n_sim=1,                                  # We run all patients once (per treatment)   psa_bool = FALSE,                         # No PSA for this example   arm_list = c(\"int\", \"ref\"),                common_all_inputs = common_all_inputs,       common_pt_inputs = common_pt_inputs,         unique_pt_inputs = unique_pt_inputs,         init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   util_instant_list = util_instant,   cost_ongoing_list = cost_ongoing,   cost_instant_list = cost_instant,   input_out = c(\"BLAge\",\"Sex\",\"nat.death\",\"pfs.time\") ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.76s #> Time to run analysis 1: 0.76s #> Total time to run: 0.76s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example with IPD trial data","text":"model run, can use results summarize using summary_results_det print results deterministic case. individual patient data generated simulation recorded psa_ipd object. can also check absolute number events per strategy.","code":"summary_results_det(results[[1]][[1]]) #will print the last simulation! #>                              int        ref #> costs                  261251.76   94361.19 #> dcosts                      0.00  166890.57 #> lys                         3.60       2.75 #> dlys                        0.00       0.85 #> qalys                       1.71       1.41 #> dqalys                      0.00       0.30 #> ICER                          NA  195784.55 #> ICUR                          NA  563768.08 #> INMB                          NA -152089.22 #> costs_undisc           286099.08  101986.36 #> dcosts_undisc               0.00  184112.72 #> lys_undisc                  3.99       2.97 #> dlys_undisc                 0.00       1.02 #> qalys_undisc                1.88       1.52 #> dqalys_undisc               0.00       0.35 #> ICER_undisc                   NA  180232.81 #> ICUR_undisc                   NA  518666.81 #> INMB_undisc                   NA -166364.07 #> BLAge                      59.66      59.66 #> dBLAge                      0.00       0.00 #> c_default              260951.76   94061.19 #> dc_default                  0.00  166890.57 #> c_default_inst            300.00     300.00 #> dc_default_inst             0.00       0.00 #> c_default_inst_undisc     300.00     300.00 #> dc_default_inst_undisc      0.00       0.00 #> c_default_undisc       285799.08  101686.36 #> dc_default_undisc           0.00  184112.72 #> nat.death                  24.33      24.33 #> dnat.death                  0.00       0.00 #> pfs.time                    1.61       0.58 #> dpfs.time                   0.00       1.03 #> q_default                   1.73       1.43 #> dq_default                  0.00       0.30 #> q_default_inst             -0.02      -0.02 #> dq_default_inst             0.00       0.00 #> q_default_inst_undisc      -0.02      -0.02 #> dq_default_inst_undisc      0.00       0.00 #> q_default_undisc            1.89       1.54 #> dq_default_undisc           0.00       0.36 #> Sex                         0.53       0.53 #> dSex                        0.00       0.00  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))   psa_ipd[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ipd.html","id":"plots","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Plots","title":"Example with IPD trial data","text":"now use simulation output plot Kaplan-Meier curves simulated OS PFS observed Kaplan-Meier curves. simulated progression-free survival curve lower observed due addition progression-accelerating event model.","code":"#Overall survival KM.death <- psa_ipd %>% filter(evtname==\"Death\") %>% mutate(Event = 1)  sim.km.OS <- survfit(Surv(evttime, Event) ~ arm, data = KM.death)  km.comb <- list(   Observed = km.est.OS,   Predicted = sim.km.OS )  ggsurvplot(km.comb, combine = TRUE,            title=\"Overall Survival\",            palette=c(\"coral\",\"turquoise\",\"turquoise3\",\"coral3\"),            legend.labs=c(\"Observed - Ref\",\"Observed - Int\",\"Predicted - Int\",\"Predicted - Ref\"),            linetype = c(2,2,1,1),            xlim=c(0,10), break.time.by = 1, censor=FALSE) #Progression-free survival km.est.PFS <- survfit(Surv(AVAL_PFS/365.25, Event_PFS) ~ ARMCD, data = IPD) KM.PFS.DES <- psa_ipd %>% filter(evtname==\"Death\") %>% mutate(evttime = ifelse(is.na(pfs.time),evttime,pfs.time),                                                           Event = 1)  sim.km.PFS <- survfit(Surv(evttime, Event) ~ arm, data = KM.PFS.DES)  km.comb <- list(Observed = km.est.PFS,                 Predicted = sim.km.PFS)  ggsurvplot(km.comb,combine = TRUE,            title=\"Progression-free Survival\",            palette=c(\"coral\",\"turquoise\",\"turquoise3\",\"coral3\"),            legend.labs=c(\"Observed - Ref\",\"Observed - Int\",\"Predicted - Int\",\"Predicted - Ref\"),            linetype = c(2,2,1,1),            xlim=c(0,5), break.time.by = 1, censor = FALSE)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example for a Markov Model","text":"document runs discrete event simulation model context simple cohort Markov model 4 states. Note exercise done patient simulation approach (microsimulation) rather cohort one.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Example for a Markov Model","text":"","code":"library(WARDEN)  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows library(purrr)  #Show all numbers, no scientific notation options(scipen = 999)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"model-concept","dir":"Articles","previous_headings":"Introduction","what":"Model Concept","title":"Example for a Markov Model","text":"model simple Markov model 4 states whose transition matrix can found . order run pure Markov model within functions, define event cycle. generate initial trace event (cycle) update trace multiplying transition matrix. Costs QALYs can computed similar fashion multiplying trace times cost utility.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"load-data","dir":"Articles","previous_headings":"Introduction","what":"Load Data","title":"Example for a Markov Model","text":"dummy data generated . data structure defined , otherwise give problems.","code":"#Utilities util.data <- data.frame( name = c(\"util1\" ,\"util2\" ,\"util3\" ,\"util4\"),                          value = c(0.9,0.75,0.6,0),                          se=rep(0.02,4),                          stringsAsFactors = FALSE )   #Costs cost.data <- data.frame( name = c(\"cost1\" ,\"cost2\" ,\"cost3\" ,\"cost4\",\"cost_int\"),                          value = c(1000,3000,6000,0,1000),                          stringsAsFactors = FALSE ) %>%   mutate(se= value/5)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Example for a Markov Model","text":"Initial inputs flags used model can defined . can define inputs common patients (common_all_inputs) within simulation, inputs unique patient independently treatment (e.g. natural death, defined common_pt_inputs), inputs unique patient treatment (unique_pt_inputs). Items can included add_item function, can used subsequent items. inputs generated events reaction events executed. Furthermore, program first executes common_all_inputs, common_pt_inputs unique_pt_inputs. one use items generated common_all_inputs unique_pt_inputs. also define specific utilities costs used model. strongly recommended assign unnamed objects going processed model. case, ’re using util_v cost_v intermediate input objects processed (just use make code readable), ’s fine name . define initial trace, number cycles simulated, transition matrices initial cycle time (.e. 0). important note QALYs Costs used length 1. length > 1, model expand data, instead event row, event 4 rows (1 per state). means processing results data needed order provide correct results.","code":"#Put objects here that do not change on any patient or intervention loop, for example costs and utilities common_all_inputs <- add_item(max_n_cycles = 30) %>%   add_item( #utilities      pick_val_v(base        = util.data$value,                 psa         = pick_psa(rep(\"rbeta_mse\",nrow(util.data)),rep(1,nrow(util.data)),util.data$value,util.data$se),                 sens        = util.data$value,                 psa_ind     = psa_bool,                 sens_ind    = sensitivity_bool,                 indicator   = rep(0, nrow(util.data)),                 names_out   = util.data[,\"name\"]                 )      ) %>%   add_item( #costs     pick_val_v(base         = cost.data$value,                 psa         = pick_psa(rep(\"rgamma_mse\",nrow(cost.data)),rep(1,nrow(cost.data)),cost.data$value,cost.data$se),                 sens        = cost.data$value,                 psa_ind     = psa_bool,                 sens_ind    = sensitivity_bool,                 indicator   = rep(0, nrow(cost.data)),                 names_out   = cost.data[,\"name\"]                 )     )   #Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s) #common across arm but changes per pt could be implemented here (if (arm==)... ) unique_pt_inputs <- add_item(                             trace = c(1,0,0,0), #initialize trace, everyone at state 1                             transition = if( arm==\"noint\"){                                              matrix(c(0.4,0.3,0.2,0.1,                                             0.1,0.4,0.3,0.2,                                             0.1,0.1,0.5,0.3,                                             0,0,0,1),nrow=4,byrow=T)                                          } else{                                             matrix(c(0.5,0.3,0.1,0.1,                                                      0.2,0.4,0.3,0.1,                                                      0.1,0.2,0.5,0.2,                                                      0,0,0,1),nrow=4,byrow=T)                                               }, # In this case we have two different matrices, note this could also be a single matrix using symbolic RRs or similar                                                          #Alternative approach                             # rr = ifelse(arm==\"noint\",1,0.9),                             # transition_2 = matrix(c(0.4,0.3,0.2,0.1,                             #                 0.1,0.4,0.3,0.2,                             #                 0.1,0.1,0.5,0.3,                             #                 0,0,0,1),nrow=4,byrow=T) * rr,                             # transition_2 = cbind(1-rowSums(transition_2[,-1]),transition_2[,-1]) ,                             cycle_time = 0,                             q_default =  trace %*% c(util1,util2,util3,util4), #utilities weighted by state to get QALY                             c_default = if(arm==\"noint\"){                                trace %*% c(cost1+ cost_int,cost2+ cost_int,cost3+ cost_int,cost4)                              } else{                                trace %*% c(cost1,cost2,cost3,cost4)                              } )"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example for a Markov Model","text":"model, events start cycle.","code":"init_event_list <-    add_tte(arm=c(\"noint\",\"int\"),evts=c(\"start\",\"cycle\"),input={ #intervention     start <- 0     cycle <- 1        })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Example for a Markov Model","text":"explanation part works can seen models. Markov model case, event start generate many cycles need. cycle event update time cycle keep track produce output model update trace. Finally, events , finish simulation setting curtime infinity. Alternatively, just use start event iterate cycle, saving everything array. alternative option described involve tweaking running model (using time dimension, e.g., discounting assuming previous time 0 current time 0 instead vector times, results require post-processing adequate).","code":"evt_react_list <-   add_reactevt(name_evt = \"start\",                input = {                  for (cycle in 2:max_n_cycles) {                    new_event(list(\"cycle\" = curtime + cycle))                  }                                  }) %>%   add_reactevt(name_evt = \"cycle\",                input = {                   q_default <- trace %*% c(util1,util2,util3,util4)                  c_default <- if(arm==\"noint\"){                                  trace %*% c(cost1+ cost_int,cost2+ cost_int,cost3+ cost_int,cost4)                                } else{                                  trace %*% c(cost1,cost2,cost3,cost4)                                }                    cycle_time <- cycle_time + 1                    trace <- trace %*% transition #or transition_2                                                        if (max_n_cycles == cycle_time) {                    curtime <- Inf #Indicate end of simulation for patient                  }                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Example for a Markov Model","text":"Costs utilities introduced . However, ’s worth noting model able run without costs utilities.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"utilities","dir":"Articles","previous_headings":"Costs and Utilities","what":"Utilities","title":"Example for a Markov Model","text":"","code":"util_ongoing <- \"q_default\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example for a Markov Model","text":"","code":"cost_ongoing <- \"c_default\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example for a Markov Model","text":"model can run using function run_sim . must define number patients simulated, number simulations, whether want run PSA , strategy list, inputs, events reactions defined , utilities, costs also want extra output level ipd data desired exported. worth noting psa_bool argument run PSA automatically, rather additional input/flag model use reference determine whether want use deterministic stochastic input. , also defined common_all_inputs first item defined, result . However, recommend defined run_sim. Note distribution chosen, number events interaction events can substantial impact running time model. Since taking cohort approach, just need indicate npats = 1.","code":"#Logic is: per patient, per intervention, per event, react to that event. results <- run_sim(     npats=1,                               # number of patients, recommended to set to 1000 if using PSA as it takes quite a while   n_sim=1,                                  # if >1, then PSA, otherwise deterministic   psa_bool = FALSE,   arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   input_out = c(                            # list of additional outputs (Flags, etc) that the user wants to export for each patient and event     \"trace\",     \"cycle_time\"   ) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.05s #> Time to run analysis 1: 0.05s #> Total time to run: 0.06s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example for a Markov Model","text":"model run, can use results summarize using summary_results_det print results last simulation (nsim=1, ’s deterministic case), summary_results_sim show PSA results (confidence intervals). can also use individual patient data generated simulation, collect psa_ipd object. Note data life years wrong, model assumes running patient simulation data therefore ’s adding 4 states together, inflating total life years. can manually adjust get correct life years. Note trace data exported separately ’s length > 1. can also check cycles","code":"summary_results_det(results[[1]][[1]]) #will print the last simulation! #>                        int     noint #> costs             18957.73  20353.56 #> dcosts                0.00  -1395.83 #> lys                  19.89     19.89 #> dlys                  0.00      0.00 #> qalys                 5.81      4.37 #> dqalys                0.00      1.44 #> ICER                    NA      -Inf #> ICUR                    NA   -971.07 #> INMB                    NA  73266.50 #> costs_undisc      23836.54  23677.54 #> dcosts_undisc         0.00    159.00 #> lys_undisc           30.00     30.00 #> dlys_undisc           0.00      0.00 #> qalys_undisc          6.92      4.90 #> dqalys_undisc         0.00      2.02 #> ICER_undisc             NA       Inf #> ICUR_undisc             NA     78.75 #> INMB_undisc             NA 100797.64 #> c_default         18957.73  20353.56 #> dc_default            0.00  -1395.83 #> c_default_undisc  23836.54  23677.54 #> dc_default_undisc     0.00    159.00 #> cycle_time           30.00     30.00 #> dcycle_time           0.00      0.00 #> q_default             5.81      4.37 #> dq_default            0.00      1.44 #> q_default_undisc      6.92      4.90 #> dq_default_undisc     0.00      2.02  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))  traces <- data.table::rbindlist(results[[1]][[1]]$extradata_raw)  trace_t <- cbind(traces,  psa_ipd[rep(seq(1, nrow(psa_ipd)), each = 4)]) %>%   mutate(state = rep(seq(1:4),62))  trace_t[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) life_years <-  trace_t  %>%    group_by(arm) %>%   filter(state!=4) %>% #erase death state for LY computation   mutate(ly_final = lys*lag(trace,3L)) %>% #multiply by previous trace summarise(ly_final = sum(ly_final,na.rm = TRUE)) #get final discounted life years  life_years %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) results[[1]][[1]][[\"total_lys\"]][[\"int\"]] <- life_years$ly_final[life_years$arm==\"int\"] results[[1]][[1]][[\"total_lys\"]][[\"noint\"]] <- life_years$ly_final[life_years$arm==\"noint\"]  summary_results_det(results[[1]][[1]])  #>                        int     noint #> costs             18957.73  20353.56 #> dcosts                0.00  -1395.83 #> lys                   6.31      4.53 #> dlys                  0.00      1.78 #> qalys                 5.81      4.37 #> dqalys                0.00      1.44 #> ICER                    NA   -785.61 #> ICUR                    NA   -971.07 #> INMB                    NA  73266.50 #> costs_undisc      23836.54  23677.54 #> dcosts_undisc         0.00    159.00 #> lys_undisc           30.00     30.00 #> dlys_undisc           0.00      0.00 #> qalys_undisc          6.92      4.90 #> dqalys_undisc         0.00      2.02 #> ICER_undisc             NA       Inf #> ICUR_undisc             NA     78.75 #> INMB_undisc             NA 100797.64 #> c_default         18957.73  20353.56 #> dc_default            0.00  -1395.83 #> c_default_undisc  23836.54  23677.54 #> dc_default_undisc     0.00    159.00 #> cycle_time           30.00     30.00 #> dcycle_time           0.00      0.00 #> q_default             5.81      4.37 #> dq_default            0.00      1.44 #> q_default_undisc      6.92      4.90 #> dq_default_undisc     0.00      2.02"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_markov.html","id":"plots","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Plots","title":"Example for a Markov Model","text":"now use data plot traces.","code":"ggplot(trace_t,aes(x=evttime,y = trace,col=arm)) + geom_line() + facet_wrap(~state)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example for a Sick-Sicker-Dead model","text":"document runs discrete event simulation model context late oncology model show functions can used generate model steps. running DES, ’s important consider speed. Simulation based models can computationally expensive, means using efficient coding can substantial impact performance.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Example for a Sick-Sicker-Dead model","text":"","code":"library(WARDEN)  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows library(purrr) options(scipen = 999) options(digits=3) options(tibble.print_max = 50)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Example for a Sick-Sicker-Dead model","text":"Initial inputs flags used model can defined . can define inputs change across scenarios (sensitivity_inputs), inputs common patients (common_all_inputs) within simulation, inputs unique patient independently treatment (e.g. natural time death, defined common_pt_inputs), inputs unique patient treatment (unique_pt_inputs). Items can included add_item add_item2 functions, can used subsequent items. inputs generated events reaction events executed. Furthermore, program first executes common_all_inputs, common_pt_inputs unique_pt_inputs. one use items generated common_all_inputs unique_pt_inputs. Note inputs “reset” patient, patient 1 arm “noint” changes util.sick = 2, even ’s common parameter everyone, reset 1 patient 1 arm “int”. Note time death set common_pt_inputs, also just set add_tte function explained . user full flexibility implement type inputs. auxiliary functions help setting inputs, like pick_val_v pick_val (pick_psa, see section Sensitivity Analysis). Note pick_val_v pick_val can directly loaded parameters (fact, named list loaded directly R). small tweak needed ’s first item added, item list must initiated using add_item() (see ). Alternatively, using add_item2(), needed, pick_val_v just needs used additional argument deploy_env = TRUE.","code":"#We don't need to use sensitivity_inputs here, so we don't add that object  #Put objects here that do not change on any patient or intervention loop #We use add_item2 and add_item to showcase how the user can implement the inputs (either works, add_item2 is just faster) common_all_inputs <-add_item2(input = {                       util.sick   <- 0.8                       util.sicker <- 0.5                       cost.sick   <- 3000                       cost.sicker <- 7000                       cost.int    <- 1000                       coef_noint  <- log(0.2)                       HR_int      <- 0.8                       drc         <- 0.035 #different values than what's assumed by default                       drq         <- 0.035                       random_seed_sicker_i <- sample.int(100000,npats,replace = FALSE) })  #to be used as seeds to draw the time to event for sicker, to ensure same luck for the same patient independently of the arm   #Put objects here that do not change as we loop through treatments for a patient common_pt_inputs <- add_item(death= max(0.0000001,rnorm(n=1, mean=12, sd=3)))   #Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s) unique_pt_inputs <- add_item(fl.sick = 1,                              q_default = util.sick,                              c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example for a Sick-Sicker-Dead model","text":"Events added add_tte function. use function applying interventions. must define several arguments: one indicate intervention, one define names events used, one define names objects created like store (optional, maybe generate intermediate input event want save) actual input generate time event. Events objects automatically initialized Inf. draw times event patients. Note: order evts argument appears first used reference order process events case ties (“sick” processed “sicker” tie time event.) Note model use evnets defined evts argument look objects defined input list expression allocate time events. event declared evts defined elsewhere, assumed TTE Inf default. chunk bit complex, ’s worth spending bit time explaining . init_event_list object populated using add_tte function applies arms, “int” strategy “noint” strategy. first declare start time 0. Note also separated arm user wants clarity using two add_tte functions (.e., add_tte(arm=\"noint\"...) %>% add_tte(arm=\"int\"...)). proceed generate actual time event. use draw_tte() function generate time event, though one can set way (e.g., using rexp). One always aware competing risks interact . abstracted type corrections , recommended understanding affect results look competing risks/semi-competing risks literature.","code":"init_event_list <-    add_tte(arm=c(\"noint\",\"int\"), evts = c(\"sick\",\"sicker\",\"death\") ,input={     sick <- 0     sicker <- draw_tte(1,dist=\"exp\", coef1=coef_noint, beta_tx = ifelse(arm==\"int\",HR_int,1), seed = random_seed_sicker_i[i]) #this way the value would be the same if it wasn't for the HR, effectively \"cloning\" patients luck        })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Example for a Sick-Sicker-Dead model","text":"initial times events defined, also need declare events react affect . , use evt_react_list object add_reactevt function. function just needs state event affected, actual reaction (usually setting flags 1 0, creating new/adjusting events). series objects can used context help reactions. Apart global objects flags defined , can also use curtime current event time, prevtime time previous event, cur_evtlist named vector events yet happen patient, arm current treatment loop, evt current event processed, expresses patient iteration, simulation specific simulation (relevant number simulations greater 1). Furthermore, one can also call input/item created create new ones. example, even modify cost/utility item changing directly, e.g. modify_item(list(cost.idfs.tx=500)) assigning directly cost.idfs.tx <- 500. functions add/modify events inputs use lists. Whenever several inputs/events added modified, ’s recommended group within one function, reduces computation cost. rather use two modify_event list one element, ’s better group single modify_event list two elements. new_eventallows generate events add vector events. accepts one event. modify_event allows modify events (e.g. delay death). adding event, name events time events must defined. using modify_event, one must indicate events affected new times events. event specified exist already occurred, ignored. modify_event create_if_null = TRUE argument also generate events don’t exist. Note one potentially omit part modeling set init_event_list actually define new events dynamically reactions (\"ae\" event). However, can impact computation time, possible ’s always better use init_event_list. modify/create items, WARDEN now allows assign directly code, without need use modify_item modify_item_seq, allows code run faster (~30-35% faster comparing modify_item_seq, 15-20% comparing modify_item). However, two functions, modify_item modify_item_seq, still available user keep working, allow modify add items. Elements defined within function evaluated sequentially modify_item (.e. defining modify_item(list(fl.new = 1, var1 = fl.new * 5))) give error fl.new defined outside function), modify_item_seq sequentially slightly bigger computational cost, left choices user. Note one can modify costs/utilities using construction type_name_category, type either “qaly” “cost”, name name (e.g., “default”) category category used (e.g., “instant”), one pass cost_default_instant modify cost. list relevant functions used within add_reactevt : model run curtime set Inf, event terminates model (case, os), modify curtime set Inf. Finally, note two different ways accumulating continuous outcomes, backwards (.e., example , set q_default = util.sick sicker event, modify q_default value death event) forwards (example ). option can modified run_sim function using accum_backwards argument, assumes forwards default.","code":"evt_react_list <-   add_reactevt(name_evt = \"sick\",                input = {}) %>%   add_reactevt(name_evt = \"sicker\",                input = {                  q_default <- util.sicker                  c_default <- cost.sicker + if(arm==\"int\"){cost.int}else{0}                  fl.sick   <- 0                 }) %>%   add_reactevt(name_evt = \"death\",                input = {                  q_default <- 0                  c_default <- 0                  curtime   <- Inf                })    # Below how it would be set up if using `accum_backwards = TRUE` in `run_sim()` (and will give equal final results) # Note that we set the value applied in the reaction right up to the event, changing the interpretation of the reaction # It is also a slower method than the standard approach # In this case we use `modify_item_seq` in the reaction for death, but given that the items are not interacting with each other, # we could use `modify_item` instead and make the computation faster # # evt_react_list <- #     add_reactevt(name_evt = \"sick\", #                  input = {}) %>% #     add_reactevt(name_evt = \"sicker\", #                  input = { #                      modify_item(list( #                      q_default = util.sick, #                      c_default = cost.sick + if(arm==\"int\"){cost.int}else{0}, #                      fl.sick = 0 #                      )) #                  }) %>% #     add_reactevt(name_evt = \"death\", #                  input = { #                      c_dis <- if(fl.sick==1){cost.sick}else{cost.sicker}  #                      modify_item_seq(list( #                      q_default = if(fl.sick==1){util.sick}else{util.sicker}, #                      c_default = c_dis + if(arm==\"int\"){cost.int}else{0}, #                      curtime = Inf #                      )) #                  })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"extract-interactions-within-events","dir":"Articles","previous_headings":"Events > Add Reaction to Those Events","what":"Extract Interactions Within Events","title":"Example for a Sick-Sicker-Dead model","text":"additional optional step, easily see interactions reactions events, can also now use extract_from_reactions function obtain data.frame relationships defined reactions model. functions looks assignments (<- = assign), modify_item, modify_item_seq, modify_event new_event checks elements defined , definition, whether triggered conditionally (e.g., \"(==1){modify_item(list(b=2))}\"). Note straightforward build network graph showcasing interactions events terms events affecting events, show () events affect specific items.","code":"df_interactions <- extract_from_reactions(evt_react_list)  kable(df_interactions)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Example for a Sick-Sicker-Dead model","text":"Costs utilities introduced . However, ’s worth noting model able run without costs utilities. Utilities/Costs/outputs defined declaring object belongs utilities/costs/outputs, whether need discounted continuously discretely (instantaneous). passed run_sim function.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"utilities","dir":"Articles","previous_headings":"Costs and Utilities","what":"Utilities","title":"Example for a Sick-Sicker-Dead model","text":"","code":"util_ongoing <- \"q_default\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example for a Sick-Sicker-Dead model","text":"","code":"cost_ongoing <- \"c_default\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model","text":"model can run using function run_sim . must define number patients simulated, number simulations, whether want run PSA , strategy list, inputs, events reactions defined , utilities, costs also want extra output level ipd data desired exported. worth noting psa_bool argument run PSA automatically, rather additional input/flag model use reference determine whether want use deterministic stochastic input. , also defined common_all_inputs first item defined, result . However, recommend defined run_sim. Note distribution chosen, number events interaction events can substantial impact running time model. Debugging can implemented using argument debug run_sim function.","code":"#Logic is: per patient, per intervention, per event, react to that event. results <- run_sim(     npats=1000,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.72s #> Time to run analysis 1: 0.72s #> Total time to run: 0.72s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example for a Sick-Sicker-Dead model","text":"model run, can use results summarize using summary_results_det print results last simulation (nsim = 1, ’s deterministic case), summary_results_sim show PSA results (confidence intervals). can also use individual patient data generated simulation, collect plot psa_ipd object. can also check absolute number events per strategy.","code":"summary_results_det(results[[1]][[1]]) #print first simulation #>                        int    noint #> costs             58978.88 51768.23 #> dcosts                0.00  7210.66 #> lys                   9.72     9.72 #> dlys                  0.00     0.00 #> qalys                 6.27     6.08 #> dqalys                0.00     0.19 #> ICER                    NA      Inf #> ICUR                    NA 38286.46 #> INMB                    NA  2206.06 #> costs_undisc      74324.03 65474.81 #> dcosts_undisc         0.00  8849.22 #> lys_undisc           11.99    11.99 #> dlys_undisc           0.00     0.00 #> qalys_undisc          7.62     7.38 #> dqalys_undisc         0.00     0.24 #> ICER_undisc             NA      Inf #> ICUR_undisc             NA 37557.56 #> INMB_undisc             NA  2931.65 #> c_default         58978.88 51768.23 #> dc_default            0.00  7210.66 #> c_default_undisc  74324.03 65474.81 #> dc_default_undisc     0.00  8849.22 #> q_default             6.27     6.08 #> dq_default            0.00     0.19 #> q_default_undisc      7.62     7.38 #> dq_default_undisc     0.00     0.24  summary_results_sim(results[[1]]) #>                                       int                   noint #> costs             58,979 (58,979; 58,979) 51,768 (51,768; 51,768) #> dcosts                           0 (0; 0)    7,211 (7,211; 7,211) #> lys                     9.72 (9.72; 9.72)       9.72 (9.72; 9.72) #> dlys                             0 (0; 0)                0 (0; 0) #> qalys                   6.27 (6.27; 6.27)       6.08 (6.08; 6.08) #> dqalys                           0 (0; 0)    0.188 (0.188; 0.188) #> ICER                         NaN (NA; NA)          Inf (Inf; Inf) #> ICUR                         NaN (NA; NA) 38,286 (38,286; 38,286) #> INMB                         NaN (NA; NA)    2,206 (2,206; 2,206) #> costs_undisc      74,324 (74,324; 74,324) 65,475 (65,475; 65,475) #> dcosts_undisc                    0 (0; 0)    8,849 (8,849; 8,849) #> lys_undisc                    12 (12; 12)             12 (12; 12) #> dlys_undisc                      0 (0; 0)                0 (0; 0) #> qalys_undisc            7.62 (7.62; 7.62)       7.38 (7.38; 7.38) #> dqalys_undisc                    0 (0; 0)    0.236 (0.236; 0.236) #> ICER_undisc                  NaN (NA; NA)          Inf (Inf; Inf) #> ICUR_undisc                  NaN (NA; NA) 37,558 (37,558; 37,558) #> INMB_undisc                  NaN (NA; NA)    2,932 (2,932; 2,932) #> c_default         58,979 (58,979; 58,979) 51,768 (51,768; 51,768) #> dc_default                       0 (0; 0)    7,211 (7,211; 7,211) #> c_default_undisc  74,324 (74,324; 74,324) 65,475 (65,475; 65,475) #> dc_default_undisc                0 (0; 0)    8,849 (8,849; 8,849) #> q_default               6.27 (6.27; 6.27)       6.08 (6.08; 6.08) #> dq_default                       0 (0; 0)    0.188 (0.188; 0.188) #> q_default_undisc        7.62 (7.62; 7.62)       7.38 (7.38; 7.38) #> dq_default_undisc                0 (0; 0)    0.236 (0.236; 0.236)  summary_results_sens(results) #>        arm analysis analysis_name          variable                   value #>     <char>    <int>        <char>            <fctr>                  <char> #>  1:    int        1                           costs 58,979 (58,979; 58,979) #>  2:  noint        1                           costs 51,768 (51,768; 51,768) #>  3:    int        1                          dcosts                0 (0; 0) #>  4:  noint        1                          dcosts    7,211 (7,211; 7,211) #>  5:    int        1                             lys       9.72 (9.72; 9.72) #>  6:  noint        1                             lys       9.72 (9.72; 9.72) #>  7:    int        1                            dlys                0 (0; 0) #>  8:  noint        1                            dlys                0 (0; 0) #>  9:    int        1                           qalys       6.27 (6.27; 6.27) #> 10:  noint        1                           qalys       6.08 (6.08; 6.08) #> 11:    int        1                          dqalys                0 (0; 0) #> 12:  noint        1                          dqalys    0.188 (0.188; 0.188) #> 13:    int        1                            ICER            NaN (NA; NA) #> 14:  noint        1                            ICER          Inf (Inf; Inf) #> 15:    int        1                            ICUR            NaN (NA; NA) #> 16:  noint        1                            ICUR 38,286 (38,286; 38,286) #> 17:    int        1                            INMB            NaN (NA; NA) #> 18:  noint        1                            INMB    2,206 (2,206; 2,206) #> 19:    int        1                    costs_undisc 74,324 (74,324; 74,324) #> 20:  noint        1                    costs_undisc 65,475 (65,475; 65,475) #> 21:    int        1                   dcosts_undisc                0 (0; 0) #> 22:  noint        1                   dcosts_undisc    8,849 (8,849; 8,849) #> 23:    int        1                      lys_undisc             12 (12; 12) #> 24:  noint        1                      lys_undisc             12 (12; 12) #> 25:    int        1                     dlys_undisc                0 (0; 0) #> 26:  noint        1                     dlys_undisc                0 (0; 0) #> 27:    int        1                    qalys_undisc       7.62 (7.62; 7.62) #> 28:  noint        1                    qalys_undisc       7.38 (7.38; 7.38) #> 29:    int        1                   dqalys_undisc                0 (0; 0) #> 30:  noint        1                   dqalys_undisc    0.236 (0.236; 0.236) #> 31:    int        1                     ICER_undisc            NaN (NA; NA) #> 32:  noint        1                     ICER_undisc          Inf (Inf; Inf) #> 33:    int        1                     ICUR_undisc            NaN (NA; NA) #> 34:  noint        1                     ICUR_undisc 37,558 (37,558; 37,558) #> 35:    int        1                     INMB_undisc            NaN (NA; NA) #> 36:  noint        1                     INMB_undisc    2,932 (2,932; 2,932) #> 37:    int        1                       c_default 58,979 (58,979; 58,979) #> 38:  noint        1                       c_default 51,768 (51,768; 51,768) #> 39:    int        1                      dc_default                0 (0; 0) #> 40:  noint        1                      dc_default    7,211 (7,211; 7,211) #> 41:    int        1                c_default_undisc 74,324 (74,324; 74,324) #> 42:  noint        1                c_default_undisc 65,475 (65,475; 65,475) #> 43:    int        1               dc_default_undisc                0 (0; 0) #> 44:  noint        1               dc_default_undisc    8,849 (8,849; 8,849) #> 45:    int        1                       q_default       6.27 (6.27; 6.27) #> 46:  noint        1                       q_default       6.08 (6.08; 6.08) #> 47:    int        1                      dq_default                0 (0; 0) #> 48:  noint        1                      dq_default    0.188 (0.188; 0.188) #> 49:    int        1                q_default_undisc       7.62 (7.62; 7.62) #> 50:  noint        1                q_default_undisc       7.38 (7.38; 7.38) #> 51:    int        1               dq_default_undisc                0 (0; 0) #> 52:  noint        1               dq_default_undisc    0.236 (0.236; 0.236) #>        arm analysis analysis_name          variable                   value  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))   psa_ipd[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"plots","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Plots","title":"Example for a Sick-Sicker-Dead model","text":"now use data output plot histograms/densities simulation.  can also plot patient level incremental QALY/costs.","code":"data_plot <- results[[1]][[1]]$merged_df %>%   filter(evtname != \"sick\") %>%   group_by(arm,evtname,simulation) %>%   mutate(median = median(evttime)) %>%   ungroup()  ggplot(data_plot) +   geom_density(aes(fill = arm, x = evttime),                alpha = 0.7) +   geom_vline(aes(xintercept=median,col=arm)) +   facet_wrap( ~ evtname, scales = \"free\") +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw() data_qaly_cost<- psa_ipd[,.SD[1],by=.(pat_id,arm,simulation)][,.(arm,qaly=total_qalys,cost=total_costs,pat_id,simulation)] data_qaly_cost[,ps_id:=paste(pat_id,simulation,sep=\"_\")]   mean_data_qaly_cost <- data_qaly_cost %>% group_by(arm) %>% summarise(across(where(is.numeric),mean))  ggplot(data_qaly_cost,aes(x=qaly, y = cost, col = arm)) +    geom_point(alpha=0.15,shape = 21) +   geom_point(data=mean_data_qaly_cost, aes(x=qaly, y = cost, fill = arm), shape = 21,col=\"black\",size=3) +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw()+   theme(axis.text.x = element_text(angle = 90, vjust = .5))"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"inputs","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Inputs","title":"Example for a Sick-Sicker-Dead model","text":"case, inputs must created first change across sensitivity analysis. , item list sensitivity_inputs can used. case, also use pick_val_v allows model automatically pick relevant value (PSA, PSA sensitivity analysis) based corresponding boolean flags psa_bool sensitivity_bool. case also use sens iterator sensitivity analysis n_sensitivity argument run_sim. Note just changed inputs handled common_all_inputs, done unique_pt_inputs, cases, inputs change per patient, pick_val_v pick_val functions applied within unique_pt_inputs make sure evaluated correspond. Note psa directly calling distributions passing parameters.Note also sens_name_used automatically computed engine accesible user (’s name sensitivity analysis, e.g., “scenario 1”). indicator parameter pick_val_v pick_val used determine parameters left “” ones substituted sensitivity value. two ways , either setting binary way (1 0), using indicator number parameter values varied (useful several parameters varied time, specific values vector varied). can set using indicator_sens_binary argument. Note pick_val_v pick_val can directly loaded parameters (fact, named list loaded directly R). small tweak needed ’s first item added, item list must initiated using add_item() (see ). Note one can use list lists case base_value parameters vectors instead elements length 1. case, showcase list also use data.frame. pick_psa can used select correct PSA distributions.","code":"#Load some data list_par <- list(parameter_name = list(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),                               base_value = list(0.8,0.5,3000,7000,1000,log(0.2),0.8),                               DSA_min = list(0.6,0.3,1000,5000,800,log(0.1),0.5),                               DSA_max = list(0.9,0.7,5000,9000,2000,log(0.4),0.9),                               PSA_dist = list(\"rnorm\",\"rbeta_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rnorm\",\"rlnorm\"),                               a=list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)),                               b=lapply(list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)), function(x) abs(x/5)),                               scenario_1=list(0.6,0.3,1000,5000,800,log(0.1),0.5),                               scenario_2=list(0.9,0.7,5000,9000,2000,log(0.4),0.9)                               )  sensitivity_inputs <-add_item(             indicators = if(sensitivity_bool){ create_indicators(sens,n_sensitivity*length(sensitivity_names),rep(1,length(list_par[[1]])))}else{                                 rep(1,length(list_par[[1]]))} #vector of indicators, value 0 everywhere except at sens, where it takes value 1 (for dsa_min and dsa_max, if not sensitivity analysis, then we activate all of them, i.e., in a PSA)                               )  common_all_inputs <-add_item() %>%    add_item(             pick_val_v(base        = list_par[[\"base_value\"]],                        psa         = pick_psa(list_par[[\"PSA_dist\"]],rep(1,length(list_par[[\"PSA_dist\"]])),list_par[[\"a\"]],list_par[[\"b\"]]),                        sens        = list_par[[sens_name_used]],                        psa_ind     = psa_bool,                        sens_ind    = sensitivity_bool,                        indicator   = indicators,                        names_out   = list_par[[\"parameter_name\"]]                        )             ) %>%   add_item(random_seed_sicker_i = sample(1:1000,1000,replace = FALSE)) #we don't add this variable ot the sensitivity analysis"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"model-execution-1","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model","text":"model executed , just adding sensitivity_inputs, sensitivity_names, sensitivity_bool n_sensitivity arguments. Note total number sensitivity iterations given n_sensitivity, n_sensitivity * length(sensitivity_names), case 2 x n_sensitivity, 2 x 7 = 14. two scenario analysis 2 x 1 = 2, indicators variable defined previous section taking value 1 variables altered scenario, 0 otherwise.","code":"results <- run_sim(     npats=100,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   sensitivity_inputs = sensitivity_inputs,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(list_par[[1]]),   input_out = unlist(list_par[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 1: 0.13s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 2: 0.12s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 3: 0.13s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 4: 0.12s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 5: 0.13s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 6: 0.12s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 7: 0.13s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 8: 0.13s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 9: 0.13s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Time to run analysis 10: 0.14s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 11: 0.12s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 12: 0.13s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 13: 0.12s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 14: 0.13s #> Total time to run: 1.8s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"check-results","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Check results","title":"Example for a Sick-Sicker-Dead model","text":"briefly check indeed engine changing corresponding parameter value.","code":"data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))  #Check mean value across iterations as PSA is off data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean) #> # A tibble: 14 × 8 #>    sensitivity util.sick util.sicker cost.sick cost.sicker cost.int coef_noint #>          <int>     <dbl>       <dbl>     <dbl>       <dbl>    <dbl>      <dbl> #>  1           1       0.6         0.5      3000        7000     1000      -1.61 #>  2           2       0.8         0.3      3000        7000     1000      -1.61 #>  3           3       0.8         0.5      1000        7000     1000      -1.61 #>  4           4       0.8         0.5      3000        5000     1000      -1.61 #>  5           5       0.8         0.5      3000        7000      800      -1.61 #>  6           6       0.8         0.5      3000        7000     1000      -2.30 #>  7           7       0.8         0.5      3000        7000     1000      -1.61 #>  8           8       0.8         0.5      3000        7000     1000      -1.61 #>  9           9       0.8         0.5      3000        7000     1000      -1.61 #> 10          10       0.8         0.5      3000        7000     1000      -1.61 #> 11          11       0.8         0.5      3000        7000     1000      -1.61 #> 12          12       0.8         0.5      3000        7000     1000      -1.61 #> 13          13       0.8         0.5      3000        7000     1000      -1.61 #> 14          14       0.8         0.5      3000        7000     1000      -1.61 #> # ℹ 1 more variable: HR_int <dbl>"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"model-execution-probabilistic-dsa","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Model Execution, probabilistic DSA","title":"Example for a Sick-Sicker-Dead model","text":"model executed , just activating psa_bool option","code":"results <- run_sim(     npats=100,                                  n_sim=6,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = common_all_inputs,       common_pt_inputs = common_pt_inputs,         unique_pt_inputs = unique_pt_inputs,         init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   sensitivity_inputs = sensitivity_inputs,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(list_par[[1]]),   input_out = unlist(list_par[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.15s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 1: 0.79s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.15s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 2: 0.78s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.12s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 3: 0.76s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 4: 0.78s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 5: 0.8s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 6: 0.78s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.14s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.14s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 7: 0.82s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.16s #> Simulation number: 2 #> Time to run simulation 2: 0.14s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.14s #> Time to run analysis 8: 0.84s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.31s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.12s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 9: 0.92s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 10: 0.75s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 11: 0.77s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 12: 0.77s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 13: 0.77s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 14: 0.79s #> Total time to run: 11.12s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"check-results-1","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Check results","title":"Example for a Sick-Sicker-Dead model","text":"briefly check indeed engine changing corresponding parameter value.","code":"data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))  #Check mean value across iterations as PSA is off data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean) #> # A tibble: 14 × 8 #>    sensitivity util.sick util.sicker cost.sick cost.sicker cost.int coef_noint #>          <int>     <dbl>       <dbl>     <dbl>       <dbl>    <dbl>      <dbl> #>  1           1     0.6         0.580     3156.       7974.    1061.      -1.61 #>  2           2     0.722       0.3       3156.       7974.    1061.      -1.61 #>  3           3     0.722       0.580     1000        7974.    1061.      -1.61 #>  4           4     0.722       0.580     3156.       5000     1061.      -1.61 #>  5           5     0.722       0.580     3156.       7974.     800       -1.61 #>  6           6     0.725       0.579     3140.       7957.    1065.      -2.30 #>  7           7     0.722       0.580     3155.       7973.    1061.      -1.62 #>  8           8     0.722       0.580     3156.       7974.    1061.      -1.61 #>  9           9     0.722       0.580     3156.       7974.    1061.      -1.61 #> 10          10     0.722       0.580     3156.       7974.    1061.      -1.61 #> 11          11     0.722       0.580     3156.       7974.    1061.      -1.61 #> 12          12     0.722       0.580     3156.       7974.    1061.      -1.61 #> 13          13     0.722       0.580     3156.       7974.    1061.      -1.61 #> 14          14     0.722       0.580     3156.       7974.    1061.      -1.61 #> # ℹ 1 more variable: HR_int <dbl>"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"model-execution-simple-psa","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Model Execution, Simple PSA","title":"Example for a Sick-Sicker-Dead model","text":"model executed , just activating psa_bool option deactivating sensitivity_bool removing sensitivity_names setting n_sensitivity = 1","code":"results <- run_sim(     npats=100,                                  n_sim=10,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = common_all_inputs,       common_pt_inputs = common_pt_inputs,         unique_pt_inputs = unique_pt_inputs,         init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   sensitivity_inputs = sensitivity_inputs,   sensitivity_bool = FALSE,   n_sensitivity = 1,   input_out = unlist(list_par[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.31s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Simulation number: 7 #> Time to run simulation 7: 0.12s #> Simulation number: 8 #> Time to run simulation 8: 0.13s #> Simulation number: 9 #> Time to run simulation 9: 0.12s #> Simulation number: 10 #> Time to run simulation 10: 0.13s #> Time to run analysis 1: 1.47s #> Total time to run: 1.47s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd.html","id":"check-results-2","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Check results","title":"Example for a Sick-Sicker-Dead model","text":"briefly check indeed engine changing corresponding parameter values.","code":"data_simulation <- bind_rows(map_depth(results,2, \"merged_df\"))  #Check mean value across iterations as PSA is off data_simulation %>% group_by(simulation) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean) #> # A tibble: 10 × 8 #>    simulation util.sick util.sicker cost.sick cost.sicker cost.int coef_noint #>         <int>     <dbl>       <dbl>     <dbl>       <dbl>    <dbl>      <dbl> #>  1          1     0.528       0.563     5010.       9352.    1073.      -1.43 #>  2          2     0.666       0.544     3065.       7914.     808.      -1.07 #>  3          3     0.742       0.526     2393.       7690.    1323.      -1.99 #>  4          4     0.727       0.767     2491.       8069.    1009.      -1.34 #>  5          5     0.808       0.570     4021.       7834.    1026.      -1.93 #>  6          6     0.874       0.501     1881.       6913.    1158.      -2.01 #>  7          7     0.859       0.457     2730.       9349.    1264.      -1.70 #>  8          8     0.935       0.438     3954.       6225.     813.      -1.35 #>  9          9     0.886       0.648     3104.       7909.     695.      -1.75 #> 10         10     0.870       0.576     3952.       6264.    1176.      -1.52 #> # ℹ 1 more variable: HR_int <dbl>"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"main-options","dir":"Articles","previous_headings":"","what":"Main options","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"","code":"library(WARDEN)  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows library(purrr) if(!require(randtoolbox)){     install.packages(\"randtoolbox\")     library(randtoolbox) } #> Loading required package: randtoolbox #> Loading required package: rngWELL #> This is randtoolbox. For an overview, type 'help(\"randtoolbox\")'. options(scipen = 999) options(digits=3) options(tibble.print_max = 50)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"document runs discrete event simulation model context late oncology model show using quasi-random numbers can radically change convergence speed using quasi-random sobol sequences instead purely random numbers. Sobol sequences deterministic way generating numbers (0 1) way fills space evenly. Several methods can used randomize generation sequences, create multiple dimensions want multiple variables using sequences. Sobol sequences can fill space evenly random uniform distribution, can make model converge faster. vignette explores one can use sobol sequences accelerate convergence reduce number profiles needed.  running DES, ’s important consider speed. Simulation based models can computationally expensive, means using efficient coding can substantial impact performance.","code":"n_points <- 500  sobol_seq <- randtoolbox::sobol(n = n_points, dim = 2) random_points <- matrix(runif(n_points * 2), ncol = 2)  sobol_df <- data.frame(x = sobol_seq[, 1], y = sobol_seq[, 2], Type = \"Sobol\") random_df <- data.frame(x = random_points[, 1], y = random_points[, 2], Type = \"Random Uniform\")  combined_df <- rbind(sobol_df, random_df)  ggplot(combined_df, aes(x = x, y = y, color = Type)) +   geom_point(alpha = 0.7, size = 1) +   facet_wrap(~Type) +   theme_bw() +    labs(     title = \"Comparison of Sobol Sequence vs Random Uniform Sampling\"   ) +   theme(legend.position = \"none\")"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"generate inputs, create two versions, one random numbers generated uniform variable, another generated sobol sequence.","code":"randtoolbox::sobol(1,2, init = TRUE) #initialize #>      [,1] [,2] #> [1,]  0.5  0.5 N <- 500 sims <- 5 common_all_inputs <-add_item(                       util.sick = 0.8,                       util.sicker = 0.5,                       cost.sick = 3000,                       cost.sicker = 7000,                       cost.int = 1000,                       coef_noint = log(0.2),                       HR_int = 0.8,                       drc = 0.035,                        drq = 0.035                       )  common_all_inputs_unif <- common_all_inputs %>%   add_item(random_n = runif(N),            random_n_death = runif(N)) #we draw N random uniform samples  common_all_inputs_sobol <- common_all_inputs %>%   add_item(random_sobol = (randtoolbox::sobol(N,2, init = TRUE) + matrix(rep(runif(2), each = N), nrow = N, byrow = TRUE)) %% 1,            random_n = random_sobol[,1],            random_n_death = random_sobol[,2])  #we draw n sobol sequences, we need to do a small trick as scrambling and seeds are temporarely deactivated within the randtoolbox package  common_pt_inputs <- add_item(death= max(0.0000001,qnorm(random_n_death[i], mean=12, sd=3)))  #use random number for death to draw from a normal distribution  unique_pt_inputs <- add_item(fl.sick = 1,                              q_default = util.sick,                              c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"Time event exponential drawn using random number","code":"init_event_list <-    add_tte(arm=c(\"noint\",\"int\"), evts = c(\"sick\",\"sicker\",\"death\") ,input={     sick <- 0     sicker <- qexp(random_n[i], rate = exp(coef_noint + log(ifelse(arm==\"int\",HR_int,1)))) #draw the TTE using the random number we created        })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"","code":"evt_react_list <-   add_reactevt(name_evt = \"sick\",                input = {}) %>%   add_reactevt(name_evt = \"sicker\",                input = {                  q_default <- util.sicker                  c_default <- cost.sicker + if(arm==\"int\"){cost.int}else{0}                  fl.sick <- 0                }) %>%   add_reactevt(name_evt = \"death\",                input = {                  q_default <- 0                  c_default <- 0                   curtime <- Inf                 })"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"utilities","dir":"Articles","previous_headings":"Costs and Utilities","what":"Utilities","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"","code":"util_ongoing <- \"q_default\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"","code":"cost_ongoing <- \"c_default\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"run versions model simulations showcase different speed convergence.","code":"results_unif <- run_sim(     npats=N,                                  n_sim=sims,                                     psa_bool = FALSE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = common_all_inputs_unif,       common_pt_inputs = common_pt_inputs,          unique_pt_inputs = unique_pt_inputs,          init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 2,   seed = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 0.43s #> Simulation number: 2 #> Time to run simulation 2: 0.53s #> Simulation number: 3 #> Time to run simulation 3: 0.34s #> Simulation number: 4 #> Time to run simulation 4: 0.49s #> Simulation number: 5 #> Time to run simulation 5: 0.35s #> Time to run analysis 1: 2.13s #> Total time to run: 2.13s  results_sobol <- run_sim(     npats=N,                                  n_sim=sims,                                     psa_bool = FALSE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = common_all_inputs_sobol,       common_pt_inputs = common_pt_inputs,          unique_pt_inputs = unique_pt_inputs,          init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 2,   seed = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 0.33s #> Simulation number: 2 #> Time to run simulation 2: 0.34s #> Simulation number: 3 #> Time to run simulation 3: 0.34s #> Simulation number: 4 #> Time to run simulation 4: 0.34s #> Simulation number: 5 #> Time to run simulation 5: 0.36s #> Time to run analysis 1: 1.71s #> Total time to run: 1.71s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"models run, merge data generate cumulative ICER see fast converge final estimated value. can clearly seen random uniform approach makes model converge much slowly sobol sequences.","code":"summary_results_sim(results_unif[[1]])  #>                                       int                   noint #> costs             59,311 (57,800; 61,194) 52,090 (50,768; 53,725) #> dcosts                           0 (0; 0)    7,220 (7,033; 7,469) #> lys                     9.73 (9.59; 9.91)       9.73 (9.59; 9.91) #> dlys                             0 (0; 0)                0 (0; 0) #> qalys                   6.26 (6.19; 6.39)           6.07 (6; 6.2) #> dqalys                           0 (0; 0)    0.188 (0.178; 0.197) #> ICER                         NaN (NA; NA)          Inf (Inf; Inf) #> ICUR                         NaN (NA; NA) 38,402 (36,651; 42,023) #> INMB                         NaN (NA; NA)    2,201 (1,419; 2,604) #> costs_undisc      74,738 (72,422; 77,338) 65,881 (63,864; 68,132) #> dcosts_undisc                    0 (0; 0)    8,857 (8,558; 9,206) #> lys_undisc                12 (11.8; 12.3)         12 (11.8; 12.3) #> dlys_undisc                      0 (0; 0)                0 (0; 0) #> qalys_undisc              7.6 (7.49; 7.8)       7.37 (7.26; 7.55) #> dqalys_undisc                    0 (0; 0)    0.236 (0.223; 0.249) #> ICER_undisc                  NaN (NA; NA)          Inf (Inf; Inf) #> ICUR_undisc                  NaN (NA; NA) 37,578 (35,380; 41,293) #> INMB_undisc                  NaN (NA; NA)    2,956 (1,942; 3,550) #> c_default         59,311 (57,800; 61,194) 52,090 (50,768; 53,725) #> dc_default                       0 (0; 0)    7,220 (7,033; 7,469) #> c_default_undisc  74,738 (72,422; 77,338) 65,881 (63,864; 68,132) #> dc_default_undisc                0 (0; 0)    8,857 (8,558; 9,206) #> q_default               6.26 (6.19; 6.39)           6.07 (6; 6.2) #> dq_default                       0 (0; 0)    0.188 (0.178; 0.197) #> q_default_undisc          7.6 (7.49; 7.8)       7.37 (7.26; 7.55) #> dq_default_undisc                0 (0; 0)    0.236 (0.223; 0.249) summary_results_sim(results_sobol[[1]])  #>                                       int                   noint #> costs             59,690 (59,529; 59,855) 52,398 (52,243; 52,536) #> dcosts                           0 (0; 0)    7,292 (7,257; 7,319) #> lys                     9.74 (9.72; 9.77)       9.74 (9.72; 9.77) #> dlys                             0 (0; 0)                0 (0; 0) #> qalys                   6.24 (6.23; 6.26)       6.06 (6.04; 6.08) #> dqalys                           0 (0; 0)    0.184 (0.183; 0.185) #> ICER                         NaN (NA; NA)          Inf (Inf; Inf) #> ICUR                         NaN (NA; NA) 39,650 (39,204; 39,964) #> INMB                         NaN (NA; NA)    1,904 (1,835; 1,998) #> costs_undisc      75,219 (74,967; 75,467) 66,248 (66,004; 66,457) #> dcosts_undisc                    0 (0; 0)    8,971 (8,920; 9,010) #> lys_undisc                  12 (12; 12.1)           12 (12; 12.1) #> dlys_undisc                      0 (0; 0)                0 (0; 0) #> qalys_undisc            7.58 (7.56; 7.61)       7.36 (7.33; 7.38) #> dqalys_undisc                    0 (0; 0)    0.229 (0.227; 0.231) #> ICER_undisc                  NaN (NA; NA)          Inf (Inf; Inf) #> ICUR_undisc                  NaN (NA; NA) 39,184 (38,675; 39,524) #> INMB_undisc                  NaN (NA; NA)    2,477 (2,382; 2,612) #> c_default         59,690 (59,529; 59,855) 52,398 (52,243; 52,536) #> dc_default                       0 (0; 0)    7,292 (7,257; 7,319) #> c_default_undisc  75,219 (74,967; 75,467) 66,248 (66,004; 66,457) #> dc_default_undisc                0 (0; 0)    8,971 (8,920; 9,010) #> q_default               6.24 (6.23; 6.26)       6.06 (6.04; 6.08) #> dq_default                       0 (0; 0)    0.184 (0.183; 0.185) #> q_default_undisc        7.58 (7.56; 7.61)       7.36 (7.33; 7.38) #> dq_default_undisc                0 (0; 0)    0.229 (0.227; 0.231)   det_ipd_unif <- bind_rows(map(results_unif[[1]], \"merged_df\")) %>% mutate(type = \"unif\") det_ipd_sobol <- bind_rows(map(results_sobol[[1]], \"merged_df\")) %>% mutate(type = \"sobol\")  merged_ipd <- rbind(det_ipd_unif,det_ipd_sobol) %>%   group_by(arm, type, simulation) %>%   mutate(cumul_total_qalys = cumsum(total_qalys)/pat_id,          cumul_total_costs = cumsum(total_costs)/pat_id) %>%   transmute(type, pat_id, arm, simulation, cumul_total_qalys, cumul_total_costs) %>%   tidyr::pivot_wider(names_from = arm, values_from = c(cumul_total_qalys,cumul_total_costs)) %>%   mutate(inc_costs = cumul_total_costs_int - cumul_total_costs_noint,          inc_qalys = cumul_total_qalys_int - cumul_total_qalys_noint,          ICER = inc_costs/ inc_qalys)      ggplot(merged_ipd, aes(x=pat_id,y=ICER, colour = type, fill = as.factor(simulation)))+   geom_line() +   theme_bw() +   ylim(30000,45000) #> Warning: Removed 49 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"model-execution-1","dir":"Articles","previous_headings":"Model with PSA","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"","code":"#Load some data list_par <- list(parameter_name = list(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),                               base_value = list(0.8,0.5,3000,7000,1000,log(0.2),0.8),                               DSA_min = list(0.6,0.3,1000,5000,800,log(0.1),0.5),                               DSA_max = list(0.9,0.7,5000,9000,2000,log(0.4),0.9),                               PSA_dist = list(\"qnorm\",\"qbeta_mse\",\"qgamma_mse\",\"qgamma_mse\",\"qgamma_mse\",\"qnorm\",\"qlnorm\"),                               a=list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)),                               b=lapply(list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)), function(x) abs(x/10)),                               scenario_1=list(0.6,0.3,1000,5000,800,log(0.1),0.5),                               scenario_2=list(0.9,0.7,5000,9000,2000,log(0.4),0.9)                               )  sensitivity_inputs <-add_item(             indicators = if(sensitivity_bool){ create_indicators(sens,n_sensitivity*length(sensitivity_names),rep(1,length(list_par[[1]])))}else{                                 rep(1,length(list_par[[1]]))} #vector of indicators, value 0 everywhere except at sens, where it takes value 1 (for dsa_min and dsa_max, if not sensitivity analysis, then we activate all of them, i.e., in a PSA)                               )  common_all_inputs <-  add_item(   random_sobol_psa = (randtoolbox::sobol(1,7, init = TRUE) + matrix(rep(runif(7), each = 1), nrow = 1, byrow = TRUE)) %% 1   ) %>%    add_item(             pick_val_v(base        = list_par[[\"base_value\"]],                        psa         = pick_psa(list_par[[\"PSA_dist\"]],random_sobol_psa,list_par[[\"a\"]],list_par[[\"b\"]]),                        sens        = list_par[[sens_name_used]],                        psa_ind     = psa_bool,                        sens_ind    = sensitivity_bool,                        indicator   = indicators,                        names_out   = list_par[[\"parameter_name\"]]                        )             )   common_all_inputs_unif <- common_all_inputs %>%   add_item(random_n = runif(N),            random_n_death = runif(N)) #we draw N random uniform samples  common_all_inputs_sobol <- common_all_inputs %>%   add_item(random_sobol = (randtoolbox::sobol(N,2, init = TRUE) + matrix(rep(runif(2), each = N), nrow = N, byrow = TRUE)) %% 1,            random_n = random_sobol[,1],            random_n_death = random_sobol[,2])  #we draw n sobol sequences, we need to do a small trick as scrambling and seeds are temporarely deactivated within the randtoolbox package    results_unif_psa <- run_sim(     npats=N,                                  n_sim=sims,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),   sensitivity_inputs = sensitivity_inputs,   common_all_inputs = common_all_inputs_unif,       common_pt_inputs = common_pt_inputs,          unique_pt_inputs = unique_pt_inputs,          init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 2,   seed = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 0.35s #> Simulation number: 2 #> Time to run simulation 2: 0.37s #> Simulation number: 3 #> Time to run simulation 3: 0.52s #> Simulation number: 4 #> Time to run simulation 4: 0.5s #> Simulation number: 5 #> Time to run simulation 5: 0.33s #> Time to run analysis 1: 2.08s #> Total time to run: 2.08s  results_sobol_psa <- run_sim(     npats=N,                                  n_sim=sims,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),    sensitivity_inputs = sensitivity_inputs,   common_all_inputs = common_all_inputs_sobol,       common_pt_inputs = common_pt_inputs,          unique_pt_inputs = unique_pt_inputs,          init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 2,   seed = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Patient-arm data aggregated across events by selecting the last value for input_out items. #> Time to run simulation 1: 0.34s #> Simulation number: 2 #> Time to run simulation 2: 0.34s #> Simulation number: 3 #> Time to run simulation 3: 0.34s #> Simulation number: 4 #> Time to run simulation 4: 0.34s #> Simulation number: 5 #> Time to run simulation 5: 0.54s #> Time to run analysis 1: 1.89s #> Total time to run: 1.89s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_sobol.html","id":"summary-of-results-1","dir":"Articles","previous_headings":"Post-processing of PSA Outputs","what":"Summary of Results","title":"Example for a Sick-Sicker-Dead model, Quasi-Random Sobol Sequence vs. Purely Random","text":"models run, merge data generate cumulative ICER see fast converge final estimated value. can clearly seen random uniform approach makes model converge much slowly sobol sequences.","code":"summary_results_sim(results_unif_psa[[1]])  #>                                       int                                 noint #> costs             60,135 (58,403; 63,016)               53,027 (51,497; 55,211) #> dcosts                           0 (0; 0)                  7,108 (5,994; 7,805) #> lys                       10 (9.85; 10.2)                       10 (9.85; 10.2) #> dlys                             0 (0; 0)                              0 (0; 0) #> qalys                   6.33 (5.63; 6.78)                     6.12 (5.53; 6.53) #> dqalys                           0 (0; 0)                    0.21 (0.105; 0.25) #> ICER                         NaN (NA; NA)                        Inf (Inf; Inf) #> ICUR                         NaN (NA; NA)               38,930 (24,578; 70,228) #> INMB                         NaN (NA; NA)                 3,388 (-1,708; 6,245) #> costs_undisc      73,464 (71,678; 76,647)               64,968 (62,991; 67,367) #> dcosts_undisc                    0 (0; 0)                  8,495 (7,170; 9,280) #> lys_undisc                12 (11.8; 12.3)                       12 (11.8; 12.3) #> dlys_undisc                      0 (0; 0)                              0 (0; 0) #> qalys_undisc             7.48 (6.7; 7.99)                     7.22 (6.57; 7.69) #> dqalys_undisc                    0 (0; 0)                  0.254 (0.127; 0.302) #> ICER_undisc                  NaN (NA; NA) Inf (-4,217,115,425,990,821,376; Inf) #> ICUR_undisc                  NaN (NA; NA)               38,554 (24,223; 69,703) #> INMB_undisc                  NaN (NA; NA)                 4,183 (-1,988; 7,695) #> c_default         60,135 (58,403; 63,016)               53,027 (51,497; 55,211) #> dc_default                       0 (0; 0)                  7,108 (5,994; 7,805) #> c_default_undisc  73,464 (71,678; 76,647)               64,968 (62,991; 67,367) #> dc_default_undisc                0 (0; 0)                  8,495 (7,170; 9,280) #> q_default               6.33 (5.63; 6.78)                     6.12 (5.53; 6.53) #> dq_default                       0 (0; 0)                    0.21 (0.105; 0.25) #> q_default_undisc         7.48 (6.7; 7.99)                     7.22 (6.57; 7.69) #> dq_default_undisc                0 (0; 0)                  0.254 (0.127; 0.302) summary_results_sim(results_sobol_psa[[1]])  #>                                       int                   noint #> costs             60,571 (58,122; 64,995) 53,370 (52,034; 56,982) #> dcosts                           0 (0; 0)    7,200 (6,049; 8,074) #> lys                       10 (9.99; 10.1)         10 (9.99; 10.1) #> dlys                             0 (0; 0)                0 (0; 0) #> qalys                    6.31 (5.66; 6.8)        6.1 (5.55; 6.56) #> dqalys                           0 (0; 0)    0.203 (0.105; 0.242) #> ICER                         NaN (NA; NA)          Inf (Inf; Inf) #> ICUR                         NaN (NA; NA) 40,231 (26,808; 71,510) #> INMB                         NaN (NA; NA)   2,970 (-1,776; 5,273) #> costs_undisc      73,994 (71,014; 79,434) 65,368 (63,730; 69,820) #> dcosts_undisc                    0 (0; 0)    8,626 (7,239; 9,685) #> lys_undisc                  12 (12; 12.1)           12 (12; 12.1) #> dlys_undisc                      0 (0; 0)                0 (0; 0) #> qalys_undisc            7.45 (6.73; 8.03)        7.21 (6.6; 7.74) #> dqalys_undisc                    0 (0; 0)    0.244 (0.126; 0.289) #> ICER_undisc                  NaN (NA; NA)          Inf (Inf; Inf) #> ICUR_undisc                  NaN (NA; NA) 40,091 (26,705; 71,186) #> INMB_undisc                  NaN (NA; NA)   3,590 (-2,091; 6,365) #> c_default         60,571 (58,122; 64,995) 53,370 (52,034; 56,982) #> dc_default                       0 (0; 0)    7,200 (6,049; 8,074) #> c_default_undisc  73,994 (71,014; 79,434) 65,368 (63,730; 69,820) #> dc_default_undisc                0 (0; 0)    8,626 (7,239; 9,685) #> q_default                6.31 (5.66; 6.8)        6.1 (5.55; 6.56) #> dq_default                       0 (0; 0)    0.203 (0.105; 0.242) #> q_default_undisc        7.45 (6.73; 8.03)        7.21 (6.6; 7.74) #> dq_default_undisc                0 (0; 0)    0.244 (0.126; 0.289)   psa_ipd_unif <- bind_rows(map(results_unif_psa[[1]], \"merged_df\")) %>% mutate(type = \"unif\") psa_ipd_sobol <- bind_rows(map(results_sobol_psa[[1]], \"merged_df\")) %>% mutate(type = \"sobol\")  merged_ipd_psa <- rbind(psa_ipd_unif,psa_ipd_sobol) %>%   group_by(arm, type, simulation) %>%   mutate(cumul_total_qalys = cumsum(total_qalys)/pat_id,          cumul_total_costs = cumsum(total_costs)/pat_id) %>%   transmute(type, pat_id, arm, simulation, cumul_total_qalys, cumul_total_costs) %>%   tidyr::pivot_wider(names_from = arm, values_from = c(cumul_total_qalys,cumul_total_costs)) %>%   mutate(inc_costs = cumul_total_costs_int - cumul_total_costs_noint,          inc_qalys = cumul_total_qalys_int - cumul_total_qalys_noint,          ICER = inc_costs/ inc_qalys)      ggplot(merged_ipd_psa, aes(x=pat_id,y=ICER, colour = type, fill = as.factor(simulation)))+   geom_line() +   theme_bw() +    ylim(20000,80000) #> Warning: Removed 7 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"document runs discrete event simulation model context late oncology model show functions can used generate model steps. running DES, ’s important consider speed. Simulation based models can computationally expensive, means using efficient coding can substantial impact performance.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"","code":"library(WARDEN)  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows library(purrr) options(scipen = 999) options(digits=3) options(tibble.print_max = 50)"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"Initial inputs flags used model can defined . can define inputs change across scenarios (sensitivity_inputs), inputs common patients (common_all_inputs) within simulation, inputs unique patient independently treatment (e.g. natural time death, defined common_pt_inputs), inputs unique patient treatment (unique_pt_inputs). Items can included add_item function, can used subsequent items. inputs generated events reaction events executed. Furthermore, program first executes common_all_inputs, common_pt_inputs unique_pt_inputs. one use items generated common_all_inputs unique_pt_inputs. Note inputs “reset” patient, patient 1 arm “noint” changes util.sick = 2, even ’s common parameter everyone, reset 1 patient 1 arm “int”. Note time death set common_pt_inputs, also just set add_tte function explained . user full flexibility implement type inputs. auxiliary functions help setting inputs, like pick_val_v pick_val (pick_psa, see section Sensitivity Analysis). Note pick_val_v pick_val can directly loaded parameters (fact, named list loaded directly R). small tweak needed ’s first item added, item list must initiated using add_item() (see ).","code":"#We don't need to use sensitivity_inputs here, so we don't add that object  #Put objects here that do not change on any patient or intervention loop common_all_inputs <-add_item(                       util.sick = 0.8,                       util.sicker = 0.5,                       cost.sick = 3000,                       cost.sicker = 7000,                       cost.int = 1000,                       coef_noint = log(0.2),                       HR_int = 0.8,                       drc = 0.035, #different values than what's assumed by default                       drq = 0.035) #different values than what's assumed by default   #Put objects here that do not change as we loop through treatments for a patient common_pt_inputs <- add_item2(input = {   rnd_stream_a <- random_stream(100) #arbitrary amount of random numbers to be used, should be >= max number of calls that use that random number (e.g., if item/event A requires 5 random numbers due to repeated calls, then at least 5 numbers should be generated )   rnd_stream_b <- random_stream(100)   common_luck <- runif(1)   fl.sick  <- 1   q_default  <- util.sick   })  #Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s) unique_pt_inputs <- add_item(c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"Events added add_tte function. use function applying interventions. must define several arguments: one indicate intervention, one define names events used, one define names objects created like store (optional, maybe generate intermediate input event want save) actual input generate time event. Events objects automatically initialized Inf. draw times event patients. Note: order evts argument appears first used reference order process events case ties (“sick” processed “sicker” tie time event.) Note model use evnets defined evts argument look objects defined input list expression allocate time events. event declared evts defined elsewhere, assumed TTE Inf default. chunk bit complex, ’s worth spending bit time explaining . init_event_list object populated using add_tte function applies arms, “int” strategy “noint” strategy. first declare start time 0. Note also separated arm user wants clarity using two add_tte functions (.e., add_tte(arm=\"noint\"...) %>% add_tte(arm=\"int\"...)). proceed generate actual time event. use draw_tte() function generate time event, though one can set way (e.g., using rexp). One always aware competing risks interact . abstracted type corrections , recommended understanding affect results look competing risks/semi-competing risks literature.","code":"init_event_list <-    add_tte(arm=c(\"noint\",\"int\"), evts = c(\"sick\",\"sicker\",\"death\") ,input={      sick <- 0     sicker <- qexp(rnd_stream_a$draw_n(),exp(coef_noint + ifelse(arm==\"int\",log(HR_int),0))) #use draw_n to automatically use the random number and update it in rnd_stream_a     death <-  max(0.0000001,qnorm(rnd_stream_b$draw_n(), mean=12, sd=3))   })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"initial times events defined, also need declare events react affect . , use evt_react_list object add_reactevt function. function just needs state event affected, actual reaction (usually setting flags 1 0, creating new/adjusting events). series objects can used context help reactions. Apart global objects flags defined , can also use curtime current event time, prevtime time previous event, cur_evtlist named vector events yet happen patient, arm current treatment loop, evt current event processed, expresses patient iteration, simulation specific simulation (relevant number simulations greater 1). Furthermore, one can also call input/item created create new ones. example, even modify cost/utility item changing directly, e.g. modify_item(list(cost.idfs.tx=500)). functions add/modify events inputs use lists. Whenever several inputs/events added modified, ’s recommended group within one function, reduces computation cost. rather use two modify_event list one element, ’s better group single modify_event list two elements. modify/create items, WARDEN now allows assign directly code, without need use modify_item modify_item_seq, allows code run faster (~30-35% faster comparing modify_item_seq, 15-20% comparing modify_item). However, two functions, modify_item modify_item_seq, still available user keep working, allow modify add items. Elements defined within function evaluated sequentially modify_item (.e. defining modify_item(list(fl.new = 1, var1 = fl.new * 5))) give error fl.new defined outside function), modify_item_seq sequentially slightly bigger computational cost, left choices user. Note one can modify costs/utilities using construction type_name_category, type either “qaly” “cost”, name name (e.g., “default”) category category used (e.g., “instant”), one pass cost_default_instant modify cost. modify_item modify_item_seqallow modify add items. Elements defined within function evaluated sequentially modify_item (.e. defining modify_item(list(fl.new = 1, var1 = fl.new * 5))) give error fl.new defined outside function), modify_item_seq sequentially slightly bigger computational cost, left choices user. Note one can modify costs/utilities using construction type_name_category, type either “qaly” “cost”, name name (e.g., “default”) category category used (e.g., “instant”), one pass cost_default_instant modify cost. list relevant functions used within add_reactevt : model run curtime set Inf, event terminates model (case, os), modify curtime set Inf. Finally, note two different ways accumulating continuous outcomes, backwards (.e., example , set q_default = util.sick sicker event, modify q_default value death event) forwards (example ). option can modified run_sim function using accum_backwards argument, assumes forwards default. use case luck adjustment update death time event using luck_adj function. parameters go mean 12 10, sd 3 2, update random number redraw time event. instead needed reset time event (case repeated independent events), set rnd_b = random_stream_b[2] regenerate luck. Note occurences expected happen, need keep track index make sure grab right random number. Additionally, convergence purposes one may rely quasi-random low discrepancy numbers sequence algorithms Sobol sequence, example sobol function randtoolbox package.","code":"evt_react_list <-   add_reactevt(name_evt = \"sick\",                input = {}) %>%   add_reactevt(name_evt = \"sicker\",                input = {                  q_default <- util.sicker                  c_default <- cost.sicker + if(arm==\"int\"){cost.int}else{0}                  fl.sick <- 0                                     #We perform a luck adjustment randomly but being slightly more likely in the \"noint\" arm                  if((common_luck + ifelse(arm==\"noint\", 0.1,0) ) >0.7){                     rnd_stream_b$random_n <- luck_adj(prevsurv = 1 - pnorm(q=curtime,12,3),                                                       cursurv = 1 - pnorm(q=curtime,8,2),                                                       luck = rnd_stream_b$random_n,                                                       condq = FALSE)                     modify_event(list(                       death = max(curtime,qnorm(rnd_stream_b$random_n, mean=8, sd=2))                     ))                     }                                                    }) %>%   add_reactevt(name_evt = \"death\",                input = {                  q_default <- 0                  c_default <- 0                  curtime <- Inf                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"Costs utilities introduced . However, ’s worth noting model able run without costs utilities. Utilities/Costs/outputs defined declaring object belongs utilities/costs/outputs, whether need discounted continuously discretely (instantaneous). passed run_sim function.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"utilities","dir":"Articles","previous_headings":"Costs and Utilities","what":"Utilities","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"","code":"util_ongoing <- \"q_default\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"costs","dir":"Articles","previous_headings":"Costs and Utilities","what":"Costs","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"","code":"cost_ongoing <- \"c_default\""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"model-execution","dir":"Articles","previous_headings":"Model","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"model can run using function run_sim . must define number patients simulated, number simulations, whether want run PSA , strategy list, inputs, events reactions defined , utilities, costs also want extra output level ipd data desired exported. worth noting psa_bool argument run PSA automatically, rather additional input/flag model use reference determine whether want use deterministic stochastic input. , also defined common_all_inputs first item defined, result . However, recommend defined run_sim. Note distribution chosen, number events interaction events can substantial impact running time model. Debugging can implemented using argument debug run_sim function.","code":"#Logic is: per patient, per intervention, per event, react to that event. results <- run_sim(     npats=1000,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.69s #> Time to run analysis 1: 0.69s #> Total time to run: 0.7s"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"summary-of-results","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Summary of Results","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"model run, can use results summarize using summary_results_det print results last simulation (nsim = 1, ’s deterministic case), summary_results_sim show PSA results (confidence intervals). can also use individual patient data generated simulation, collect plot psa_ipd object. can also check absolute number events per strategy.","code":"summary_results_det(results[[1]][[1]]) #print first simulation #>                        int    noint #> costs             54126.08 45747.63 #> dcosts                0.00  8378.44 #> lys                   9.04     8.78 #> dlys                  0.00     0.26 #> qalys                 5.88     5.57 #> dqalys                0.00     0.31 #> ICER                    NA 32688.17 #> ICUR                    NA 26833.80 #> INMB                    NA  7233.29 #> costs_undisc      67095.76 56588.86 #> dcosts_undisc         0.00 10506.90 #> lys_undisc           10.99    10.63 #> dlys_undisc           0.00     0.37 #> qalys_undisc          7.06     6.65 #> dqalys_undisc         0.00     0.41 #> ICER_undisc             NA 28765.37 #> ICUR_undisc             NA 25578.19 #> INMB_undisc             NA 10031.89 #> c_default         54126.08 45747.63 #> dc_default            0.00  8378.44 #> c_default_undisc  67095.76 56588.86 #> dc_default_undisc     0.00 10506.90 #> q_default             5.88     5.57 #> dq_default            0.00     0.31 #> q_default_undisc      7.06     6.65 #> dq_default_undisc     0.00     0.41  summary_results_sim(results[[1]]) #>                                       int                   noint #> costs             54,126 (54,126; 54,126) 45,748 (45,748; 45,748) #> dcosts                           0 (0; 0)    8,378 (8,378; 8,378) #> lys                     9.04 (9.04; 9.04)       8.78 (8.78; 8.78) #> dlys                             0 (0; 0)    0.256 (0.256; 0.256) #> qalys                   5.88 (5.88; 5.88)       5.57 (5.57; 5.57) #> dqalys                           0 (0; 0)    0.312 (0.312; 0.312) #> ICER                         NaN (NA; NA) 32,688 (32,688; 32,688) #> ICUR                         NaN (NA; NA) 26,834 (26,834; 26,834) #> INMB                         NaN (NA; NA)    7,233 (7,233; 7,233) #> costs_undisc      67,096 (67,096; 67,096) 56,589 (56,589; 56,589) #> dcosts_undisc                    0 (0; 0) 10,507 (10,507; 10,507) #> lys_undisc                    11 (11; 11)       10.6 (10.6; 10.6) #> dlys_undisc                      0 (0; 0)    0.365 (0.365; 0.365) #> qalys_undisc            7.06 (7.06; 7.06)       6.65 (6.65; 6.65) #> dqalys_undisc                    0 (0; 0)    0.411 (0.411; 0.411) #> ICER_undisc                  NaN (NA; NA) 28,765 (28,765; 28,765) #> ICUR_undisc                  NaN (NA; NA) 25,578 (25,578; 25,578) #> INMB_undisc                  NaN (NA; NA) 10,032 (10,032; 10,032) #> c_default         54,126 (54,126; 54,126) 45,748 (45,748; 45,748) #> dc_default                       0 (0; 0)    8,378 (8,378; 8,378) #> c_default_undisc  67,096 (67,096; 67,096) 56,589 (56,589; 56,589) #> dc_default_undisc                0 (0; 0) 10,507 (10,507; 10,507) #> q_default               5.88 (5.88; 5.88)       5.57 (5.57; 5.57) #> dq_default                       0 (0; 0)    0.312 (0.312; 0.312) #> q_default_undisc        7.06 (7.06; 7.06)       6.65 (6.65; 6.65) #> dq_default_undisc                0 (0; 0)    0.411 (0.411; 0.411)  summary_results_sens(results) #>        arm analysis analysis_name          variable                   value #>     <char>    <int>        <char>            <fctr>                  <char> #>  1:    int        1                           costs 54,126 (54,126; 54,126) #>  2:  noint        1                           costs 45,748 (45,748; 45,748) #>  3:    int        1                          dcosts                0 (0; 0) #>  4:  noint        1                          dcosts    8,378 (8,378; 8,378) #>  5:    int        1                             lys       9.04 (9.04; 9.04) #>  6:  noint        1                             lys       8.78 (8.78; 8.78) #>  7:    int        1                            dlys                0 (0; 0) #>  8:  noint        1                            dlys    0.256 (0.256; 0.256) #>  9:    int        1                           qalys       5.88 (5.88; 5.88) #> 10:  noint        1                           qalys       5.57 (5.57; 5.57) #> 11:    int        1                          dqalys                0 (0; 0) #> 12:  noint        1                          dqalys    0.312 (0.312; 0.312) #> 13:    int        1                            ICER            NaN (NA; NA) #> 14:  noint        1                            ICER 32,688 (32,688; 32,688) #> 15:    int        1                            ICUR            NaN (NA; NA) #> 16:  noint        1                            ICUR 26,834 (26,834; 26,834) #> 17:    int        1                            INMB            NaN (NA; NA) #> 18:  noint        1                            INMB    7,233 (7,233; 7,233) #> 19:    int        1                    costs_undisc 67,096 (67,096; 67,096) #> 20:  noint        1                    costs_undisc 56,589 (56,589; 56,589) #> 21:    int        1                   dcosts_undisc                0 (0; 0) #> 22:  noint        1                   dcosts_undisc 10,507 (10,507; 10,507) #> 23:    int        1                      lys_undisc             11 (11; 11) #> 24:  noint        1                      lys_undisc       10.6 (10.6; 10.6) #> 25:    int        1                     dlys_undisc                0 (0; 0) #> 26:  noint        1                     dlys_undisc    0.365 (0.365; 0.365) #> 27:    int        1                    qalys_undisc       7.06 (7.06; 7.06) #> 28:  noint        1                    qalys_undisc       6.65 (6.65; 6.65) #> 29:    int        1                   dqalys_undisc                0 (0; 0) #> 30:  noint        1                   dqalys_undisc    0.411 (0.411; 0.411) #> 31:    int        1                     ICER_undisc            NaN (NA; NA) #> 32:  noint        1                     ICER_undisc 28,765 (28,765; 28,765) #> 33:    int        1                     ICUR_undisc            NaN (NA; NA) #> 34:  noint        1                     ICUR_undisc 25,578 (25,578; 25,578) #> 35:    int        1                     INMB_undisc            NaN (NA; NA) #> 36:  noint        1                     INMB_undisc 10,032 (10,032; 10,032) #> 37:    int        1                       c_default 54,126 (54,126; 54,126) #> 38:  noint        1                       c_default 45,748 (45,748; 45,748) #> 39:    int        1                      dc_default                0 (0; 0) #> 40:  noint        1                      dc_default    8,378 (8,378; 8,378) #> 41:    int        1                c_default_undisc 67,096 (67,096; 67,096) #> 42:  noint        1                c_default_undisc 56,589 (56,589; 56,589) #> 43:    int        1               dc_default_undisc                0 (0; 0) #> 44:  noint        1               dc_default_undisc 10,507 (10,507; 10,507) #> 45:    int        1                       q_default       5.88 (5.88; 5.88) #> 46:  noint        1                       q_default       5.57 (5.57; 5.57) #> 47:    int        1                      dq_default                0 (0; 0) #> 48:  noint        1                      dq_default    0.312 (0.312; 0.312) #> 49:    int        1                q_default_undisc       7.06 (7.06; 7.06) #> 50:  noint        1                q_default_undisc       6.65 (6.65; 6.65) #> 51:    int        1               dq_default_undisc                0 (0; 0) #> 52:  noint        1               dq_default_undisc    0.411 (0.411; 0.411) #>        arm analysis analysis_name          variable                   value  psa_ipd <- bind_rows(map(results[[1]], \"merged_df\"))   psa_ipd[1:10,] %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"plots","dir":"Articles","previous_headings":"Post-processing of Model Outputs","what":"Plots","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"now use data output plot histograms/densities simulation.  can also plot patient level incremental QALY/costs.","code":"data_plot <- results[[1]][[1]]$merged_df %>%   filter(evtname != \"sick\") %>%   group_by(arm,evtname,simulation) %>%   mutate(median = median(evttime)) %>%   ungroup()  ggplot(data_plot) +   geom_density(aes(fill = arm, x = evttime),                alpha = 0.7) +   geom_vline(aes(xintercept=median,col=arm)) +   facet_wrap( ~ evtname, scales = \"free\") +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw() data_qaly_cost<- psa_ipd[,.SD[1],by=.(pat_id,arm,simulation)][,.(arm,qaly=total_qalys,cost=total_costs,pat_id,simulation)] data_qaly_cost[,ps_id:=paste(pat_id,simulation,sep=\"_\")]   mean_data_qaly_cost <- data_qaly_cost %>% group_by(arm) %>% summarise(across(where(is.numeric),mean))  ggplot(data_qaly_cost,aes(x=qaly, y = cost, col = arm)) +    geom_point(alpha=0.15,shape = 21) +   geom_point(data=mean_data_qaly_cost, aes(x=qaly, y = cost, fill = arm), shape = 21,col=\"black\",size=3) +   scale_y_continuous(expand = c(0, 0)) +   scale_x_continuous(expand = c(0, 0)) +   theme_bw()+   theme(axis.text.x = element_text(angle = 90, vjust = .5))"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"inputs","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Inputs","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"case, inputs must created first change across sensitivity analysis. , item list sensitivity_inputs can used. case, also use pick_val_v allows model automatically pick relevant value (PSA, PSA sensitivity analysis) based corresponding boolean flags psa_bool sensitivity_bool. case also use sens iterator sensitivity analysis n_sensitivity argument run_sim. Note just changed inputs handled common_all_inputs, done unique_pt_inputs, cases, inputs change per patient, pick_val_v pick_val functions applied within unique_pt_inputs make sure evaluated correspond. Note psa directly calling distributions passing parameters.Note also sens_name_used automatically computed engine accesible user (’s name sensitivity analysis, e.g., “scenario 1”). indicator parameter pick_val_v pick_val used determine parameters left “” ones substituted sensitivity value. two ways , either setting binary way (1 0), using indicator number parameter values varied (useful several parameters varied time, specific values vector varied). can set using indicator_sens_binary argument. Note pick_val_v pick_val can directly loaded parameters (fact, named list loaded directly R). small tweak needed ’s first item added, item list must initiated using add_item() (see ). pick_psa can used select correct PSA distributions.","code":"#Load some data df_par <- list(parameter_name = c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),                               base_value = c(0.8,0.5,3000,7000,1000,log(0.2),0.8),                               DSA_min = c(0.6,0.3,1000,5000,800,log(0.1),0.5),                               DSA_max = c(0.9,0.7,5000,9000,2000,log(0.4),0.9),                               PSA_dist = c(\"rnorm\",\"rbeta_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rnorm\",\"rlnorm\"),                               a = list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)),                               b = lapply(list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)), function(x) abs(x/10)),                               scenario_1=c(0.6,0.3,1000,5000,800,log(0.1),0.5),                               scenario_2=c(0.9,0.7,5000,9000,2000,log(0.4),0.9)                               )  sensitivity_inputs <-add_item(             pos_indicator = sens - n_sensitivity*floor((sens-1)/n_sensitivity), # which position to use to put the value 1 in indicator             indicators = append(rep(0, length(df_par$parameter_name))[-pos_indicator],1,pos_indicator-1) #vector of indicators, value 0 everywhere except at sens, where it takes value 1                               )  common_all_inputs <-add_item() %>%    add_item(             pick_val_v(base        = df_par[[\"base_value\"]],                        psa         = pick_psa(df_par[[\"PSA_dist\"]],rep(1,length(df_par[[\"PSA_dist\"]])),df_par[[\"a\"]],df_par[[\"b\"]]),                        sens        = df_par[[sens_name_used]],                        psa_ind     = psa_bool,                        sens_ind    = sensitivity_bool,                        indicator   = indicators,                        names_out   = df_par[[\"parameter_name\"]]                        )             )"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"model-execution-1","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Model Execution","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"model executed , just adding sensitivity_inputs, sensitivity_names, sensitivity_bool n_sensitivity arguments. Note total number sensitivity iterations given n_sensitivity, n_sensitivity * length(sensitivity_names), case 2 x n_sensitivity, 2 x 7 = 14. two scenario analysis 2 x 1 = 2, indicators variable defined previous section taking value 1 variables altered scenario, 0 otherwise.","code":"results <- run_sim(     npats=100,                               # number of patients to be simulated   n_sim=1,                                  # number of simulations to run   psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list   common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation   common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention   unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions   init_event_list = init_event_list,        # initial event list   evt_react_list = evt_react_list,          # reaction of events   util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   sensitivity_inputs = sensitivity_inputs,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(df_par$parameter_name),   input_out = c(df_par[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 1: 0.13s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 2: 0.12s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Time to run analysis 3: 0.14s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 4: 0.12s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 5: 0.13s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 6: 0.12s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 7: 0.12s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 8: 0.13s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 9: 0.12s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 10: 0.13s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 11: 0.12s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 12: 0.13s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Time to run analysis 13: 0.12s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Time to run analysis 14: 0.13s #> Total time to run: 1.79s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"check-results","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Check results","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"briefly check indeed engine changing corresponding parameter value.","code":"data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))  #Check mean value across iterations as PSA is off data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean) #> # A tibble: 14 × 8 #>    sensitivity util.sick util.sicker cost.sick cost.sicker cost.int coef_noint #>          <int>     <dbl>       <dbl>     <dbl>       <dbl>    <dbl>      <dbl> #>  1           1       0.6         0.5      3000        7000     1000     -1.61  #>  2           2       0.8         0.3      3000        7000     1000     -1.61  #>  3           3       0.8         0.5      1000        7000     1000     -1.61  #>  4           4       0.8         0.5      3000        5000     1000     -1.61  #>  5           5       0.8         0.5      3000        7000      800     -1.61  #>  6           6       0.8         0.5      3000        7000     1000     -2.30  #>  7           7       0.8         0.5      3000        7000     1000     -1.61  #>  8           8       0.9         0.5      3000        7000     1000     -1.61  #>  9           9       0.8         0.7      3000        7000     1000     -1.61  #> 10          10       0.8         0.5      5000        7000     1000     -1.61  #> 11          11       0.8         0.5      3000        9000     1000     -1.61  #> 12          12       0.8         0.5      3000        7000     2000     -1.61  #> 13          13       0.8         0.5      3000        7000     1000     -0.916 #> 14          14       0.8         0.5      3000        7000     1000     -1.61  #> # ℹ 1 more variable: HR_int <dbl>"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"model-execution-probabilistic-dsa","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Model Execution, probabilistic DSA","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"model executed , just activating psa_bool option","code":"results <- run_sim(     npats=100,                                  n_sim=6,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = common_all_inputs,       common_pt_inputs = common_pt_inputs,         unique_pt_inputs = unique_pt_inputs,         init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   sensitivity_inputs = sensitivity_inputs,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(df_par$parameter_name),   input_out = c(df_par[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 1: 0.76s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.15s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 2: 0.79s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 3: 0.77s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 4: 0.78s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.16s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 5: 0.81s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 6: 0.76s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.14s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 7: 0.8s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Simulation number: 2 #> Time to run simulation 2: 0.15s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.14s #> Simulation number: 5 #> Time to run simulation 5: 0.14s #> Simulation number: 6 #> Time to run simulation 6: 0.13s #> Time to run analysis 8: 0.82s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.14s #> Simulation number: 2 #> Time to run simulation 2: 0.3s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 9: 0.95s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.12s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 10: 0.73s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.12s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.12s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 11: 0.73s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.12s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 12: 0.75s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.12s #> Simulation number: 3 #> Time to run simulation 3: 0.13s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.13s #> Simulation number: 6 #> Time to run simulation 6: 0.12s #> Time to run analysis 13: 0.78s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.13s #> Simulation number: 2 #> Time to run simulation 2: 0.13s #> Simulation number: 3 #> Time to run simulation 3: 0.12s #> Simulation number: 4 #> Time to run simulation 4: 0.13s #> Simulation number: 5 #> Time to run simulation 5: 0.12s #> Simulation number: 6 #> Time to run simulation 6: 0.14s #> Time to run analysis 14: 0.78s #> Total time to run: 11.04s"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_ssd_stream.html","id":"check-results-1","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Check results","title":"Example for a Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment","text":"briefly check indeed engine changing corresponding parameter value.","code":"data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))  #Check mean value across iterations as PSA is off data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean) #> # A tibble: 14 × 8 #>    sensitivity util.sick util.sicker cost.sick cost.sicker cost.int coef_noint #>          <int>     <dbl>       <dbl>     <dbl>       <dbl>    <dbl>      <dbl> #>  1           1     0.6         0.541     3069.       7509.    1035.     -1.61  #>  2           2     0.762       0.3       3069.       7509.    1035.     -1.61  #>  3           3     0.762       0.541     1000        7509.    1035.     -1.61  #>  4           4     0.762       0.541     3069.       5000     1035.     -1.61  #>  5           5     0.762       0.541     3069.       7509.     800      -1.61  #>  6           6     0.762       0.541     3066.       7506.    1036.     -2.30  #>  7           7     0.761       0.541     3070.       7510.    1035.     -1.61  #>  8           8     0.9         0.541     3069.       7509.    1035.     -1.61  #>  9           9     0.762       0.7       3069.       7509.    1035.     -1.61  #> 10          10     0.762       0.541     5000        7509.    1035.     -1.61  #> 11          11     0.762       0.541     3069.       9000     1035.     -1.61  #> 12          12     0.762       0.541     3069.       7509.    2000      -1.61  #> 13          13     0.762       0.541     3066.       7506.    1036.     -0.916 #> 14          14     0.762       0.541     3069.       7509.    1035.     -1.62  #> # ℹ 1 more variable: HR_int <dbl>"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Structural and Parametric Uncertainty","text":"document runs discrete event simulation model context early breast cancer show uncertainty behaves simulation setting complements standard PSA. model extremely similar example early breast cancer, user can check original model details functions, parameters etc.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"main-options","dir":"Articles","previous_headings":"Introduction","what":"Main options","title":"Structural and Parametric Uncertainty","text":"","code":"library(WARDEN)  library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(purrr) library(tidyr) library(flexsurv) #> Loading required package: survival library(ggplot2) library(kableExtra) #>  #> Attaching package: 'kableExtra' #> The following object is masked from 'package:dplyr': #>  #>     group_rows"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"load-data","dir":"Articles","previous_headings":"Introduction","what":"Load Data","title":"Structural and Parametric Uncertainty","text":"dummy data costs utility generated .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"general-inputs-with-delayed-execution","dir":"Articles","previous_headings":"","what":"General inputs with delayed execution","title":"Structural and Parametric Uncertainty","text":"Initial inputs flags used model can defined . exactly original model, difference now adding extra chunk reflects uncertainty parameters draw distributions. Furthermore, utilities costs also distribution.","code":"#Each patient is identified through \"i\" #Items used in the model should be unnamed numeric/vectors! otherwise if they are processed by model it can lead to strangely named outcomes #In this case, util_v is a named vector, but it's not processed by the model. We extract unnamed numerics from it.  #Put objects here that do not change on any patient or intervention loop common_all_inputs <- add_item() %>%   add_item( #utilities   pick_val_v(     base =  util.data$value,     psa = MASS::mvrnorm(1,util.data$value,diag(util.data$se^2)),     sens = util.data$value,     psa_ind = psa_bool,     sens_ind = sensitivity_bool,     indicator = rep(0, nrow(util.data)),     names_out =util.data$name   ),#costs   pick_val_v(     base =  cost.data$value,     psa = rgamma_mse(1,cost.data$value,cost.data$se),     sens = cost.data$value,     psa_ind = psa_bool,     sens_ind = sensitivity_bool,     indicator = rep(0, nrow(cost.data)),     names_out =cost.data$name   ) ) %>%   add_item( #parameter uncertainty, alternative approach to using pick_val_v, it also does work     coef11_psa = ifelse(psa_bool,rnorm(1,2,0.1),2),     coef12_psa = ifelse(psa_bool,rnorm(1,3,0.1),3),     coef13_psa = ifelse(psa_bool,rnorm(1,0.8,0.05),0.8),     coef14_psa = ifelse(psa_bool,rnorm(1,0.5,0.05),0.5),     coef15_psa = ifelse(psa_bool,rnorm(1,2.3,0.1),2.3),     coef16_psa = ifelse(psa_bool,log(rnorm(1,0.08,0.005)),log(0.08)),     coef2_psa = ifelse(psa_bool,log(rnorm(1,0.2,0.01)),log(0.2)),     hr_psa = ifelse(psa_bool,exp(rnorm(1,log(1.2),0.05)),1.2)     )  #Put objects here that do not change as we loop through interventions for a patient common_pt_inputs <- add_item(sex_pt = ifelse(rbinom(1,1,p=0.01),\"male\",\"female\"),                              nat.os.s = rcond_gompertz(1,                                                      shape=if(sex_pt==\"male\"){0.102}else{0.115},                                                      rate=if(sex_pt==\"male\"){0.000016}else{0.0000041},                                                      lower_bound = 50) ) #in years, for a patient who is 50yo  #Put objects here that change as we loop through treatments for each patient (e.g. events can affect fl.tx, but events do not affect nat.os.s) #common across arm but changes per pt could be implemented here (if (arm==)... ) unique_pt_inputs <- add_item(   fl.idfs.ontx             = 1,   fl.idfs                  = 1,   fl.mbcs.ontx             = 1,   fl.mbcs.progression.mbc  = 1,   fl.tx.beva               = 1,     fl.mbcs                  = 0,   fl.mbcs_2ndline          = 0,   fl.recurrence            = 0,   fl.remission             = rbinom(1,1,0.8), #80% probability of going into remission   q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               },   c_default = if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs},   c_ae = 0 )"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"add-initial-events","dir":"Articles","previous_headings":"Events","what":"Add Initial Events","title":"Structural and Parametric Uncertainty","text":"Events generated , difference parameters simple number objects created part common_all_inputs.","code":"init_event_list <-    add_tte(arm=\"int\",                evts = c(\"start\",\"ttot\", \"ttot.beva\",\"progression.mbc\", \"os\",\"idfs\",\"ttot.early\",\"remission\",\"recurrence\",\"start.early.mbc\",\"ae\",\"2ndline_mbc\"),                other_inp = c(\"os.early\",\"os.mbc\"),                input={ #intervention     start <- 0          #Early          idfs <- draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa)      ttot.early <- min(draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa),idfs)     ttot.beva <- draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa)      os.early <- draw_tte(1,'lnorm',coef1=coef12_psa, coef2=coef2_psa)           #if patient has remission, check when will recurrence happen     if (fl.remission) {        recurrence <- idfs + draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa)       remission <- idfs              #if recurrence happens before death       if (min(os.early,nat.os.s)>recurrence) {                   #Late metastatic (after finishing idfs and recurrence)                  os.mbc <- draw_tte(1,'lnorm',coef1=coef13_psa, coef2=coef2_psa) + idfs  +  recurrence                   progression.mbc <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + idfs +  recurrence                   ttot <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + idfs +  recurrence                         }            } else{ #If early metastatic       start.early.mbc <- draw_tte(1,'lnorm',coef1=coef15_psa, coef2=coef2_psa)              idfs <- ifelse(start.early.mbc<idfs,start.early.mbc,idfs)       ttot.early <- min(ifelse(start.early.mbc<idfs,start.early.mbc,idfs),ttot.early)              os.mbc <- draw_tte(1,'lnorm',coef1=coef13_psa, coef2=coef2_psa) + start.early.mbc              progression.mbc <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + start.early.mbc              ttot <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + start.early.mbc            }          os <- min(os.mbc,os.early,nat.os.s)         }) %>%  add_tte(arm=\"noint\",                        evts = c(\"start\",\"ttot\", \"ttot.beva\",\"progression.mbc\", \"os\",\"idfs\",\"ttot.early\",\"remission\",\"recurrence\",\"start.early.mbc\"),                        other_inp = c(\"os.early\",\"os.mbc\"),                                               input={  #reference strategy     start <- 0      #Early          idfs <- draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa,beta_tx = hr_psa)      ttot.early <- min(draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa,beta_tx = hr_psa),idfs)          os.early <- draw_tte(1,'lnorm',coef1=coef12_psa, coef2=coef2_psa,beta_tx = hr_psa)           #if patient has remission, check when will recurrence happen     if (fl.remission) {        recurrence <- idfs +draw_tte(1,'lnorm',coef1=coef11_psa, coef2=coef2_psa)       remission <- idfs              #if recurrence happens before death       if (min(os.early,nat.os.s)>recurrence) {                   #Late metastatic (after finishing idfs and recurrence)                  os.mbc <- draw_tte(1,'lnorm',coef1=coef13_psa, coef2=coef2_psa) + idfs  +  recurrence                   progression.mbc <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + idfs +  recurrence                   ttot <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + idfs +  recurrence                }            } else{ #If early metastatic       start.early.mbc <- draw_tte(1,'lnorm',coef1=coef15_psa, coef2=coef2_psa)              idfs <- ifelse(start.early.mbc<idfs,start.early.mbc,idfs)       ttot.early <- min(ifelse(start.early.mbc<idfs,start.early.mbc,idfs),ttot.early)              os.mbc <- draw_tte(1,'lnorm',coef1=coef13_psa, coef2=coef2_psa) + start.early.mbc              progression.mbc <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + start.early.mbc              ttot <- draw_tte(1,'lnorm',coef1=coef14_psa, coef2=coef2_psa) + start.early.mbc                   }         os <- min(os.mbc,os.early,nat.os.s)        })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"add-reaction-to-those-events","dir":"Articles","previous_headings":"Events","what":"Add Reaction to Those Events","title":"Structural and Parametric Uncertainty","text":"reactions set fashion original model. small modification made generating event 2ndline_mbc, now also uses random parameter PSA option active.","code":"evt_react_list <-   add_reactevt(name_evt = \"start\",                input = {}) %>%   add_reactevt(name_evt = \"ttot\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}                               \"fl.mbcs.ontx\"= 0 #Flag that patient is now off-treatment                                  }) %>%   add_reactevt(name_evt = \"ttot.beva\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                               \"fl.tx.beva\"= 0 #Flag that patient is now off-treatment                                  }) %>%   add_reactevt(name_evt = \"progression.mbc\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                               \"fl.mbcs.progression.mbc\"=0                               \"fl.mbcs_2ndline\"=1 #Flag that patient is progressed and going in 2nd line                                    new_event(list(\"2ndline_mbc\" = curtime + draw_tte(1,'exp', coef16_psa)/12))                                  }) %>%   add_reactevt(name_evt = \"idfs\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}                               \"fl.idfs\"= 0                                  }) %>%   add_reactevt(name_evt = \"ttot.early\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = if(arm==\"noint\"){cost.idfs.txnoint* fl.idfs.ontx  + cost.idfs}else{(cost.idfs.tx) * fl.idfs.ontx + cost.tx.beva * fl.tx.beva + cost.idfs}                               \"fl.idfs.ontx\"=0                               \"fl.tx.beva\"=0 #Flag that patient is now off-treatment                                    n_ae <- rpois(1,lambda=0.25*(curtime -prevtime)) #1 AE every 4 years                                    if (n_ae>0) {                    new_event(rep(list(\"ae\" = curtime + 0.0001),n_ae))                  }                }) %>%   add_reactevt(name_evt = \"remission\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.recurrence * fl.recurrence                               \"fl.remission\"= 1                                  }) %>%   add_reactevt(name_evt = \"recurrence\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.recurrence * fl.recurrence                               \"fl.recurrence\"=1                               \"fl.remission\"=0                               \"fl.mbcs\"=1                               \"fl.mbcs.progression.mbc\"=1 #ad-hoc for plot                                  }) %>%   add_reactevt(name_evt = \"start.early.mbc\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.recurrence * fl.recurrence                               \"fl.mbcs\"=1                               \"fl.mbcs.progression.mbc\"=1                                  }) %>%   add_reactevt(name_evt = \"2ndline_mbc\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                               \"fl.mbcs_2ndline\"= 0                                    n_ae <- rpois(1,lambda=0.25*(curtime -prevtime)) #1 AE every 4 years                                    if (n_ae>0) {                    new_event(rep(list(\"ae\" = curtime + 0.0001),n_ae))                  }                }) %>%   add_reactevt(name_evt = \"ae\",                input = {                                    q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                               c_ae = cost.ae                                    modify_event(list(                               \"os\" = max(cur_evtlist[[\"os\"]] - 0.125,curtime +0.0001) ))#each AE brings forward death by 1.5 months                }) %>%   add_reactevt(name_evt = \"os\",                input = {                  q_default = if (fl.idfs==1) {                                 util.idfs.ontx * fl.idfs.ontx + (1-fl.idfs.ontx) * (1-fl.idfs.ontx)                                } else if (fl.idfs==0 & fl.mbcs==0) {                                 util.remission * fl.remission + fl.recurrence*util.recurrence                               } else if (fl.mbcs==1) {                                 util.mbc.progression.mbc * fl.mbcs.progression.mbc + (1-fl.mbcs.progression.mbc)*util.mbc.pps                               }                               c_default = cost.mbc.tx  * fl.mbcs.ontx + cost.mbc.progression.mbc * fl.mbcs.progression.mbc + cost.mbc.pps * (1-fl.mbcs.progression.mbc) + cost.2ndline*fl.mbcs_2ndline                               \"fl.tx.beva\"=0                               \"fl.mbcs.ontx\"=0                               \"fl.idfs\"=0                               \"fl.mbcs\"=0                               \"curtime\"=Inf                })"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"costs-and-utilities","dir":"Articles","previous_headings":"","what":"Costs and Utilities","title":"Structural and Parametric Uncertainty","text":"Costs utilities introduced .","code":"util_ongoing <- \"q_default\"  cost_ongoing <- \"c_default\"  cost_instant <-  \"c_ae\""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"model","dir":"Articles","previous_headings":"","what":"Model","title":"Structural and Parametric Uncertainty","text":"model can now executed normal. Given modeling exercise relies sampling distributions simulating finite number patients, randomness involved can affect results, even assumption parameters fixed. However, running patients also means simulation slower, trade-accuracy speed. important question understand much uncertainty observe running PSA comes parametric uncertainty much comes fact simulating finite sample.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"structural-uncertainty","dir":"Articles","previous_headings":"Model","what":"Structural Uncertainty","title":"Structural and Parametric Uncertainty","text":"One way test run simulations increasing number patients simulated. example, run 20 deterministic simulations 50, 100, 500, 1,000 patients, show model outcome can change depending random seed used. Note exercise can time consuming. ’s important note optimal number patients simulated depend dispersion distributions, patient pathway, number possible outcomes difference among . example, event low probability high impact variability implies higher number patients simulated order obtain stable outcomes. test, set psa_bool = FALSE (optional) set ipd = FALSE. last option means exporting IPD data simulations, rather aggregate outcomes (last simulation, included default). important simulating large number patients lot simulations, can generate large objects (>1 GB). option can also especially relevant running PSA, require psa_bool = TRUE high number simulations. can plot results (case, costs, lys qalys “noint” intervention) can also try understand relative size uncertainty provided sampling. compute coefficient variation outcomes exported (costs, qalys, lys, ICER ICUR). first thing noticed ICER ICUR CV much higher costs/lys/qalys. incremental nature ICER/ICUR, means ’s sensitive small variations outputs. costs/qalys/lys quite precise reduced number simulations (~1,000), order precise ICER/ICUR need go higher (~5,000/10,000). However, one see mean quite stable ~5,000 patients. can plot CV see clearly:","code":"sample_sizes <- c(50,100,500,1000)  sim_size_df <- NULL for (sample_size in sample_sizes) {   results <- suppressWarnings( #run without warnings       run_sim(       npats=sample_size,                        # number of patients to be simulated     n_sim=20,                                # number of simulations to run     psa_bool = FALSE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list     common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation     common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention     unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions     init_event_list = init_event_list,        # initial event list     evt_react_list = evt_react_list,          # reaction of events     util_ongoing_list = util_ongoing,     cost_ongoing_list = cost_ongoing,     cost_instant_list = cost_instant,     ipd=FALSE                                 # Return IPD data through merged_df? Set to FALSE as it's not of interest here and it makes code slower   ))     #We're extracting the overall ICER/ICUR and also costs/qalys/lys for the \"noint\" intervention   loop_df <- rbind(extract_psa_result(results[[1]],\"total_costs\"),                    extract_psa_result(results[[1]],\"total_lys\"),                    extract_psa_result(results[[1]],\"total_qalys\"))      loop_df <- rbind(loop_df %>%                      pivot_longer(cols=c(\"int\",\"noint\"),names_to=\"arm\"),                    loop_df %>%                      mutate(dif = int - noint) %>%                      group_by(simulation) %>%                      transmute(value = dif[element==\"total_costs\"]/dif[element==\"total_qalys\"],element = \"ICUR\", arm=\"noint\") %>%                      relocate(element, arm) %>%                      ungroup() %>%                      distinct())         loop_df$sample_size <- sample_size   sim_size_df <- rbind(sim_size_df,loop_df)    }"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"parameter-uncertainty","dir":"Articles","previous_headings":"Model","what":"Parameter Uncertainty","title":"Structural and Parametric Uncertainty","text":"Structural uncertainty type uncertainty model can . Parameters can also changed across simulations using psa_bool = TRUE option. Let’s see happens compare true PSA structural uncertainty 1,000 patients. Now uncertainty much bigger compared case 1,000 iterations parameter uncertainty.","code":"sample_sizes <- 1000  sim_size_psa_df <- NULL for (sample_size in sample_sizes) {   results <- suppressWarnings( #run without warnings       run_sim(       npats=sample_size,                        # number of patients to be simulated     n_sim=20,                                # number of simulations to run     psa_bool = TRUE,                         # use PSA or not. If n_sim > 1 and psa_bool = FALSE, then difference in outcomes is due to sampling (number of pats simulated)     arm_list = c(\"int\", \"noint\"),             # intervention list     common_all_inputs = common_all_inputs,    # inputs common that do not change within a simulation     common_pt_inputs = common_pt_inputs,      # inputs that change within a simulation but are not affected by the intervention     unique_pt_inputs = unique_pt_inputs,      # inputs that change within a simulation between interventions     init_event_list = init_event_list,        # initial event list     evt_react_list = evt_react_list,          # reaction of events     util_ongoing_list = util_ongoing,     cost_ongoing_list = cost_ongoing,     cost_instant_list = cost_instant,     ipd=FALSE                                 # Return IPD data through merged_df? Set to FALSE as it's not of interest here and it makes code slower   ))     #We're extracting the overall ICER/ICUR and also costs/qalys/lys for the \"noint\" intervention   loop_psa_df <- rbind(extract_psa_result(results[[1]],\"total_costs\"),                    extract_psa_result(results[[1]],\"total_lys\"),                    extract_psa_result(results[[1]],\"total_qalys\"))      loop_psa_df <- rbind(loop_psa_df %>%                      pivot_longer(cols=c(\"int\",\"noint\"),names_to=\"arm\"),                    loop_psa_df %>%                      mutate(dif = int - noint) %>%                      group_by(simulation) %>%                      transmute(value = dif[element==\"total_costs\"]/dif[element==\"total_qalys\"],element = \"ICUR\", arm=\"noint\") %>%                      relocate(element, arm) %>%                      ungroup() %>%                      distinct())      loop_psa_df$sample_size  <-  sample_size   sim_size_psa_df <- rbind(sim_size_psa_df,loop_psa_df)    }"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"ceacceaf-and-evpi","dir":"Articles","previous_headings":"","what":"CEAC/CEAF and EVPI","title":"Structural and Parametric Uncertainty","text":"PSA run, additional analyses can performed understand importance behavior uncertainty.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"ceacceaf","dir":"Articles","previous_headings":"CEAC/CEAF and EVPI","what":"CEAC/CEAF","title":"Structural and Parametric Uncertainty","text":"can now use ceac_des function vector willingness pay results PSA generate CEAC CEAF plots.","code":"wtp <- seq(from=0,to=150000,by=1000) ceac_out <-ceac_des(wtp,results)  ggplot(ceac_out,aes(x=wtp,y=prob_best,group=comparator,col=comparator)) +   geom_line()+   xlab(\"Willingness to Pay\") +   ylab(\"Probability of being cost-effective\")+   theme_bw() +   scale_x_continuous(expand = c(0, 0)) +   ggtitle(\"Cost Effectiveness Acceptability Curve (CEAC)\") +   theme(plot.title = element_text(hjust = 0.5)) ggplot(ceac_out,aes(x=wtp,y=prob_best,group=comparator,col=comparator)) +   geom_step()+   xlab(\"Willingness to Pay\") +   ylab(\"Probability of being cost-effective\")+   theme_bw() +   scale_x_continuous(expand = c(0, 0)) +   ggtitle(\"Cost Effectiveness Acceptability Frontier (CEAF)\")+   theme(plot.title = element_text(hjust = 0.5))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/example_uncertainty.html","id":"evpi","dir":"Articles","previous_headings":"CEAC/CEAF and EVPI","what":"EVPI","title":"Structural and Parametric Uncertainty","text":"Similarly ceac_des, function evpi_des also allows compute EVPI.","code":"evpi_out <-evpi_des(wtp,results)  ggplot(evpi_out,aes(x=wtp,y=evpi)) +   geom_line()+   xlab(\"Willingness to Pay\") +   ylab(\"EVPI\")+   theme_bw() +   scale_x_continuous(expand = c(0, 0)) +   ggtitle(\"Expected Value of Perfect Information (EVPI)\") +   theme(plot.title = element_text(hjust = 0.5))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"How to Use the Automatic Input Selector","text":"document explains use set functions related automatic input selector, particularly pick_val_v, pick_psa, create_indicators, model takes care everything terms running deterministic analysis, DSA, PSA, probabilistic DSA, scenario analyses. Note use add_item examples , one just using add_item2, differences way input added using input = {...} argument deploy_env = TRUE (e.g., add_item(input = {pick_val_v(..., deploy_env = TRUE)})).","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"in-a-nutshell","dir":"Articles","previous_headings":"Introduction","what":"In a Nutshell","title":"How to Use the Automatic Input Selector","text":"key function pick_val_v. function essentially hides loop, iterates inputs depending whether parameter vector single length, whether PSA scenario flags active, proceeds select right value. also can consider multiple parameters covaried time scenario DSA analysis. pick_psa function wrapper just calls corresponding function first argument, can used draw distributions. recommendation use “r” functions like rnorm, runif, etc. random seed handled automatically model ensure inputs drawn appropiately. Finally, create_indicators function generate vector 0 1 used scenario analyses DSA, e.g., DSA need iterate corresponding parameters. can start simple example, see data , set parameters, base case values, PSA parameters, DSA, scenario, whether parameter active PSA (vector 0 1s):","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"the-basic-setup","dir":"Articles","previous_headings":"Introduction","what":"The basic setup","title":"How to Use the Automatic Input Selector","text":"’ll build case step step. pick_val_v, need set values base case (base), PSA (psa), sensitivity values (sens). also need set whether currently PSA (psa_ind), whether sensitivity analysis (sens_ind). Finally, need give guidance sensitivity analysis parameters vary iteration (.e., ’s iterating minimum range DSA, util.sick? util.sicker?) give names parameters export named list. simplest case don’t DSA scenario analysis. case function relatively straightforward. set base case values, set PSA values using parameters data, indicate indeed PSA analysis scenario analysis (TRUE), indicate scenario analysis parameters included, finally indicate PSA, first 4 included remaining 3 (defaulting base values). See complex example, now including scenario analyses/DSA, letting model handling things automatically. Note pick_val_v arguments set variables: sens_name_used, psa_bool, sensitivity_bool indicators. except indicators set model automatically, obtained run_sim (sensitivity_names, psa_bool sensitivity_bool, respectively). sens_name_used selected automatically model, example sensitivity_names = \"DSA_min\", \"DSA_max\", model automatically knows one currently active, start \"DSA_min\", iterated relevant parameters, go \"DSA_max\". psa_bool sensitivity_bool boolean flags whether current analysis deterministic/probabilistic standard/scenario(DSA). Since example using run_sim, setting advance. indicators object need set setting inputs add_item, used scenario/DSA analyses (send_ind = sensitivity_bool = TRUE). case, set 1s (length equal number vectors) whenever scenario analysis, otherwise use create_indicators function takes extra arguments. create_indicators creates vector 0 1s, taking value 1 right index going varied. takes extra objects given automatically model: sens, n_sensitivity, sensitivity_names. sensitivity_names comes run_sim mentioned , n_sensitivity also must declared run_sim, number parameters varied, case, 7). sens index analysis currently run, case assume start first index return vector 1 followed 6 0s. Note necessarily use indicator_psa argument pick_val_v. left , understand parameters included PSA. , need provide argument declaring parameters excluded included (vector 0 1s). recap: case, artificially set key variables beforehand, execute pick_val_v function. first run deterministic analysis. Now ’s easy switch probabilistic analysis. ’s easy switch probabilistic scenario analysis.","code":"pick_val_v(base        = l_inputs[[\"base_value\"]],              psa         = pick_psa(                  l_inputs[[\"PSA_dist\"]],                  l_inputs[[\"n\"]],                  l_inputs[[\"a\"]],                  l_inputs[[\"b\"]]),              psa_ind     = TRUE, #PSA is active              sens_ind    = FALSE, #No scenario analysis              names_out   = l_inputs[[\"parameter_name\"]],              indicator   = rep(1,7), #This is only relevant for scenario analysis, set to all 1s              indicator_psa = l_inputs[[\"psa_indicators\"]] #vector of 4 1s and 3 0s.   )  #> $util.sick #> [1] 0.576 #>  #> $util.sicker #> [1] 0.529 #>  #> $cost.sick #> [1] 1671 #>  #> $cost.sicker #> [1] 6114 #>  #> $cost.int #> [1] 1000 #>  #> $coef_noint #> [1] -1.61 #>  #> $HR_int #> [1] 0.8 sens <- 1 n_sensitivity <- length(l_inputs[[1]]) sensitivity_names <- c(\"DSA_min\", \"DSA_max\") #Vector of length 7, a 1 followed by 6 0s, if sens was 2 it would be a c(0,1,0,0,0,0,0) vector  create_indicators(sens,n_sensitivity*length(sensitivity_names),rep(1,length(l_inputs[[1]]))) #> [1] 1 0 0 0 0 0 0  sens_name_used <- \"DSA_min\" psa_bool <- FALSE sensitivity_bool <- FALSE  #deterministic indicators <-  if(sensitivity_bool){ create_indicators(sens,n_sensitivity*length(sensitivity_names),rep(1,length(l_inputs[[1]])))}else{                                 rep(1,length(l_inputs[[1]]))}   #DETERMINISTIC as.data.frame(   pick_val_v(base        = l_inputs[[\"base_value\"]],            psa         = pick_psa(              l_inputs[[\"PSA_dist\"]],              l_inputs[[\"n\"]],              l_inputs[[\"a\"]],              l_inputs[[\"b\"]]),            sens        = l_inputs[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"            psa_ind     = psa_bool, #FALSE            sens_ind    = sensitivity_bool, #FALSE            indicator   = indicators, #all 1s, or a vector of 1 1 and the rest 0s.            names_out   = l_inputs[[\"parameter_name\"]],            indicator_psa = l_inputs[[\"psa_indicators\"]]             ) )  #>   util.sick util.sicker cost.sick cost.sicker cost.int coef_noint HR_int #> 1       0.8         0.5      3000        7000     1000      -1.61    0.8 #PSA psa_bool <- TRUE as.data.frame(   pick_val_v(base        = l_inputs[[\"base_value\"]],            psa         = pick_psa(              l_inputs[[\"PSA_dist\"]],              l_inputs[[\"n\"]],              l_inputs[[\"a\"]],              l_inputs[[\"b\"]]),            sens        = l_inputs[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"            psa_ind     = psa_bool, #FALSE            sens_ind    = sensitivity_bool, #FALSE            indicator   = indicators, #all 1s, or a vector of 1 1 and the rest 0s.            names_out   = l_inputs[[\"parameter_name\"]],            indicator_psa = l_inputs[[\"psa_indicators\"]]             ) ) #>   util.sick util.sicker cost.sick cost.sicker cost.int coef_noint HR_int #> 1     0.761       0.467      2620        5725     1000      -1.61    0.8 #Probabilistic DSA, first parameter being varied as sens = 1 psa_bool <- TRUE sensitivity_bool <- TRUE indicators <-  if(sensitivity_bool){ create_indicators(sens,n_sensitivity*length(sensitivity_names),rep(1,length(l_inputs[[1]])))}else{                                 rep(1,length(l_inputs[[1]]))}  as.data.frame(   pick_val_v(base        = l_inputs[[\"base_value\"]],            psa         = pick_psa(              l_inputs[[\"PSA_dist\"]],              l_inputs[[\"n\"]],              l_inputs[[\"a\"]],              l_inputs[[\"b\"]]),            sens        = l_inputs[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"            psa_ind     = psa_bool, #FALSE            sens_ind    = sensitivity_bool, #FALSE            indicator   = indicators, #all 1s, or a vector of 1 1 and the rest 0s.            names_out   = l_inputs[[\"parameter_name\"]],            indicator_psa = l_inputs[[\"psa_indicators\"]]             ) )  #>   util.sick util.sicker cost.sick cost.sicker cost.int coef_noint HR_int #> 1       0.6        0.48      3989        5818     1000      -1.61    0.8"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"integrating-into-a-model","dir":"Articles","previous_headings":"Introduction","what":"Integrating into a model","title":"How to Use the Automatic Input Selector","text":"now use setup simple model, run deterministic, probabilistic, probabilistic DSA deterministic scenario analysis. Note sens iterator needs adjusted, just measures total number sensitivity iterations. 2 sensitivities 7 parameters , sens go 1 14. 7 parameters, need create iterator_sensitivity variable “reset” index back 1, 2, 3… goes 7, covers DSA_min DSA_max, simply use sens_iterator function.","code":"rm(sens, sens_name_used, sensitivity_bool, psa_bool) #remove global objects that may confuse program  i_sensitivity <-add_item(   iterator_sensitivity = sens_iterator(sens,n_sensitivity)   ) %>%add_item(             indicators = if(sensitivity_bool  & sens_name_used %in% c(\"DSA_min\", \"DSA_max\")){  create_indicators(iterator_sensitivity,n_sensitivity*length(sensitivity_names),rep(1,length(l_inputs[[1]]))) #only for DSA we use this approach               }else{rep(1,length(l_inputs[[1]]))}                               )   i_simple <- add_item() %>%   add_item(     pick_val_v(       base = l_inputs[[\"base_value\"]],       psa = pick_psa(         l_inputs[[\"PSA_dist\"]],         l_inputs[[\"n\"]],         l_inputs[[\"a\"]],         l_inputs[[\"b\"]]),       sens          = l_inputs[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"       psa_ind       = psa_bool, #FALSE       sens_ind      = sensitivity_bool, #FALSE       indicator     = indicators, #all 1s, or a vector of 1 1 and the rest 0s.       names_out     = l_inputs[[\"parameter_name\"]],       indicator_psa = l_inputs[[\"psa_indicators\"]]        )     )    i_arm <- add_item(q_default = util.sick,            c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})   init_event_list <-    add_tte(arm=c(\"noint\",\"int\"), evts = c(\"a1\",\"b1\") ,input={     a1 <- 0     b1 <- 2   })  evt_react_list <-   add_reactevt(name_evt = \"a1\",                input = {})  %>%   add_reactevt(name_evt = \"b1\",                input = {                  q_default = 0                  c_default = 0                   curtime = Inf                })   util_ongoing <- \"q_default\" cost_ongoing <- \"c_default\"  results <- run_sim(     npats=5,                                  n_sim=1,                                     psa_bool = FALSE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   init_event_list = init_event_list,           evt_react_list = evt_react_list,             util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1 ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.05s #> Time to run analysis 1: 0.05s #> Total time to run: 0.05s  summary_results_sim(results[[1]])  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) results <- run_sim(     npats=5,                                 n_sim=2,                                     psa_bool = TRUE,                            arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   init_event_list = init_event_list,           evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity, #this argument can also be removed since it's not used   sensitivity_names = NULL,           #this argument can also be removed since it's not used   sensitivity_bool = FALSE,           #this argument can also be removed since it's not used   n_sensitivity = 1                   #this argument can also be removed since it's not used ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.04s #> Simulation number: 2 #> Time to run simulation 2: 0.09s #> Time to run analysis 1: 0.14s #> Total time to run: 0.14s  summary_results_sim(results[[1]])  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) #DSA analyses, we set n_sensitivity to 7 as we need to iterate over all the parameters results <- run_sim(     npats=5,                                  n_sim=2,                                    psa_bool = TRUE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   init_event_list = init_event_list,          evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(l_inputs[[1]]), #7 parameters   input_out = unlist(l_inputs[[\"parameter_name\"]])  ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 1: 0.12s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 2: 0.12s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 3: 0.12s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 4: 0.12s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 5: 0.13s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 6: 0.12s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 7: 0.12s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 8: 0.12s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 9: 0.12s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 10: 0.12s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 11: 0.12s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 12: 0.12s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 13: 0.13s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 14: 0.12s #> Total time to run: 1.72s  summary_results_sens(results) #>          arm analysis analysis_name     variable                 value #>       <char>    <int>        <char>       <fctr>                <char> #>    1:    int        1       DSA_min        costs 9,783 (7,989; 11,577) #>    2:  noint        1       DSA_min        costs  7,841 (6,047; 9,635) #>    3:    int        2       DSA_min        costs 9,783 (7,989; 11,577) #>    4:  noint        2       DSA_min        costs  7,841 (6,047; 9,635) #>    5:    int        3       DSA_min        costs  3,884 (3,884; 3,884) #>   ---                                                                  #> 1116:  noint       12       DSA_max dutil.sicker              0 (0; 0) #> 1117:    int       13       DSA_max dutil.sicker              0 (0; 0) #> 1118:  noint       13       DSA_max dutil.sicker              0 (0; 0) #> 1119:    int       14       DSA_max dutil.sicker              0 (0; 0) #> 1120:  noint       14       DSA_max dutil.sicker              0 (0; 0)  data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\")) data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean)  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) #Scenario analyses, we set n_sensitivity to 1 as we don't have to iterate over all parameters, each scenario is run only once results <- run_sim(     npats=5,                                  n_sim=2,                                    psa_bool = TRUE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   init_event_list = init_event_list,          evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity,   sensitivity_names = c(\"scenario_1\",\"scenario_2\"),   sensitivity_bool = TRUE,   n_sensitivity = 1,   input_out = unlist(l_inputs[[\"parameter_name\"]]) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 1: 0.13s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 2: 0.12s #> Total time to run: 0.25s  summary_results_sens(results) #>         arm analysis analysis_name     variable                   value #>      <char>    <int>        <char>       <fctr>                  <char> #>   1:    int        1    scenario_1        costs    3,496 (3,496; 3,496) #>   2:  noint        1    scenario_1        costs    1,942 (1,942; 1,942) #>   3:    int        2    scenario_2        costs 13,594 (13,594; 13,594) #>   4:  noint        2    scenario_2        costs    9,710 (9,710; 9,710) #>   5:    int        1    scenario_1       dcosts                0 (0; 0) #>  ---                                                                    #> 156:  noint        2    scenario_2  util.sicker          0.7 (0.7; 0.7) #> 157:    int        1    scenario_1 dutil.sicker                0 (0; 0) #> 158:  noint        1    scenario_1 dutil.sicker                0 (0; 0) #> 159:    int        2    scenario_2 dutil.sicker                0 (0; 0) #> 160:  noint        2    scenario_2 dutil.sicker                0 (0; 0)  data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))   data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),mean)  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"parameters-spread-across-different-levels","dir":"Articles","previous_headings":"Introduction","what":"Parameters spread across different levels","title":"How to Use the Automatic Input Selector","text":"happens inputs single level (e.g., patient level), also simulation, patient, arm, etc levels? case, can still use pick_val_v handle things us, need careful indicators, particularly DSA. example, 10 parameters, 7 set simulation level 3 patient level, pick_val_V simulation level want indicator vector length 7 patient level length 3. DSA, need iterate parameter, need aware index currently run, risk varying first parameters simulation patient level time. create_indicators can handle us telling many parameters gone “” (.e. ones higher hierarchy, simulation level case 0, patient level previous 7 parameters set simulation level). See example. Let’s simply add parameters also now patient level. Note using parameters model, impact can still see really varied. still need create specific indicators category.","code":"#let's set the index to 8th (so it would correspond to the patient level indicator) create_indicators(8,20,c(1,1,1,1,1,1,1),0) #all 0s #> [1] 0 0 0 0 0 0 0  create_indicators(8,20,c(1,1,1),7) #first index is 1! because we know we are at index 8, and we have already gone through 7 iterations #> [1] 1 0 0 l_inputs_pat <- list(parameter_name = list(\"age\",\"sex\"),                  base_value = list(60,1),                  PSA_dist = list(\"rnorm\",\"rbinom\"),                  a=list(60,1),                  b=list(10,0.5),                  n=as.list(rep(1,2)),                  DSA_min = list(30,0),                  DSA_max = list(80,1),                  scenario_1=list(55,1),                  scenario_2=list(45,0),                  psa_indicators = as.list(rep(1,2))                  )  i_sensitivity <- add_item(   iterator_sensitivity = sens_iterator(sens,n_sensitivity) #resets back to 1 if it goes over n_sensitivity   ) %>%   add_item(             indicators = if(sensitivity_bool  & sens_name_used %in% c(\"DSA_min\", \"DSA_max\")){               create_indicators(iterator_sensitivity,                                  n_sensitivity*length(sensitivity_names),                                 rep(1,length(l_inputs[[1]])))              }else{                 rep(1,length(l_inputs[[1]]))               }           ) %>%   add_item(             indicators_pat = if(sensitivity_bool  & sens_name_used %in% c(\"DSA_min\", \"DSA_max\")){               create_indicators(iterator_sensitivity,                                 n_sensitivity*length(sensitivity_names),                                 rep(1,length(l_inputs_pat[[1]])),                                 length(l_inputs[[1]]))              }else{                 rep(1,length(l_inputs_pat[[1]]))               }           )       i_pat <- add_item() %>%   add_item(     pick_val_v(       base = l_inputs_pat[[\"base_value\"]],       psa = pick_psa(         l_inputs_pat[[\"PSA_dist\"]],         l_inputs_pat[[\"n\"]],         l_inputs_pat[[\"a\"]],         l_inputs_pat[[\"b\"]]),       sens          = l_inputs_pat[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"       psa_ind       = psa_bool, #FALSE       sens_ind      = sensitivity_bool, #TRUE       indicator     = indicators_pat, #all 1s, or a vector of 1 1 and the rest 0s.       names_out     = l_inputs_pat[[\"parameter_name\"]],       indicator_psa = l_inputs_pat[[\"psa_indicators\"]]        )     )   results <- run_sim(     npats=5,                                  n_sim=2,                                    psa_bool = FALSE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   common_pt_inputs = i_pat,   init_event_list = init_event_list,          evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(l_inputs[[1]]) + length(l_inputs_pat[[1]]), #9 parameters   input_out = c(unlist(l_inputs[[\"parameter_name\"]]),unlist(l_inputs_pat[[\"parameter_name\"]])) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 1: 0.14s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 2: 0.13s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 3: 0.14s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 4: 0.13s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.08s #> Time to run analysis 5: 0.14s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 6: 0.14s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 7: 0.13s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 8: 0.14s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 9: 0.13s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 10: 0.14s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 11: 0.14s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 12: 0.13s #> Analysis number: 13 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 13: 0.14s #> Analysis number: 14 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 14: 0.14s #> Analysis number: 15 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 15: 0.13s #> Analysis number: 16 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 16: 0.14s #> Analysis number: 17 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 17: 0.14s #> Analysis number: 18 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.22s #> Time to run analysis 18: 0.28s #> Total time to run: 2.58s  summary_results_sens(results) #>          arm analysis analysis_name     variable                value #>       <char>    <int>        <char>       <fctr>               <char> #>    1:    int        1       DSA_min        costs 7,768 (7,768; 7,768) #>    2:  noint        1       DSA_min        costs 5,826 (5,826; 5,826) #>    3:    int        2       DSA_min        costs 7,768 (7,768; 7,768) #>    4:  noint        2       DSA_min        costs 5,826 (5,826; 5,826) #>    5:    int        3       DSA_min        costs 3,884 (3,884; 3,884) #>   ---                                                                 #> 1580:  noint       16       DSA_max dutil.sicker             0 (0; 0) #> 1581:    int       17       DSA_max dutil.sicker             0 (0; 0) #> 1582:  noint       17       DSA_max dutil.sicker             0 (0; 0) #> 1583:    int       18       DSA_max dutil.sicker             0 (0; 0) #> 1584:  noint       18       DSA_max dutil.sicker             0 (0; 0)   data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))   data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\",\"age\",\"sex\"),mean)  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"multiple-parameters-covaried","dir":"Articles","previous_headings":"Introduction","what":"Multiple parameters covaried","title":"How to Use the Automatic Input Selector","text":"WARDEN also allows parameters changed together DSA, programmer believes e.g, age sex take min max value together, can done switching 0-1 vector vector takes integer values reflect DSA scenario number. See applied, also assume utilities costs varied together. case, indicators simplified, need 1) correct index (provided iterator_sensitivity) 2) dsa indicators index understand parameters covaried. also need make sure adjust n_sensitivity run_sim new number dsa iterations (5).","code":"l_inputs <- list(parameter_name = list(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\"),                  base_value = list(0.8,0.5,3000,7000,1000,log(0.2),0.8),                  PSA_dist = list(\"rnorm\",\"rbeta_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rgamma_mse\",\"rnorm\",\"rlnorm\"),                  a=list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)),                  b=lapply(list(0.8,0.5,3000,7000,1000,log(0.2),log(0.8)), function(x) abs(x/5)),                  n=as.list(rep(1,7)),                  DSA_min = list(0.6,0.3,1000,5000,800,log(0.1),0.5),                  DSA_max = list(0.9,0.7,5000,9000,2000,log(0.4),0.9),                  scenario_1=list(0.6,0.3,1000,5000,800,log(0.1),0.5),                  scenario_2=list(0.9,0.7,5000,9000,2000,log(0.4),0.9),                  psa_indicators = as.list(c(rep(1,4),rep(0,3))),                  dsa_indicators = as.list(c(1,1,2,2,2,3,4))  #covary utilities together, costs together                  )  l_inputs_pat <- list(parameter_name = list(\"age\",\"sex\"),                  base_value = list(60,1),                  PSA_dist = list(\"rnorm\",\"rbinom\"),                  a=list(60,1),                  b=list(10,0.5),                  n=as.list(rep(1,2)),                  DSA_min = list(30,0),                  DSA_max = list(80,1),                  scenario_1=list(55,1),                  scenario_2=list(45,0),                  psa_indicators = as.list(rep(1,2)),                  dsa_indicators = list(5,5) #will be 5th analysis done                  )  i_sensitivity <- add_item(   iterator_sensitivity = sens_iterator(sens,n_sensitivity) #resets back to 1 if it goes over n_sensitivity   )    i_simple <- add_item() %>%   add_item(     pick_val_v(       base = l_inputs[[\"base_value\"]],       psa = pick_psa(         l_inputs[[\"PSA_dist\"]],         l_inputs[[\"n\"]],         l_inputs[[\"a\"]],         l_inputs[[\"b\"]]),       sens          = l_inputs[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"       psa_ind       = psa_bool, #FALSE       sens_ind      = sensitivity_bool, #TRUE       indicator     = l_inputs[[\"dsa_indicators\"]],        sens_iterator = iterator_sensitivity,       indicator_sens_binary = FALSE,       names_out     = l_inputs[[\"parameter_name\"]],       indicator_psa = l_inputs[[\"psa_indicators\"]] ,       distributions = l_inputs[[\"PSA_dist\"]],       covariances   = l_inputs[[\"b\"]]       )     )    i_pat <- add_item() %>%   add_item(     pick_val_v(       base = l_inputs_pat[[\"base_value\"]],       psa = pick_psa(         l_inputs_pat[[\"PSA_dist\"]],         l_inputs_pat[[\"n\"]],         l_inputs_pat[[\"a\"]],         l_inputs_pat[[\"b\"]]),       sens          = l_inputs_pat[[sens_name_used]], #e.g., sens_name_used = \"DSA_min\"       psa_ind       = psa_bool, #FALSE       sens_ind      = sensitivity_bool, #TRUE       indicator     = l_inputs_pat[[\"dsa_indicators\"]],        sens_iterator = iterator_sensitivity,       indicator_sens_binary = FALSE,       names_out     = l_inputs_pat[[\"parameter_name\"]],       indicator_psa = l_inputs_pat[[\"psa_indicators\"]],       distributions = l_inputs_pat[[\"PSA_dist\"]],       covariances   = l_inputs_pat[[\"b\"]]       )     )   results <- run_sim(     npats=5,                                  n_sim=2,                                    psa_bool = FALSE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   common_pt_inputs = i_pat,   init_event_list = init_event_list,          evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(unique(l_inputs[[\"dsa_indicators\"]])) + length(unique(l_inputs_pat[[\"dsa_indicators\"]])), #5 parameters!!!   input_out = c(unlist(l_inputs[[\"parameter_name\"]]),unlist(l_inputs_pat[[\"parameter_name\"]])) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 1: 0.13s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 2: 0.13s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 3: 0.13s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 4: 0.12s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 5: 0.14s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 6: 0.12s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 7: 0.13s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 8: 0.13s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 9: 0.13s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 10: 0.13s #> Total time to run: 1.29s  summary_results_sens(results) #>         arm analysis analysis_name     variable                value #>      <char>    <int>        <char>       <fctr>               <char> #>   1:    int        1       DSA_min        costs 7,768 (7,768; 7,768) #>   2:  noint        1       DSA_min        costs 5,826 (5,826; 5,826) #>   3:    int        2       DSA_min        costs 3,496 (3,496; 3,496) #>   4:  noint        2       DSA_min        costs 1,942 (1,942; 1,942) #>   5:    int        3       DSA_min        costs 7,768 (7,768; 7,768) #>  ---                                                                 #> 876:  noint        8       DSA_max dutil.sicker             0 (0; 0) #> 877:    int        9       DSA_max dutil.sicker             0 (0; 0) #> 878:  noint        9       DSA_max dutil.sicker             0 (0; 0) #> 879:    int       10       DSA_max dutil.sicker             0 (0; 0) #> 880:  noint       10       DSA_max dutil.sicker             0 (0; 0)   data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))   data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\",\"age\",\"sex\"),mean)  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/inputs_selector.html","id":"parameters-that-are-vectors","dir":"Articles","previous_headings":"Introduction","what":"Parameters that are vectors","title":"How to Use the Automatic Input Selector","text":"Now ready handle cases. approach shown yet parameters vectors instead length 1. case, approach previous one, parameters varied together. add l_inputs_pat new parameter length 2 multivariate normal. can seen DSA, now straightforward switch probabilistic DSA, deterministic case, standard PSA.","code":"l_inputs_pat <- list(parameter_name = list(\"age\",\"sex\", \"v_state\"),                  base_value = list(60,1, c(10,20)),                  PSA_dist = list(\"rnorm\",\"rbinom\",\"mvrnorm\"),                  a=list(60,1,c(10,20)),                  b=list(10,0.5,matrix(c(2,1,4,1),2,2)),                  n=as.list(rep(1,3)),                  DSA_min = list(30,0, c(5,10)),                  DSA_max = list(80,1, c(15,25)),                  scenario_1=list(55,1, c(12,21)),                  scenario_2=list(45,0, c(16,10)),                  psa_indicators = list(1,1,c(1,0)), #we vary the first one but not the second one in PSA!                  dsa_indicators = list(5,5,c(6,6))                  )   results <- run_sim(     npats=5,                                  n_sim=2,                                    psa_bool = FALSE,                           arm_list = c(\"int\", \"noint\"),                common_all_inputs = i_simple,   unique_pt_inputs  = i_arm,   common_pt_inputs = i_pat,   init_event_list = init_event_list,          evt_react_list = evt_react_list,            util_ongoing_list = util_ongoing,   cost_ongoing_list = cost_ongoing,   ipd = 1,   sensitivity_inputs = i_sensitivity,   sensitivity_names = c(\"DSA_min\",\"DSA_max\"),   sensitivity_bool = TRUE,   n_sensitivity = length(unique(l_inputs[[\"dsa_indicators\"]])) + length(unique(l_inputs_pat[[\"dsa_indicators\"]])), #6 parameters!   input_out = c(unlist(l_inputs[[\"parameter_name\"]]),unlist(l_inputs_pat[[\"parameter_name\"]])) ) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 1: 0.13s #> Analysis number: 2 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 2: 0.13s #> Analysis number: 3 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 3: 0.13s #> Analysis number: 4 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 4: 0.13s #> Analysis number: 5 #> Simulation number: 1 #> Time to run simulation 1: 0.07s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 5: 0.13s #> Analysis number: 6 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 6: 0.13s #> Analysis number: 7 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 7: 0.13s #> Analysis number: 8 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 8: 0.13s #> Analysis number: 9 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.07s #> Time to run analysis 9: 0.13s #> Analysis number: 10 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 10: 0.12s #> Analysis number: 11 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 11: 0.13s #> Analysis number: 12 #> Simulation number: 1 #> Time to run simulation 1: 0.06s #> Simulation number: 2 #> Time to run simulation 2: 0.06s #> Time to run analysis 12: 0.12s #> Total time to run: 1.55s  summary_results_sens(results) #>          arm analysis analysis_name     variable                value #>       <char>    <int>        <char>       <fctr>               <char> #>    1:    int        1       DSA_min        costs 7,768 (7,768; 7,768) #>    2:  noint        1       DSA_min        costs 5,826 (5,826; 5,826) #>    3:    int        2       DSA_min        costs 3,496 (3,496; 3,496) #>    4:  noint        2       DSA_min        costs 1,942 (1,942; 1,942) #>    5:    int        3       DSA_min        costs 7,768 (7,768; 7,768) #>   ---                                                                 #> 1052:  noint       10       DSA_max dutil.sicker             0 (0; 0) #> 1053:    int       11       DSA_max dutil.sicker             0 (0; 0) #> 1054:  noint       11       DSA_max dutil.sicker             0 (0; 0) #> 1055:    int       12       DSA_max dutil.sicker             0 (0; 0) #> 1056:  noint       12       DSA_max dutil.sicker             0 (0; 0)   data_sensitivity <- bind_rows(map_depth(results,2, \"merged_df\"))  #v_state is length > 1, so it does not appear in merged_df as it would break the data. We can get it manually and print it v_state_avg <- tibble( v_state =     unlist(       lapply(         map_depth(results,2, \"v_state\"), function(x) {             vecs <- list(x[[1]]$int, x[[1]]$noint, x[[2]]$int, x[[2]]$noint)             paste(colMeans(do.call(rbind, vecs)), collapse=\", \")         }       )     )   )  data_sensitivity %>% group_by(sensitivity) %>% summarise_at(c(\"util.sick\",\"util.sicker\",\"cost.sick\",\"cost.sicker\",\"cost.int\",\"coef_noint\",\"HR_int\",\"age\",\"sex\"),mean) %>%   bind_cols(v_state_avg)  %>%   kable() %>%   kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/warden_explained.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"WARDEN Explained","text":"document explains logic behind WARDEN main approach simulate discrete event simulations, well explaining briefly rationale certain design decisions.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/warden_explained.html","id":"in-a-nutshell","dir":"Articles","previous_headings":"Introduction","what":"In a Nutshell","title":"WARDEN Explained","text":"WARDEN main simulation engine core nothing nested loop different levels. However, work need delay execution inputs provided user, relevant inputs provided add_tte, add_item/add_item2 add_reactevt substituted delayed execution stored lists. Load inputs sequentially. ’s unnamed list, unlist assign “sens” input list. Load inputs sequentially. ’s unnamed list, unlist store components. “sens” list integrated new list “simulation” input list. Load inputs sequentially. ’s unnamed list, unlist store components. “simulation” list integrated new list “” input list. Load inputs sequentially. ’s unnamed list, unlist store components. “” list integrated new list “arm” input list. Load initial time events. First look initial time event expression declared user; found, look input list already declared; found, set equal Inf. Select next event checking event minimum time event; case ties, untie using order declared add_tte initial time events. events left, set curtime = Inf (end simulation) Evaluate reaction event looking relevant expression list event reactions specific “simulation” done, compute outputs vectorized (discount outcomes relevant based type, aggregate data relevant, obtain timed frequency outputs needed, etc.) debug mode store log relevant data loaded changed event reactions, exported simulation stops (also error). WARDEN allows continue error (though recommended) WARDEN handles random numbers automatically, setting seeds differently simulation, patient arm level. WARDEN makes sure starting seed cloned patient across interventions. However, conditional statements can alter random state R conditional trigger random expressions (e.g., (arm==2){runif(1)}else{5}) change per intervention. keep random number cloned intended, ’s recommended pre-draw random numbers type random object used use (see Example Sick-Sicker-Dead model - Random Number Streams & Luck Adjustment vignette information). WARDEN uses L’Ecuyer-CMRG random number generator. way WARDEN processes events e.g., modify_item looking inputs currently available relevant input list, evaluating passed list (e.g., modify_item_seq(list(= 1, b = + 1))) adding resulting objects (b) parent environment well relevant input list storage. latest update WARDEN, objects included modify_item stored relevant input list available evaluation, e.g.,","code":"add_reactevt(name_evt = \"event_1\", input = {   z <- 2 #this will be stored in the main input list, and will be available in the next event reaction!       modify_item_seq(list(a = 1, b = z + 1, z = z)) #this will work, because z is available      c <- b + 5  }  #The above expression is equivalent to writing:  add_reactevt(name_evt = \"event_1\", input = {   z <- 2    a <- 1   b <- z + 1   modify_item(list(a = a, b = b, z = z))       c <- b + 5 #b will be available  }   #As well as add_reactevt(name_evt = \"event_1\", input = {   modify_item_seq(list(a = 1, z = 2, b = z + 1))  #modify_item_seq evaluates sequentially, so the value of z will be available for b        c <- b + 5 #b will be available  }  #And add_reactevt(name_evt = \"event_1\", input = {   a  <- 1   z  <- 2   b  <- z + 1    c  <- b + 5 #b will be available  }  #But note that this will not work! add_reactevt(name_evt = \"event_1\", input = {   modify_item(list(a = 1, z = 2, b = z + 1))  #modify_item is faster but does not evaluate sequentially (all at once), so the value of z will NOT be available for b }"},{"path":"https://jsanchezalv.github.io/WARDEN/articles/warden_explained.html","id":"storing-inputs-making-it-faster","dir":"Articles","previous_headings":"Introduction","what":"Storing Inputs, Making it Faster","title":"WARDEN Explained","text":"Multiple ways storing inputs processing events can thought . 1) data.frames, 2) lists, 3) environments, 4) utilize C++ implementation (among others). WARDEN uses lists store inputs process events. Data.frames can slow memory-intense manipulate, avoided purpose. Lists environments can behave quite similar, environments modified reference, can speed things , give freedom user declare set event reactions instead requiring declare modify_item. However, using environments “natural” R expressions (e.g., <- 1; b <- + 1instead modify_item_seq(list(= 1, b = + 1))) made debugging mode harder handle. internal experiments showed 20% 40% speed increase switching lists environments normal mode. [Changed WARDEN 1.0] recent update, now user need use modify_item modify_item_seq, transition environment performed. limitation debugging mode handled extract abstract syntax tree event reactions looking type assignments. limitation “dynamic” assignments (e.g., assign(paste0(\"x_\",), 5) created loop) captured debugging engine, therefore excluded debugging log file. user try assign variables explicitly whenever possible, e.g., x_1 <- 5. C++ implementation avoided purpose WARDEN user-friendly give user much freedom possible define inputs. likely much faster, implementation C++ require careful handling every user input, likely forcing us restrict specific data types functions.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/articles/warden_explained.html","id":"parallel-engine-approach","dir":"Articles","previous_headings":"Introduction","what":"Parallel engine approach","title":"WARDEN Explained","text":"Furthermore, parallel core/thread implementation also available simulation level, .e., perform “simulation” loop parallel. reason select simulation patient patient normally takes small amount time run, simulation level offers right balance terms time run. However, user expect slightly efficient (perhaps 20-40% speed increase medium large simulations), opposed radically faster. Two factors important: number simulations run (n_sim), size simulation (given number events number patients arms). n_sim small, may worth use parallel approach time loss set different cores/threads (normally 2 5 seconds), simulations runs fast simple (couple seconds ) may worth . Even n_sim large simulation complex, efficiency gain may ~20-40%, even using >5 cores. reason RAM use increases fast R creates new sessions duplicated data (’s shared among cores/threads), medium large simulation can easily become >2 GB RAM use per simulation, systems large processing power large RAM (e.g., 32 64GB) benefit approach. parallel implementation also limitations terms exporting logs error simulation (due parallel set-), approach recommended user quite confident simulation run without issues.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Javier Sanchez Alvarez. Author, maintainer. Gabriel Lemyre. Contributor. Valerie Aponte Ribero. Contributor.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Sanchez Alvarez J (2025). WARDEN: Workflows Health Technology Assessments R using Discrete EveNts. R package version 1.2.2, https://jsanchezalv.github.io/WARDEN/.","code":"@Manual{,   title = {WARDEN: Workflows for Health Technology Assessments in R using Discrete EveNts},   author = {Javier {Sanchez Alvarez}},   year = {2025},   note = {R package version 1.2.2},   url = {https://jsanchezalv.github.io/WARDEN/}, }"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Workflows for Health Technology Assessments in R using Discrete EveNts","text":"WARDEN user-friendly package facilitates use discrete event simulations without resource constraints cost-effectiveness analysis. package supports flexible, transparent, practical approach discrete event simulation keeping acceptable performance. current version supports: Discrete event simulation models, Markov/semi-Markov models hybrid models using parallel non-parallel engines Seamlessly integrating data.frames objects model Delayed execution main inputs facilitate readability model Implementation structural parameter uncertainty Helper functions facilitate drawing time events use hazard ratios, well functions facilitate transparency Performing cost-effectiveness uncertainty analysis recommended user checks vignettes, first simple Sick-Sicker-Dead model complex model early breast cancer. markov example shows run cohort Markov model using modeling framework. Similarly, simulation based Markov model run. Structural parametric uncertainty explored corresponding vignette. IPD vignette shows WARDEN can used individual patient data available.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Workflows for Health Technology Assessments in R using Discrete EveNts","text":"look package home site details documentation specific tutorials. details code, check Github repository, CRAN site.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Workflows for Health Technology Assessments in R using Discrete EveNts","text":"WARDEN can now installed directly CRAN repo via","code":"install.packages(\"WARDEN\") #CRAN version   # install.packages(\"devtools\") devtools::install_github(\"jsanchezalv/WARDEN\", ref=\"main\") #github version"},{"path":"https://jsanchezalv.github.io/WARDEN/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Workflows for Health Technology Assessments in R using Discrete EveNts","text":"use WARDEN, please contact authors date appropriate citation.","code":""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":null,"dir":"Reference","previous_headings":"","what":"Define parameters that may be used in model calculations (list) — add_item","title":"Define parameters that may be used in model calculations (list) — add_item","text":"Define parameters may used model calculations (list)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define parameters that may be used in model calculations (list) — add_item","text":"","code":"add_item(.data = NULL, ...)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define parameters that may be used in model calculations (list) — add_item","text":".data Existing data ... Items define simulation","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define parameters that may be used in model calculations (list) — add_item","text":"list items","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define parameters that may be used in model calculations (list) — add_item","text":"functions add/modify events/inputs use lists. Whenever several inputs/events added modified, recommended group within one function, reduces computation cost. rather use two add_item list one element, better group single add_item list two elements. Whenever function directly implemented must evaluated later object name attached (e.g., pick_val_v), implemented first add_item() (empty content) avoid confusing .data argument, wrapping function within substitute()","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define parameters that may be used in model calculations (list) — add_item","text":"","code":"library(magrittr)  add_item(fl.idfs = 0) #> $fl.idfs #> [1] 0 #>  add_item(util_idfs = if(psa_bool){rnorm(1,0.8,0.2)} else{0.8}, util.mbc = 0.6, cost_idfs = 2500) #> $util_idfs #> if (psa_bool) { #>     rnorm(1, 0.8, 0.2) #> } else { #>     0.8 #> } #>  #> $util.mbc #> [1] 0.6 #>  #> $cost_idfs #> [1] 2500 #>  common_inputs <- add_item() %>% add_item(pick_val_v(   base      = l_statics[[\"base\"]],   psa       = pick_psa(     l_statics[[\"function\"]],     l_statics[[\"n\"]],     l_statics[[\"a\"]],     l_statics[[\"b\"]]   ),   sens      = l_statics[[sens_name_used]],   psa_ind   = psa_bool,   sens_ind  = sensitivity_bool,   indicator = indicators_statics,   names_out = l_statics[[\"parameter_name\"]] ) )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":null,"dir":"Reference","previous_headings":"","what":"Define parameters that may be used in model calculations (uses expressions) — add_item2","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":"Define parameters may used model calculations (uses expressions)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":"","code":"add_item2(.data = NULL, input)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":".data Existing data input Items define simulation expression (.e., using )","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":"substituted expression evaluated engine","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":"functions add/modify events/inputs use lists. chaining together add_item2, just append expressions together order established. using pick_val_v, note used deploy_env = TRUE argument add_item2 process correctly.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_item2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define parameters that may be used in model calculations (uses expressions) — add_item2","text":"","code":"library(magrittr)  add_item2(input = {fl.idfs <-  0}) #> { #>     fl.idfs <- 0 #> } add_item2(input = {  util_idfs <- if(psa_bool){rnorm(1,0.8,0.2)} else{0.8}  util.mbc <- 0.6  cost_idfs <- 2500}) #> { #>     util_idfs <- if (psa_bool) { #>         rnorm(1, 0.8, 0.2) #>     } #>     else { #>         0.8 #>     } #>     util.mbc <- 0.6 #>     cost_idfs <- 2500 #> } common_inputs <- add_item2(input = { pick_val_v(   base      = l_statics[[\"base\"]],   psa       = pick_psa(     l_statics[[\"function\"]],     l_statics[[\"n\"]],     l_statics[[\"a\"]],     l_statics[[\"b\"]]   ),   sens      = l_statics[[sens_name_used]],   psa_ind   = psa_bool,   sens_ind  = sensitivity_bool,   indicator = indicators_statics,   names_out = l_statics[[\"parameter_name\"]],   deploy_env = TRUE #Note this option must be active if using it at add_item2 ) } )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":null,"dir":"Reference","previous_headings":"","what":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":"Define modifications events, costs, utilities, items affected occurrence event","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":"","code":"add_reactevt(.data = NULL, name_evt, input)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":".data Existing data event reactions name_evt Name event reactions defined. input Expressions define happens event, using functions defined Details section","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":"named list event name, inside substituted expression saved later evaluation","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":"series objects can used context help define event reactions. following functions may used define event reactions within add_reactevt() function: modify_item() | Adds & Modifies items/flags/variables future events (consider sequential) modify_item_seq() | Adds & Modifies items/flags/variables future events sequential manner new_event() | Adds events vector events patient modify_event() | Modifies existing events changing time Apart items defined add_item(), can also use standard variables always defined within simulation: curtime | Current event time (numeric) prevtime | Time previous event (numeric) cur_evtlist | Named vector events yet happen patient (named numeric vector) evt | Current event processed (character) | Patient iterated (character) simulation | Simulation iterated (numeric) model run curtime set Inf, event terminates model modify curtime set Inf. user can use extract_from_reactions function output obtain data.frame relationships defined reactions model.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_reactevt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define the modifications to other events, costs, utilities, or other items affected by the occurrence of the event — add_reactevt","text":"","code":"add_reactevt(name_evt = \"start\",input = {}) #> $start #> $start$react #> { #> } #>  #>  add_reactevt(name_evt = \"idfs\",input = {modify_item(list(\"fl.idfs\"= 0))}) #> $idfs #> $idfs$react #> { #>     modify_item(list(fl.idfs = 0)) #> } #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":null,"dir":"Reference","previous_headings":"","what":"Define events and the initial event time — add_tte","title":"Define events and the initial event time — add_tte","text":"Define events initial event time","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define events and the initial event time — add_tte","text":"","code":"add_tte(.data = NULL, arm, evts, other_inp = NULL, input)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define events and the initial event time — add_tte","text":".data Existing data initial event times arm intervention events initial event times defined evts vector names events other_inp vector input variables saved simulation input definition initial event times events listed evts argument","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define events and the initial event time — add_tte","text":"list initial events event times","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define events and the initial event time — add_tte","text":"Events need separately defined intervention. event defined list, user needs add reaction event using add_reactevt() function determine calculations happen event.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/add_tte.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define events and the initial event time — add_tte","text":"","code":"add_tte(arm=\"int\",evts = c(\"start\",\"ttot\",\"idfs\",\"os\"), input={ start <- 0 idfs <- draw_tte(1,'lnorm',coef1=2, coef2=0.5) ttot <- min(draw_tte(1,'lnorm',coef1=1, coef2=4),idfs) os <- draw_tte(1,'lnorm',coef1=0.8, coef2=0.2) }) #> $int #> $int$expr #> { #>     start <- 0 #>     idfs <- draw_tte(1, \"lnorm\", coef1 = 2, coef2 = 0.5) #>     ttot <- min(draw_tte(1, \"lnorm\", coef1 = 1, coef2 = 4), idfs) #>     os <- draw_tte(1, \"lnorm\", coef1 = 0.8, coef2 = 0.2) #> } #>  #> $int$evts #> [1] \"start\" \"ttot\"  \"idfs\"  \"os\"    #>  #> $int$other_inp #> NULL #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ast_as_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","title":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","text":"Transform substituted expression Abstract Syntax Tree (AST) list","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ast_as_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","text":"","code":"ast_as_list(ee)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ast_as_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","text":"ee Substituted expression","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ast_as_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","text":"Nested list Abstract Syntax Tree (AST)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ast_as_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a substituted expression to its Abstract Syntax Tree (AST) as a list — ast_as_list","text":"","code":"expr <- substitute({  a <- sum(5+7)  modify_item(list(afsa=ifelse(TRUE,\"asda\",NULL)))  modify_item_seq(list(      o_other_q_gold1 = if(gold == 1) { utility } else { 0 },      o_other_q_gold2 = if(gold == 2) { utility } else { 0 },      o_other_q_gold3 = if(gold == 3) { utility } else { 0 },      o_other_q_gold4 = if(gold == 4) { utility } else { 0 },      o_other_q_on_dup = if(on_dup) { utility } else { 0 }   ))  if(a==1){   modify_item(list(a=list(6+b)))      modify_event(list(e_exn = curtime + 14 / days_in_year + qexp(rnd_exn, r_exn))) } else{   modify_event(list(e_exn = curtime + 14 / days_in_year + qexp(rnd_exn, r_exn)))   if(a>6){     modify_item(list(a=8))   }    }   if (sel_resp_incl == 1 & on_dup == 1) {      modify_event(list(e_response = curtime, z = 6))    }  })   out <- ast_as_list(expr)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ceac_des.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","title":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","text":"Calculate cost-effectiveness acceptability curve (CEAC) DES model PSA result","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ceac_des.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","text":"","code":"ceac_des(wtp, results, interventions = NULL, sensitivity_used = 1)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ceac_des.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","text":"wtp Vector length >=1 willingness pay results list object returned run_sim() interventions character vector names interventions used analysis sensitivity_used Integer signaling sensitivity analysis use","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ceac_des.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","text":"data frame CEAC results","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/ceac_des.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the cost-effectiveness acceptability curve (CEAC) for a DES model with a PSA result — ceac_des","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))  ceac_des(seq(from=10000,to=500000,by=10000),res) #> # A tibble: 100 × 3 #> # Groups:   wtp [50] #>      wtp comparator prob_best #>    <dbl> <chr>          <dbl> #>  1 10000 int                0 #>  2 10000 noint              1 #>  3 20000 int                0 #>  4 20000 noint              1 #>  5 30000 int                0 #>  6 30000 noint              1 #>  7 40000 int                0 #>  8 40000 noint              1 #>  9 50000 int                0 #> 10 50000 noint              1 #> # ℹ 90 more rows"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional dirichlet values — cond_dirichlet","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"Calculate conditional dirichlet values","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"","code":"cond_dirichlet(alpha, i, xi, full_output = FALSE)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"alpha mean vector index known parameter (1-based index) xi known value -th parameter (>0) full_output boolean indicating whether return full list parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"List length 2, one new mu covariance parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"Function compute conditional dirichlet values","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_dirichlet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional dirichlet values — cond_dirichlet","text":"","code":"alpha <- c(2, 3, 4) i <- 2  # Index of the known parameter xi <- 0.5  # Known value of the second parameter  # Compute the conditional alpha parameters with full output cond_dirichlet(alpha, i, xi, full_output = TRUE) #> [1] 0.1666667 0.5000000 0.3333333"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional multivariate normal values — cond_mvn","title":"Calculate conditional multivariate normal values — cond_mvn","text":"Calculate conditional multivariate normal values","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional multivariate normal values — cond_mvn","text":"","code":"cond_mvn(mu, Sigma, i, xi, full_output = FALSE)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional multivariate normal values — cond_mvn","text":"mu mean vector Sigma covariance matrix index known parameter (1-based index) xi known value -th parameter full_output boolean indicating whether return full list parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional multivariate normal values — cond_mvn","text":"List length 2, one new mu covariance parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate conditional multivariate normal values — cond_mvn","text":"Function compute conditional multivariate normal values","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/cond_mvn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional multivariate normal values — cond_mvn","text":"","code":"mu <- c(1, 2, 3) Sigma <- matrix(c(0.2, 0.05, 0.1,                    0.05, 0.3, 0.05,                    0.1, 0.05, 0.4), nrow = 3)  i <- 1:2  # Index of the known parameter xi <- c(1.2,2.3)  # Known value of the first parameter  cond_mvn(mu, Sigma, i, xi,full_output = TRUE) #> $mean #> [1] 1.200000 2.300000 3.121739 #>  #> $covariance #>      [,1] [,2]      [,3] #> [1,]    0    0 0.0000000 #> [2,]    0    0 0.0000000 #> [3,]    0    0 0.3478261 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"Creates vector indicators (0 1) sensitivity/DSA analysis","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"","code":"create_indicators(sens, n_sensitivity, elem, n_elem_before = 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"sens current analysis iterator n_sensitivity total number analyses run elem vector 0s 1s elements iterate (1 = parameter included scenario/DSA) n_elem_before Sum 1s (# parameters included scenario/DSA) go elem","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"Numeric vector composed 0 1, value 1 used pick_val_v pick corresponding index sens argument","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"n_elem_before used several indicators want used (e.g., patient level common level inputs) facilitating readibility code","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/create_indicators.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a vector of indicators (0 and 1) for sensitivity/DSA analysis — create_indicators","text":"","code":"create_indicators(10,20,c(1,1,1,1)) #> [1] 0 0 0 0 create_indicators(7,20,c(1,0,0,1,1,1,0,0,1,1),2) #>  [1] 0 0 0 0 0 0 0 0 1 0"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":null,"dir":"Reference","previous_headings":"","what":"Cycle discounting — disc_cycle","title":"Cycle discounting — disc_cycle","text":"Cycle discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cycle discounting — disc_cycle","text":"","code":"disc_cycle(   lcldr = 0.035,   lclprvtime = 0,   cyclelength,   lclcurtime,   lclval,   starttime = 0 )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cycle discounting — disc_cycle","text":"lcldr discount rate lclprvtime time previous event simulation cyclelength cycle length lclcurtime time current event simulation lclval  value discounted starttime start time accrual cycle costs (0)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cycle discounting — disc_cycle","text":"Double based cycle discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cycle discounting — disc_cycle","text":"Note function counts extremes interval, example consider 25 cycles, disc_cycle_v leave right interval open","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cycle discounting — disc_cycle","text":"","code":"disc_cycle(lcldr=0.035, lclprvtime=0, cyclelength=1/12, lclcurtime=2, lclval=500,starttime=0) #> [1] 12079.88"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":null,"dir":"Reference","previous_headings":"","what":"Cycle discounting for vectors — disc_cycle_v","title":"Cycle discounting for vectors — disc_cycle_v","text":"Cycle discounting vectors","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cycle discounting for vectors — disc_cycle_v","text":"","code":"disc_cycle_v(   lcldr = 0.035,   lclprvtime = 0,   cyclelength,   lclcurtime,   lclval,   starttime = 0,   max_cycles = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cycle discounting for vectors — disc_cycle_v","text":"lcldr discount rate lclprvtime time previous event simulation cyclelength cycle length lclcurtime time current event simulation lclval  value discounted starttime start time accrual cycle costs (0) max_cycles maximum number cycles","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cycle discounting for vectors — disc_cycle_v","text":"Double vector based cycle discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cycle discounting for vectors — disc_cycle_v","text":"function per cycle discounting, .e., considers cost/qaly accrued per cycles, performs automatically without needing create new events. can accommodate changes cycle length/value/starttime (e.g., case induction maintenance doses) within item.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_cycle_v.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cycle discounting for vectors — disc_cycle_v","text":"","code":"disc_cycle_v(lcldr=0.03, lclprvtime=0, cyclelength=1/12, lclcurtime=2, lclval=500,starttime=0) #> [1] 11666.54 disc_cycle_v(  lcldr=0.000001,  lclprvtime=0,  cyclelength=1/12,  lclcurtime=2,  lclval=500,  starttime=0,  max_cycles = 4) #> [1] 2000  #Here we have a change in cycle length, max number of cylces and starttime at time 2  #(e.g., induction to maintenance) #In the model, one would do this by redifining cycle_l, max_cycles and starttime  #of the corresponding item at a given event time.  disc_cycle_v(lcldr=0,  lclprvtime=c(0,1,2,2.5),  cyclelength=c(1/12, 1/12,1/2,1/2),  lclcurtime=c(1,2,2.5,4), lclval=c(500,500,500,500),  starttime=c(0,0,2,2), max_cycles = c(24,24,2,2)   ) #> [1] 6000 6000  500  500"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate instantaneous discounted costs or qalys — disc_instant","title":"Calculate instantaneous discounted costs or qalys — disc_instant","text":"Calculate instantaneous discounted costs qalys","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate instantaneous discounted costs or qalys — disc_instant","text":"","code":"disc_instant(lcldr = 0.035, lclcurtime, lclval)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate instantaneous discounted costs or qalys — disc_instant","text":"lcldr discount rate lclcurtime time current event simulation lclval value discounted","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate instantaneous discounted costs or qalys — disc_instant","text":"Double based discrete time discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate instantaneous discounted costs or qalys — disc_instant","text":"","code":"disc_instant(lcldr=0.035, lclcurtime=3, lclval=2500) #> [1] 2254.857"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant_v.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","title":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","text":"Calculate instantaneous discounted costs qalys vectors","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant_v.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","text":"","code":"disc_instant_v(lcldr = 0.035, lclcurtime, lclval)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant_v.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","text":"lcldr discount rate lclcurtime time current event simulation lclval value discounted","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant_v.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","text":"Double based discrete time discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_instant_v.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate instantaneous discounted costs or qalys for vectors — disc_instant_v","text":"","code":"disc_instant_v(lcldr=0.035, lclcurtime=3, lclval=2500) #> [1] 2254.857"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate discounted costs and qalys between events — disc_ongoing","title":"Calculate discounted costs and qalys between events — disc_ongoing","text":"Calculate discounted costs qalys events","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate discounted costs and qalys between events — disc_ongoing","text":"","code":"disc_ongoing(lcldr = 0.035, lclprvtime, lclcurtime, lclval)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate discounted costs and qalys between events — disc_ongoing","text":"lcldr discount rate lclprvtime time previous event simulation lclcurtime time current event simulation lclval value discounted","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate discounted costs and qalys between events — disc_ongoing","text":"Double based continuous time discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate discounted costs and qalys between events — disc_ongoing","text":"","code":"disc_ongoing(lcldr=0.035,lclprvtime=0.5, lclcurtime=3, lclval=2500) #> [1] 5886.65"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing_v.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","title":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","text":"Calculate discounted costs qalys events vectors","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing_v.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","text":"","code":"disc_ongoing_v(lcldr = 0.035, lclprvtime, lclcurtime, lclval)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing_v.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","text":"lcldr discount rate lclprvtime time previous event simulation lclcurtime time current event simulation lclval value discounted","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing_v.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","text":"Double based continuous time discounting","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/disc_ongoing_v.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate discounted costs and qalys between events for vectors — disc_ongoing_v","text":"","code":"disc_ongoing_v(lcldr=0.035,lclprvtime=0.5, lclcurtime=3, lclval=2500) #> [1] 5886.65"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a time to event from a list of parametric survival functions — draw_tte","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"Draw time event list parametric survival functions","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"","code":"draw_tte(   n_chosen,   dist,   coef1 = NULL,   coef2 = NULL,   coef3 = NULL,   ...,   beta_tx = 1,   seed = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"n_chosen number observations drawn dist distribution; takes values 'lnorm','norm','mvnorm','weibullPH','weibull','llogis','gompertz','gengamma','gamma','exp','beta','poisgamma' coef1 First coefficient distribution, defined coef() output flexsurvreg object (rate \"rpoisgamma\") coef2 Second coefficient distribution, defined coef() output flexsurvreg object (theta \"rpoisgamma\") coef3 Third coefficient distribution, defined coef() output flexsurvreg object (used \"rpoisgamma\") ... Additional arguments used specific distribution (e.g., return_ind_rate dist = \"poisgamma\") beta_tx Parameter natural scale applied addition scale/rate coefficient -e.g., HR used exponential- (used \"rpoisgamma\" \"beta\") seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"vector time event estimates given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"arguments relevant function can called directly","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/draw_tte.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a time to event from a list of parametric survival functions — draw_tte","text":"","code":"draw_tte(n_chosen=1,dist='exp',coef1=1,beta_tx=1) #> [1] 0.329793 draw_tte(n_chosen=10,\"poisgamma\",coef1=1,coef2=1,obs_time=1,return_ind_rate=FALSE) #> [[1]] #> numeric(0) #>  #> [[2]] #> [1] 0.6901357 #>  #> [[3]] #> numeric(0) #>  #> [[4]] #> [1] 0.7689012 #>  #> [[5]] #> numeric(0) #>  #> [[6]] #> [1] 0.4775767 0.5404240 0.5600788 0.6349382 0.6412048 0.6822714 #>  #> [[7]] #> numeric(0) #>  #> [[8]] #> numeric(0) #>  #> [[9]] #> [1] 0.1277729 #>  #> [[10]] #> [1] 0.3075535 0.9511123 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/evpi_des.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","title":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","text":"Calculate Expected Value Perfect Information (EVPI) DES model PSA result","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/evpi_des.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","text":"","code":"evpi_des(wtp, results, interventions = NULL, sensitivity_used = 1)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/evpi_des.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","text":"wtp Vector length >=1 willingness pay results list object returned run_sim() interventions character vector names interventions used analysis sensitivity_used Integer signaling sensitivity analysis use","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/evpi_des.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","text":"data frame EVPI results","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/evpi_des.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Expected Value of Perfect Information (EVPI) for a DES model with a PSA result — evpi_des","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))  evpi_des(seq(from=10000,to=500000,by=10000),res) #> # A tibble: 100 × 2 #>       wtp  evpi #>     <dbl> <dbl> #>  1  10000     0 #>  2  20000     0 #>  3  30000     0 #>  4  40000     0 #>  5  50000     0 #>  6  60000     0 #>  7  70000     0 #>  8  80000     0 #>  9  90000     0 #> 10 100000     0 #> # ℹ 90 more rows"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_elements_from_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","title":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","text":"Extracts items events looking assignments, modify_item, modify_item_seq, modify_event new_event","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_elements_from_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","text":"","code":"extract_elements_from_list(node, conditional_flag = FALSE)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_elements_from_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","text":"node Relevant node within nested AST list conditional_flag Boolean whether statement contained within conditional statement","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_elements_from_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","text":"data.frame relevant item/event, event assigned, whether contained within conditional statement","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_elements_from_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts items and events by looking into assignments, modify_item, modify_item_seq, modify_event and new_event — extract_elements_from_list","text":"","code":"expr <- substitute({  a <- sum(5+7)  modify_item(list(afsa=ifelse(TRUE,\"asda\",NULL)))  modify_item_seq(list(      o_other_q_gold1 = if(gold == 1) { utility } else { 0 },      o_other_q_gold2 = if(gold == 2) { utility } else { 0 },      o_other_q_gold3 = if(gold == 3) { utility } else { 0 },      o_other_q_gold4 = if(gold == 4) { utility } else { 0 },      o_other_q_on_dup = if(on_dup) { utility } else { 0 }   ))  if(a==1){   modify_item(list(a=list(6+b)))      modify_event(list(e_exn = curtime + 14 / days_in_year + qexp(rnd_exn, r_exn))) } else{   modify_event(list(e_exn = curtime + 14 / days_in_year + qexp(rnd_exn, r_exn)))   if(a>6){     modify_item(list(a=8))   }    }   if (sel_resp_incl == 1 & on_dup == 1) {      modify_event(list(e_response = curtime, z = 6))    }  })   out <- ast_as_list(expr)  results <- extract_elements_from_list(out)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_from_reactions.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","title":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","text":"Extract items events interactions event reactions list","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_from_reactions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","text":"","code":"extract_from_reactions(reactions)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_from_reactions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","text":"reactions list generated add_reactevt","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_from_reactions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","text":"data.frame relevant item/event, event assigned, whether contained within conditional statement","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_from_reactions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract all items and events and their interactions from the event reactions list — extract_from_reactions","text":"","code":"evt_react_list2 <-   add_reactevt(name_evt = \"sick\",                input = {modify_item(list(a=1+5/3))                  assign(\"W\", 5 + 3 / 6 )                  x[5] <- 18                  for(i in 1:5){                    assign(paste0(\"x_\",i),5+3)                  }                  if(j == TRUE){                    y[[\"w\"]] <- 612-31+3                  }#'                                  q_default <- 0                  c_default <- 0                  curtime   <- Inf                  d <- c <- k <- 67                })      extract_from_reactions(evt_react_list2) #>      event            name   type conditional_flag   definition #>     <char>          <char> <char>           <lgcl>       <char> #>  1:   sick               a   item            FALSE      1 + 5/3 #>  2:   sick               W   item            FALSE      5 + 3/6 #>  3:   sick            x[5]   item            FALSE           18 #>  4:   sick paste0('x_', i)   item            FALSE        5 + 3 #>  5:   sick        y[['w']]   item             TRUE 612 - 31 + 3 #>  6:   sick       q_default   item            FALSE            0 #>  7:   sick       c_default   item            FALSE            0 #>  8:   sick         curtime   item            FALSE          Inf #>  9:   sick               d   item            FALSE c <- k <- 67 #> 10:   sick               c   item            FALSE      k <- 67 #> 11:   sick               k   item            FALSE           67"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_psa_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract PSA results from a treatment — extract_psa_result","title":"Extract PSA results from a treatment — extract_psa_result","text":"Extract PSA results treatment","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_psa_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract PSA results from a treatment — extract_psa_result","text":"","code":"extract_psa_result(x, element)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_psa_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract PSA results from a treatment — extract_psa_result","text":"x output_sim data frame list object returned run_sim() element Variable PSA results extracted (single string)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_psa_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract PSA results from a treatment — extract_psa_result","text":"dataframe PSA results specified intervention","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/extract_psa_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract PSA results from a treatment — extract_psa_result","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))   extract_psa_result(res[[1]],\"total_costs\") #>        int    noint simulation     element #> 1 49921.64 41225.25          1 total_costs"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform luck adjustment — luck_adj","title":"Perform luck adjustment — luck_adj","text":"Perform luck adjustment","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform luck adjustment — luck_adj","text":"","code":"luck_adj(prevsurv, cursurv, luck, condq = TRUE)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform luck adjustment — luck_adj","text":"prevsurv Value previous survival cursurv Value current survival luck Luck used adjusted (number 0 1) condq Conditional quantile approach standard approach","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform luck adjustment — luck_adj","text":"Adjusted luck number 0 1","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform luck adjustment — luck_adj","text":"function performs luck adjustment automatically user, returning adjusted luck number. Luck interpreted fashion standard R (higher luck, higher time event). Note TTE predicted using conditional quantile function (e.g., conditional gompertz, conditional quantile weibull...) prevsurv cursurv unconditional survival using \"previous\" parametrization previous time presurv current time cursurv. distributions, presurv survival current time using previous parametrization, cursurv survival current time using current parametrization. Note advantage conditional quantile function need new parametrization update luck, makes approach computationally efficient. function can also work vectors, allow update multiple lucks single approach, can preserve names","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/luck_adj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform luck adjustment — luck_adj","text":"","code":"luck_adj(prevsurv = 0.8,  cursurv = 0.7,  luck = 0.5,  condq = TRUE) #> [1] 0.4285714   luck_adj(prevsurv = c(1,0.8,0.7),  cursurv = c(0.7,0.6,0.5),  luck = setNames(c(0.5,0.6,0.7),c(\"A\",\"B\",\"C\")),  condq = TRUE) #>         A         B         C  #> 0.2857143 0.4666667 0.5800000    luck_adj(prevsurv = 0.8,  cursurv = 0.7,  luck = 0.5,  condq = FALSE) #different results #> [1] 0.5625  #Unconditional approach, timepoint of change is 25, # parameter goes from 0.02 at time 10 to 0.025 to 0.015 at time 25, #  starting luck is 0.37 new_luck <- luck_adj(prevsurv = 1 - pweibull(q=10,3,1/0.02),  cursurv = 1 - pweibull(q=10,3,1/0.025),  luck = 0.37,  condq = FALSE) #time 10 change   new_luck <- luck_adj(prevsurv = 1 - pweibull(q=25,3,1/0.025),  cursurv = 1 - pweibull(q=25,3,1/0.015),  luck = new_luck,  condq = FALSE) #time 25 change   qweibull(new_luck, 3, 1/0.015) #final TTE  #> [1] 43.52338  #Conditional quantile approach  new_luck <- luck_adj(prevsurv = 1-pweibull(q=0,3,1/0.02),                       cursurv = 1- pweibull(q=10,3,1/0.02),                       luck = 0.37,                       condq = TRUE) #time 10 change, previous time is 0 so prevsurv will be 1  new_luck <- luck_adj(prevsurv = 1-pweibull(q=10,3,1/0.025),                       cursurv = 1- pweibull(q=25,3,1/0.025),                       luck = new_luck,                       condq = TRUE) #time 25 change  qcond_weibull(rnd = new_luck,                      shape = 3,                      scale = 1/0.015,                      lower_bound = 25) + 25 #final TTE #> [1] 43.52338"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the time of existing events — modify_event","title":"Modify the time of existing events — modify_event","text":"Modify time existing events","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the time of existing events — modify_event","text":"","code":"modify_event(evt, create_if_null = TRUE)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the time of existing events — modify_event","text":"evt list events times create_if_null boolean. TRUE, create non-existing events chosen time event. FALSE, ignore .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the time of existing events — modify_event","text":"return value, modifies/adds event cur_evtlist integrates main list storage","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Modify the time of existing events — modify_event","text":"functions add/modify events/inputs use lists. Whenever several inputs/events added modified, recommended group within one function, reduces computation cost. rather use two modify_event list one element, better group single modify_event list two elements. function evaluate sequentially. function intended used within add_reactevt function input parameter run elsewhere return error.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modify the time of existing events — modify_event","text":"","code":"add_reactevt(name_evt = \"idfs\",input = {modify_event(list(\"os\"=5))}) #> $idfs #> $idfs$react #> { #>     modify_event(list(os = 5)) #> } #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the value of existing items — modify_item","title":"Modify the value of existing items — modify_item","text":"Modify value existing items","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the value of existing items — modify_item","text":"","code":"modify_item(list_item)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the value of existing items — modify_item","text":"list_item list items values expressions","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the value of existing items — modify_item","text":"return value, modifies/adds item environment integrates main list storage","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Modify the value of existing items — modify_item","text":"functions add/modify events/inputs use lists. Whenever several inputs/events added modified, recommended group within one function, reduces computation cost. rather use two modify_item list one element, better group single modify_item list two elements. Note modify_item modify_item_seq can work subelements (e.g., modify_item(list(obj$item = 5)) work intended, better assign directly using expression approach, obj$item <- 5). Costs utilities can modified using construction type_name_category, type either \"qaly\" \"cost\", name name (e.g., \"default\") category category used (e.g., \"instant\"), one pass cost_default_instant modify cost. overwrite value defined corresponding cost/utility section. function intended used within add_reactevt function input parameter run elsewhere return error.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modify the value of existing items — modify_item","text":"","code":"add_reactevt(name_evt = \"idfs\",input = {modify_item(list(\"cost.it\"=5))}) #> $idfs #> $idfs$react #> { #>     modify_item(list(cost.it = 5)) #> } #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the value of existing items — modify_item_seq","title":"Modify the value of existing items — modify_item_seq","text":"Modify value existing items","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the value of existing items — modify_item_seq","text":"","code":"modify_item_seq(...)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the value of existing items — modify_item_seq","text":"... list items values expressions. evaluated sequentially (one list(= 1, b = +2 ))","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the value of existing items — modify_item_seq","text":"return value, modifies/adds items sequentially deploys environment main list storage","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Modify the value of existing items — modify_item_seq","text":"functions add/modify events/inputs use lists. Whenever several inputs/events added modified, recommended group within one function, reduces computation cost. rather use two modify_item list one element, better group single modify_item list two elements. Note modify_item modify_item_seq can work subelements (e.g., modify_item_seq(list(obj$item = 5)) work intended, better assign directly using expression approach, obj$item <- 5). Costs utilities can modified using construction type_name_category, type either \"qaly\" \"cost\", name name (e.g., \"default\") category category used (e.g., \"instant\"), one pass cost_default_instant modify cost. overwrite value defined corresponding cost/utility section. function different modify_item function evaluates sequentially arguments within list passed. implies slower performance relative modify_item, can cleaner convenient certain instances. function intended used within add_reactevt function input parameter run elsewhere return error.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/modify_item_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modify the value of existing items — modify_item_seq","text":"","code":"add_reactevt(name_evt = \"idfs\",input = {   modify_item_seq(list(cost.idfs = 500, cost.tx = cost.idfs + 4000))   }) #> $idfs #> $idfs$react #> { #>     modify_item_seq(list(cost.idfs = 500, cost.tx = cost.idfs +  #>         4000)) #> } #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate new events to be added to existing vector of events — new_event","title":"Generate new events to be added to existing vector of events — new_event","text":"Generate new events added existing vector events","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate new events to be added to existing vector of events — new_event","text":"","code":"new_event(evt)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate new events to be added to existing vector of events — new_event","text":"evt Event name event time","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate new events to be added to existing vector of events — new_event","text":"return value, adds event cur_evtlist integrates main list storage","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate new events to be added to existing vector of events — new_event","text":"functions add/modify events/inputs use lists. Whenever several inputs/events added modified, recommended group within one function, reduces computation cost. rather use two new_event list one element, better group single new_event list two elements. function intended used within add_reactevt function input parameter run elsewhere return error.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/new_event.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate new events to be added to existing vector of events — new_event","text":"","code":"add_reactevt(name_evt = \"idfs\",input = {new_event(list(\"ae\"=5))}) #> $idfs #> $idfs$react #> { #>     new_event(list(ae = 5)) #> } #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pcond_gompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","title":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","text":"Survival Probaility function conditional Gompertz distribution (lower bound )","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pcond_gompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","text":"","code":"pcond_gompertz(time = 1, shape, rate, lower_bound = 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pcond_gompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","text":"time Vector times shape shape parameter Gompertz distribution, defined coef() output flexsurvreg object rate rate parameter Gompertz distribution, defined coef() output flexsurvreg object lower_bound lower bound conditional distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pcond_gompertz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","text":"Estimate(s) conditional Gompertz distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pcond_gompertz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Survival Probaility function for conditional Gompertz distribution (lower bound only) — pcond_gompertz","text":"","code":"pcond_gompertz(time=1,shape=0.05,rate=0.01,lower_bound = 50) #> [1] 0.1174342"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"Helper function create list random draws whenever series functions needs called. Can implemented within pick_val_v.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"","code":"pick_psa(f, ...)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"f string vector strings function called, e.g., \"rnorm\" ... parameters passed function (e.g., \"rnorm\", arguments n, mean, sd)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"List length equal f parameters called","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"function can used pick values PSA within pick_val_v. function ignore NA items within respective parameter (see example ). element f NA (e.g., non PSA input) return NA value feature convenient mixing distributions different number arguments, e.g., rnorm rgengamma. slightly lower individually calling function, makes code easier read transparent","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_psa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function to create a list with random draws or whenever a series of functions needs to be called. Can be implemented within pick_val_v. — pick_psa","text":"","code":"params <- list( param=list(\"a\",\"b\"), dist=list(\"rlnorm\",\"rnorm\"), n=list(4,1), a=list(c(1,2,3,4),1), b=list(c(0.5,0.5,0.5,0.5),0.5), dsa_min=list(c(1,2,3,4),2), dsa_max=list(c(1,2,3,4),3) ) pick_psa(params[[\"dist\"]],params[[\"n\"]],params[[\"a\"]],params[[\"b\"]]) #> [[1]] #> [1]  1.675586 10.981649 49.775128 34.175660 #>  #> [[2]] #> [1] 1.43065 #>   #It works with functions that require different number of parameters params <- list(  param=list(\"a\",\"b\",\"c\"),  dist=list(\"rlnorm\",\"rnorm\",\"rgengamma\"),  n=list(4,1,1),  a=list(c(1,2,3,4),1,0),  b=list(c(0.5,0.5,0.5,0.5),0.5,1),  c=list(NA,NA,0.2),  dsa_min=list(c(1,2,3,4),2,1),  dsa_max=list(c(1,2,3,4),3,3) )  pick_psa(params[[\"dist\"]],params[[\"n\"]],params[[\"a\"]],params[[\"b\"]],params[[\"c\"]]) #> [[1]] #> [1]  3.709214  2.529025 25.594074 43.656966 #>  #> [[2]] #> [1] 1.273049 #>  #> [[3]] #> [1] 1.151862 #>   #Can be combined with multiple type of functions and distributions if parameters are well located  params <- list( param=list(\"a\",\"b\",\"c\",\"d\"), dist=list(\"rlnorm\",\"rnorm\",\"rgengamma\",\"draw_tte\"), n=list(4,1,1,1), a=list(c(1,2,3,4),1,0,\"norm\"), b=list(c(0.5,0.5,0.5,0.5),0.5,1,1), c=list(NA,NA,0.2,0.5), c=list(NA,NA,NA,NA), #NA arguments will be ignored dsa_min=list(c(1,2,3,4),2,1,0), dsa_max=list(c(1,2,3,4),3,3,2) )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":null,"dir":"Reference","previous_headings":"","what":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"Select values applied corresponding loop several values (vector list).","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"","code":"pick_val_v(   base,   psa,   sens,   psa_ind = psa_bool,   sens_ind = sens_bool,   indicator,   indicator_psa = NULL,   names_out = NULL,   indicator_sens_binary = TRUE,   sens_iterator = NULL,   distributions = NULL,   covariances = NULL,   deploy_env = FALSE )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"base Value PSA/DSA/Scenario psa Value PSA sens Value DSA/Scenario psa_ind Boolean whether PSA active sens_ind Boolean whether Scenario/DSA active indicator Indicator checks whether specific parameter/parameters /active DSA Scenario loop indicator_psa Indicator checks whether specific parameter/parameters /active PSA loop. NULL, assumed vector 1s length equal length(indicator) names_out Names give output list indicator_sens_binary Boolean, TRUE parameters varied fully, FALSE elements parameters may changed sens_iterator Current iterator number DSA/scenario run, e.g., 5 corresponds 5th DSA parameter changed distributions List length equal length base distributions stored covariances List length equal length base variance/covariances stored (relevant multivariate normal used) deploy_env Boolean, TRUE deploy objects environment function called . Must active using add_item2 (FALSE using add_item)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"List used inputs","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"function can used vectors lists, always return list. Lists used correlated variables introduced make sure selector knows choose among function allows choose using approach full parameters varied, approach subelements parameters can changed","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/pick_val_v.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select which values should be applied in the corresponding loop for several values (vector or list). — pick_val_v","text":"","code":"pick_val_v(base = list(0,0),              psa =list(rnorm(1,0,0.1),rnorm(1,0,0.1)),              sens = list(2,3),              psa_ind = FALSE,              sens_ind = TRUE,              indicator=list(1,2),              indicator_sens_binary = FALSE,              sens_iterator = 2,              distributions = list(\"rnorm\",\"rnorm\") ) #> [[1]] #> [1] 0 #>  #> [[2]] #> [1] 3 #>   pick_val_v(base = list(2,3,c(1,2)),              psa =sapply(1:3,                          function(x) eval(call(                            c(\"rnorm\",\"rnorm\",\"mvrnorm\")[[x]],                            1,                            c(2,3,list(c(1,2)))[[x]],                            c(0.1,0.1,list(matrix(c(1,0.1,0.1,1),2,2)))[[x]]                          ))),              sens = list(4,5,c(1.3,2.3)),              psa_ind = FALSE,              sens_ind = TRUE,              indicator=list(1,2,c(3,4)),              names_out=c(\"util\",\"util2\",\"correlated_vector\") ,              indicator_sens_binary = FALSE,              sens_iterator = 4,              distributions = list(\"rnorm\",\"rnorm\",\"mvrnorm\"),              covariances = list(0.1,0.1,matrix(c(1,0.1,0.1,1),2,2)) ) #> $util #> [1] 2 #>  #> $util2 #> [1] 3 #>  #> $correlated_vector #> [1] 1.03 2.30 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qbeta_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","title":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","text":"Draw beta distribution based mean se (quantile)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qbeta_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","text":"","code":"qbeta_mse(q, mean_v, se)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qbeta_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","text":"q Quantiles used mean_v vector mean values se vector standard errors means","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qbeta_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","text":"single estimate beta distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qbeta_mse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a beta distribution based on mean and se (quantile) — qbeta_mse","text":"","code":"qbeta_mse(q=0.5,mean_v=0.8,se=0.2) #> [1] 0.8671142"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for exponential distribution — qcond_exp","title":"Conditional quantile function for exponential distribution — qcond_exp","text":"Conditional quantile function exponential distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for exponential distribution — qcond_exp","text":"","code":"qcond_exp(rnd = 0.5, rate)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for exponential distribution — qcond_exp","text":"rnd Vector quantiles rate rate parameter Note taht conditional quantile exponential independent time due constant hazard","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for exponential distribution — qcond_exp","text":"Estimate(s) conditional exponential distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for exponential distribution — qcond_exp","text":"","code":"qcond_exp(rnd = 0.5,rate = 3) #> [1] 0.2310491"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for gamma distribution — qcond_gamma","title":"Conditional quantile function for gamma distribution — qcond_gamma","text":"Conditional quantile function gamma distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for gamma distribution — qcond_gamma","text":"","code":"qcond_gamma(rnd = 0.5, rate, shape, lower_bound = 0, s_obs)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for gamma distribution — qcond_gamma","text":"rnd Vector quantiles rate rate parameter shape shape parameter lower_bound lower bound used (current time) s_obs survival observed lower_bound time, normally defined time 0 1 - pgamma(q = lower_bound, rate, shape) may different parametrization changed previously","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for gamma distribution — qcond_gamma","text":"Estimate(s) conditional gamma distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for gamma distribution — qcond_gamma","text":"","code":"qcond_gamma(rnd = 0.5, rate = 1.06178, shape = 0.01108,lower_bound = 1, s_obs=0.8) #> [1] 87.94889"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","title":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","text":"Quantile function conditional Gompertz distribution (lower bound )","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","text":"","code":"qcond_gompertz(rnd = 0.5, shape, rate, lower_bound = 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","text":"rnd Vector quantiles shape shape parameter Gompertz distribution, defined coef() output flexsurvreg object rate rate parameter Gompertz distribution, defined coef() output flexsurvreg object lower_bound lower bound conditional distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gompertz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","text":"Estimate(s) conditional Gompertz distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_gompertz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile function for conditional Gompertz distribution (lower bound only) — qcond_gompertz","text":"","code":"qcond_gompertz(rnd=0.5,shape=0.05,rate=0.01,lower_bound = 50) #> [1] 5.007156"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_llogis.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for loglogistic distribution — qcond_llogis","title":"Conditional quantile function for loglogistic distribution — qcond_llogis","text":"Conditional quantile function loglogistic distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_llogis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for loglogistic distribution — qcond_llogis","text":"","code":"qcond_llogis(rnd = 0.5, shape, scale, lower_bound = 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_llogis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for loglogistic distribution — qcond_llogis","text":"rnd Vector quantiles shape shape parameter scale scale parameter lower_bound lower bound used (current time)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_llogis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for loglogistic distribution — qcond_llogis","text":"Estimate(s) conditional loglogistic distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_llogis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for loglogistic distribution — qcond_llogis","text":"","code":"qcond_llogis(rnd = 0.5,shape = 1,scale = 1,lower_bound = 1) #> [1] 2"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_lnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for lognormal distribution — qcond_lnorm","title":"Conditional quantile function for lognormal distribution — qcond_lnorm","text":"Conditional quantile function lognormal distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_lnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for lognormal distribution — qcond_lnorm","text":"","code":"qcond_lnorm(rnd = 0.5, meanlog, sdlog, lower_bound = 0, s_obs)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_lnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for lognormal distribution — qcond_lnorm","text":"rnd Vector quantiles meanlog meanlog parameter sdlog sdlog parameter lower_bound lower bound used (current time) s_obs survival observed lower_bound time, normally defined time 0 1 - plnorm(q = lower_bound, meanlog, sdlog) may different parametrization changed previously","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_lnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for lognormal distribution — qcond_lnorm","text":"Estimate(s) conditional lognormal distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_lnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for lognormal distribution — qcond_lnorm","text":"","code":"qcond_lnorm(rnd = 0.5, meanlog = 1,sdlog = 1,lower_bound = 1, s_obs=0.8) #> [1] 2.502045"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for normal distribution — qcond_norm","title":"Conditional quantile function for normal distribution — qcond_norm","text":"Conditional quantile function normal distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for normal distribution — qcond_norm","text":"","code":"qcond_norm(rnd = 0.5, mean, sd, lower_bound = 0, s_obs)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for normal distribution — qcond_norm","text":"rnd Vector quantiles mean mean parameter sd sd parameter lower_bound lower bound used (current time) s_obs survival observed lower_bound time, normally defined time 0 1 - pnorm(q = lower_bound, mean, sd) may different parametrization changed previously","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for normal distribution — qcond_norm","text":"Estimate(s) conditional normal distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for normal distribution — qcond_norm","text":"","code":"qcond_norm(rnd = 0.5, mean = 1,sd = 1,lower_bound = 1, s_obs=0.8) #> [1] 0.2533471"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_weibull.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional quantile function for weibull distribution — qcond_weibull","title":"Conditional quantile function for weibull distribution — qcond_weibull","text":"Conditional quantile function weibull distribution","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_weibull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional quantile function for weibull distribution — qcond_weibull","text":"","code":"qcond_weibull(rnd = 0.5, shape, scale, lower_bound = 0)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_weibull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional quantile function for weibull distribution — qcond_weibull","text":"rnd Vector quantiles shape shape parameter R stats package weibull scale scale parameter R stats package weibull lower_bound lower bound used (current time)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_weibull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional quantile function for weibull distribution — qcond_weibull","text":"Estimate(s) conditional weibull distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qcond_weibull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional quantile function for weibull distribution — qcond_weibull","text":"","code":"qcond_weibull(rnd = 0.5,shape = 3,scale = 66.66,lower_bound = 50) #> [1] 19.12624"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qgamma_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","title":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","text":"Use quantiles gamma distribution based mean se","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qgamma_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","text":"","code":"qgamma_mse(q = 1, mean_v, se, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qgamma_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","text":"q Quantile draw mean_v vector mean values se vector standard errors means seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qgamma_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","text":"single estimate gamma distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/qgamma_mse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use quantiles from a gamma distribution based on mean and se — qgamma_mse","text":"","code":"qgamma_mse(q=0.5,mean_v=0.8,se=0.2) #> [1] 0.7833965"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"Creates environment (similar R6 class) random uniform numbers drawn ","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"","code":"random_stream(stream_size = 100)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"stream_size Length vector random uniform values initialize","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"Self (environment) behaving similar R6 class","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"function creates environment object behaves similar R6 class offers speed vs. R6 class. object always initialized (see example ) specific vector random uniform values. user can call object obj$draw_number(n), n integer, return first n elements created vector uniform values. automatically remove indexes vector, next time user calls obj$draw_n() already consider next index. user can also access latest elements drawn accessing obj$random_n (useful performing luck adjustment), current stream still drawn using obj$stream original size (created) using obj$stream_size. performing luck adjustment, user can always modify random value using obj$random_n <- luck_adj(...) (valid used expression approach, modify_item)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/random_stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates an environment (similar to R6 class) of random uniform numbers to be drawn from — random_stream","text":"","code":"stream_1 <- random_stream(1000) number_1 <- stream_1$draw_n() #extract 1st index from the vector created identical(number_1,stream_1$random_n) #same value #> [1] TRUE number_2 <- stream_1$draw_n() #gets 1st index (considers previous) identical(number_2,stream_1$random_n) #same value #> [1] TRUE"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rbeta_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a beta distribution based on mean and se — rbeta_mse","title":"Draw from a beta distribution based on mean and se — rbeta_mse","text":"Draw beta distribution based mean se","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rbeta_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a beta distribution based on mean and se — rbeta_mse","text":"","code":"rbeta_mse(n = 1, mean_v, se, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rbeta_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a beta distribution based on mean and se — rbeta_mse","text":"n Number draws (must >= 1) mean_v vector mean values se vector standard errors means seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rbeta_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a beta distribution based on mean and se — rbeta_mse","text":"single estimate beta distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rbeta_mse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a beta distribution based on mean and se — rbeta_mse","text":"","code":"rbeta_mse(n=1,mean_v=0.8,se=0.2) #> [1] 0.938279"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","title":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","text":"Draw conditional Gompertz distribution (lower bound )","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","text":"","code":"rcond_gompertz(n = 1, shape, rate, lower_bound = 0, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","text":"n number observations drawn shape shape parameter Gompertz distribution, defined coef() output flexsurvreg object rate rate parameter Gompertz distribution, defined coef() output flexsurvreg object lower_bound lower bound conditional distribution seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","text":"Estimate(s) conditional Gompertz distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a conditional Gompertz distribution (lower bound only) — rcond_gompertz","text":"","code":"rcond_gompertz(1,shape=0.05,rate=0.01,lower_bound = 50) #> [1] 0.3961535"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz_lu.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","title":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","text":"Draw Conditional Gompertz distribution (lower upper bound)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz_lu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","text":"","code":"rcond_gompertz_lu(   n,   shape,   rate,   lower_bound = 0,   upper_bound = Inf,   seed = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz_lu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","text":"n number observations drawn shape shape parameter Gompertz distribution, defined coef() output flexsurvreg object rate rate parameter Gompertz distribution, defined coef() output flexsurvreg object lower_bound lower bound conditional distribution upper_bound upper bound conditional distribution seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz_lu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","text":"Estimate(s) Conditional Gompertz distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rcond_gompertz_lu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a Conditional Gompertz distribution (lower and upper bound) — rcond_gompertz_lu","text":"","code":"rcond_gompertz_lu(1,shape=0.05,rate=0.01,lower_bound = 50) #> [1] 1.325551"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","title":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","text":"Draw dirichlet distribution based number counts transition. Adapted brms::rdirichlet","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","text":"","code":"rdirichlet(n = 1, alpha, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","text":"n Number draws (must >= 1). n>1, return list matrices. alpha matrix alphas (transition counts) seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","text":"transition matrix. n>1, return list matrices.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a dirichlet distribution based on number of counts in transition. Adapted from brms::rdirichlet — rdirichlet","text":"","code":"rdirichlet(n=1,alpha= matrix(c(1251, 0, 350, 731),2,2)) #>          [,1]     [,2] #> [1,] 0.788197 0.211803 #> [2,] 0.000000 1.000000 rdirichlet(n=2,alpha= matrix(c(1251, 0, 350, 731),2,2)) #> [[1]] #>          [,1]     [,2] #> [1,] 0.789982 0.210018 #> [2,] 0.000000 1.000000 #>  #> [[2]] #>         [,1]    [,2] #> [1,] 0.79903 0.20097 #> [2,] 0.00000 1.00000 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","title":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","text":"Draw dirichlet distribution based mean transition probabilities standard errors","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","text":"","code":"rdirichlet_prob(n = 1, alpha, se, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","text":"n Number draws (must >= 1). n>1, return list matrices. alpha matrix transition probabilities se matrix standard errors seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","text":"transition matrix. n>1, return list matrices.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rdirichlet_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a dirichlet distribution based on mean transition probabilities and standard errors — rdirichlet_prob","text":"","code":"rdirichlet_prob(n=1,alpha= matrix(c(0.7,0.3,0,0.1,0.7,0.2,0.1,0.2,0.7),3,3), se=matrix(c(0.7,0.3,0,0.1,0.7,0.2,0.1,0.2,0.7)/10,3,3)) #>           [,1]      [,2]      [,3] #> [1,] 0.7731198 0.1102131 0.1166672 #> [2,] 0.2666110 0.5474962 0.1858928 #> [3,] 0.0000000 0.1887888 0.8112112  rdirichlet_prob(n=2,alpha= matrix(c(0.7,0.3,0,0.1,0.7,0.2,0.1,0.2,0.7),3,3), se=matrix(c(0.7,0.3,0,0.1,0.7,0.2,0.1,0.2,0.7)/10,3,3)) #> [[1]] #>           [,1]      [,2]      [,3] #> [1,] 0.7872455 0.0993112 0.1134433 #> [2,] 0.1990910 0.6461405 0.1547685 #> [3,] 0.0000000 0.1823028 0.8176972 #>  #> [[2]] #>           [,1]      [,2]      [,3] #> [1,] 0.7424206 0.1300043 0.1275751 #> [2,] 0.2622611 0.5808159 0.1569230 #> [3,] 0.0000000 0.2293396 0.7706604 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/replicate_profiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Replicate profiles data.frame — replicate_profiles","title":"Replicate profiles data.frame — replicate_profiles","text":"Replicate profiles data.frame","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/replicate_profiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replicate profiles data.frame — replicate_profiles","text":"","code":"replicate_profiles(   profiles,   replications,   probabilities = NULL,   replacement = TRUE,   seed_used = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/replicate_profiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replicate profiles data.frame — replicate_profiles","text":"profiles data.frame profiles replications integer, final number observations probabilities vector probabilities length number rows profiles. need add 1 (reweighted) replacement Boolean whether replacement used seed_used Integer seed used consistent results","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/replicate_profiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replicate profiles data.frame — replicate_profiles","text":"Resampled data.frame profiles","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/replicate_profiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replicate profiles data.frame — replicate_profiles","text":"","code":"replicate_profiles(profiles=data.frame(id=1:100,age=rnorm(100,60,5)), replications=200,probabilities=rep(1,100)) #>      id      age #> 1    73 61.67248 #> 2    11 58.98776 #> 3    12 68.42248 #> 4    24 60.77607 #> 5    43 59.38907 #> 6    36 64.33908 #> 7    68 57.54275 #> 8    46 61.27541 #> 9    32 52.17178 #> 10   28 56.41231 #> 11   29 61.80847 #> 12   11 58.98776 #> 13    1 51.79709 #> 14   12 68.42248 #> 15   45 55.19362 #> 16   70 57.91901 #> 17   34 62.57041 #> 18   41 64.15074 #> 19   71 57.39728 #> 20   26 52.33467 #> 21    4 62.96200 #> 22    9 57.35178 #> 23    4 62.96200 #> 24   22 56.01136 #> 25   71 57.39728 #> 26  100 63.71614 #> 27   80 68.04312 #> 28   62 65.42464 #> 29   22 56.01136 #> 30   78 60.15535 #> 31   83 65.07853 #> 32   78 60.15535 #> 33   84 60.18867 #> 34    2 62.53961 #> 35   10 56.59363 #> 36   93 55.65531 #> 37   65 70.84672 #> 38   43 59.38907 #> 39   72 64.25292 #> 40   18 60.57015 #> 41   39 51.07818 #> 42   99 64.26364 #> 43   42 63.03673 #> 44   74 55.85324 #> 45   40 54.81427 #> 46   40 54.81427 #> 47   14 59.22012 #> 48   30 66.99502 #> 49   15 59.76800 #> 50   49 57.31175 #> 51  100 63.71614 #> 52   18 60.57015 #> 53   20 55.40334 #> 54   89 73.46186 #> 55   69 67.67458 #> 56   52 56.91888 #> 57   50 57.73787 #> 58   98 60.17040 #> 59   26 52.33467 #> 60   15 59.76800 #> 61    8 54.28217 #> 62   42 63.03673 #> 63   36 64.33908 #> 64   10 56.59363 #> 65    6 60.60810 #> 66   28 56.41231 #> 67   50 57.73787 #> 68   62 65.42464 #> 69   23 63.34111 #> 70   10 56.59363 #> 71   19 60.31959 #> 72   81 67.14927 #> 73   54 62.41299 #> 74   48 64.65180 #> 75   91 66.80038 #> 76   76 52.27458 #> 77   78 60.15535 #> 78   86 55.14963 #> 79   72 64.25292 #> 80   96 62.53479 #> 81   16 55.23186 #> 82   82 55.25830 #> 83   31 61.86349 #> 84   40 54.81427 #> 85   25 60.64344 #> 86   36 64.33908 #> 87   44 64.66563 #> 88   61 63.16086 #> 89   58 67.02039 #> 90   48 64.65180 #> 91   25 60.64344 #> 92   76 52.27458 #> 93   31 61.86349 #> 94   10 56.59363 #> 95   29 61.80847 #> 96   95 66.07354 #> 97   90 66.96197 #> 98   49 57.31175 #> 99   59 66.88559 #> 100  23 63.34111 #> 101  61 63.16086 #> 102   4 62.96200 #> 103  87 58.85486 #> 104  55 62.71072 #> 105  11 58.98776 #> 106  71 57.39728 #> 107  66 60.69565 #> 108  94 57.46722 #> 109  30 66.99502 #> 110  67 66.88163 #> 111  63 66.78230 #> 112  66 60.69565 #> 113  60 65.30198 #> 114  97 49.52514 #> 115  18 60.57015 #> 116  26 52.33467 #> 117  54 62.41299 #> 118  15 59.76800 #> 119  83 65.07853 #> 120  32 52.17178 #> 121  36 64.33908 #> 122  34 62.57041 #> 123  84 60.18867 #> 124  18 60.57015 #> 125  29 61.80847 #> 126  38 59.18660 #> 127   8 54.28217 #> 128  60 65.30198 #> 129  10 56.59363 #> 130  29 61.80847 #> 131  10 56.59363 #> 132  93 55.65531 #> 133  25 60.64344 #> 134  97 49.52514 #> 135  33 59.74153 #> 136  45 55.19362 #> 137  93 55.65531 #> 138  86 55.14963 #> 139  97 49.52514 #> 140  33 59.74153 #> 141  90 66.96197 #> 142  31 61.86349 #> 143  46 61.27541 #> 144  46 61.27541 #> 145  44 64.66563 #> 146  88 55.12577 #> 147  80 68.04312 #> 148  38 59.18660 #> 149  35 62.74950 #> 150  98 60.17040 #> 151  90 66.96197 #> 152  45 55.19362 #> 153  91 66.80038 #> 154  21 64.50668 #> 155  77 61.16615 #> 156  20 55.40334 #> 157  50 57.73787 #> 158  15 59.76800 #> 159  64 61.81212 #> 160  36 64.33908 #> 161  61 63.16086 #> 162  61 63.16086 #> 163  10 56.59363 #> 164  76 52.27458 #> 165  74 55.85324 #> 166  82 55.25830 #> 167  52 56.91888 #> 168  28 56.41231 #> 169  55 62.71072 #> 170  23 63.34111 #> 171  27 61.01180 #> 172  36 64.33908 #> 173  33 59.74153 #> 174  92 58.17292 #> 175  52 56.91888 #> 176  90 66.96197 #> 177  21 64.50668 #> 178 100 63.71614 #> 179  93 55.65531 #> 180  77 61.16615 #> 181  90 66.96197 #> 182  29 61.80847 #> 183  94 57.46722 #> 184  86 55.14963 #> 185  48 64.65180 #> 186  71 57.39728 #> 187  28 56.41231 #> 188  21 64.50668 #> 189  43 59.38907 #> 190  25 60.64344 #> 191  11 58.98776 #> 192  29 61.80847 #> 193   2 62.53961 #> 194  64 61.81212 #> 195   9 57.35178 #> 196  37 63.42180 #> 197  62 65.42464 #> 198  98 60.17040 #> 199  63 66.78230 #> 200  54 62.41299"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rgamma_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from a gamma distribution based on mean and se — rgamma_mse","title":"Draw from a gamma distribution based on mean and se — rgamma_mse","text":"Draw gamma distribution based mean se","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rgamma_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from a gamma distribution based on mean and se — rgamma_mse","text":"","code":"rgamma_mse(n = 1, mean_v, se, seed = NULL)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rgamma_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from a gamma distribution based on mean and se — rgamma_mse","text":"n Number draws (must >= 1) mean_v vector mean values se vector standard errors means seed integer used set seed draw.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rgamma_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from a gamma distribution based on mean and se — rgamma_mse","text":"single estimate gamma distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rgamma_mse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from a gamma distribution based on mean and se — rgamma_mse","text":"","code":"rgamma_mse(n=1,mean_v=0.8,se=0.2) #> [1] 0.7549241"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"Draw time event (tte) Poisson Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"","code":"rpoisgamma(   n,   rate,   theta = NULL,   obs_time = 1,   t_reps,   seed = NULL,   return_ind_rate = FALSE,   return_df = FALSE )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"n number observations drawn rate rate event (terms events per observation-time) theta Optional.  omitted, function simulates times Poisson process. Represents shape gamma mixture distribution. Estimated reported theta negative binomial regression analyses r. obs_time period events observable t_reps Optional. Number TBEs generated capture events within observation window. omitted, function sets t_reps 99.99th quantile Poisson (theta provided) negative binomial (theta provided). Thus, risk missing possible events observation window 0.01%. seed integer used set seed draw. return_ind_rate boolean indicates whether additional vector rate parameters used per observation used. alter structure results two lists, one storing tte name tte, name ind_rate return_df boolean indicates whether data.table object returned","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"Estimate(s) time event based poisson/Poisson-Gamma (PG) Mixture/Negative Binomial (NB) distribution based given parameters","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"Function simulate event times Poisson Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process Event times determined sampling times events (TBEs) exponential distribution, cumulating derive event times. Events occurring within set observation time window retained returned. times Poisson process, provided rate assumed constant. PG NB, individual rates sampled Gamma distribution shape = theta scale = rate/theta.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/rpoisgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw time to event (tte) from a Poisson or Poisson-Gamma (PG) Mixture/Negative Binomial (NB) Process — rpoisgamma","text":"","code":"rpoisgamma(1,rate=1,obs_time=1,theta=1) #> [[1]] #> [1] 0.1852907 0.5010557 0.9573382 #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the simulation — run_sim","title":"Run the simulation — run_sim","text":"Run simulation","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the simulation — run_sim","text":"","code":"run_sim(   arm_list = c(\"int\", \"noint\"),   sensitivity_inputs = NULL,   common_all_inputs = NULL,   common_pt_inputs = NULL,   unique_pt_inputs = NULL,   init_event_list = NULL,   evt_react_list = evt_react_list,   util_ongoing_list = NULL,   util_instant_list = NULL,   util_cycle_list = NULL,   cost_ongoing_list = NULL,   cost_instant_list = NULL,   cost_cycle_list = NULL,   other_ongoing_list = NULL,   other_instant_list = NULL,   npats = 500,   n_sim = 1,   psa_bool = NULL,   sensitivity_bool = FALSE,   sensitivity_names = NULL,   n_sensitivity = 1,   input_out = NULL,   ipd = 1,   timed_freq = NULL,   debug = FALSE,   accum_backwards = FALSE,   continue_on_error = FALSE,   seed = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the simulation — run_sim","text":"arm_list vector names interventions evaluated simulation sensitivity_inputs list sensitivity inputs change within sensitivity similar fashion common_all_inputs, etc common_all_inputs list inputs common across patients change within simulation common_pt_inputs list inputs change across patients affected intervention unique_pt_inputs list inputs change across intervention init_event_list list initial events event times. initial events given, \"Start\" event time 0 created automatically evt_react_list list event reactions util_ongoing_list Vector QALY named variables accrued ongoing basis (discounted using drq) util_instant_list Vector QALY named variables accrued instantaneously event (discounted using drq) util_cycle_list Vector QALY named variables accrued cycles (discounted using drq) cost_ongoing_list Vector cost named variables accrued ongoing basis (discounted using drc) cost_instant_list Vector cost named variables accrued instantaneously event (discounted using drc) cost_cycle_list Vector cost named variables accrued cycles (discounted using drc) other_ongoing_list Vector named variables accrued ongoing basis (discounted using drq) other_instant_list Vector named variables accrued instantaneously event (discounted using drq) npats number patients simulated (simulate npats * length(arm_list)) n_sim number simulations run per sensitivity psa_bool boolean determine PSA conducted. n_sim > 1 psa_bool = FALSE, differences simulations due sampling sensitivity_bool boolean determine Scenarios/DSA conducted. sensitivity_names vector scenario/DSA names can used select right sensitivity (e.g., c(\"Scenario_1\", \"Scenario_2\")). parameter \"sens_name_used\" created corresponds one used iteration. n_sensitivity Number sensitivity analysis (DSA Scenarios) run. interacted sensitivity_names argument null (n_sensitivityitivity = n_sensitivity * length(sensitivity_names)). DSA, many parameters . scenario, 1. input_out vector variables returned output data frame ipd Integer taking value 1 full IPD data returned, 2 IPD data aggregating events (returning last value numeric/character/factor variables. objects (e.g., matrices), IPD still returned aggregation rule clear). values mean IPD data returned (removes non-numerical length>1 items) timed_freq NULL, produce timed outputs. Otherwise number (e.g., every 1 year) debug TRUE, generate log file accum_backwards TRUE, ongoing accumulators count backwards (.e., current value applied previous update). FALSE, current value applied current event next time updated. TRUE, user must use modify_item modify_item_seq results incorrect. continue_on_error TRUE, error attempt continue skipping current simulation seed Starting seed used whole analysis. null, set 1 default.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the simulation — run_sim","text":"list data frames simulation results","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run the simulation — run_sim","text":"function slightly different run_sim_parallel. run_sim_parallel runs multiple-core simulation level. run_sim uses -single core. run_sim can efficient using one simulation (e.g., deterministic), run_sim_parallel efficient number simulations >1 (e.g., PSA). Event ties processed order declared within init_event_list argument (evts argument within first sublist object). , program automatically adds sequence 0 (number events - 1) times 1e-10 add event times selecting event minimum time. time selected relatively small yet small ignored .min (see .Machine details) list protected objects used user input names  global environment avoid risk overwriting follows: c(\"arm\", \"arm_list\", \"categories_for_export\", \"cur_evtlist\", \"curtime\", \"evt\", \"\", \"prevtime\", \"sens\", \"simulation\", \"sens_name_used\",\"list_env\",\"uc_lists\",\"npats\",\"ipd\"). engine uses L'Ecuyer-CMRG random number generator. Note random seeds set unique category (.e., patient level, patient-arm level, etc.) drc drq parameters passed within sensitivity common_all input lists, assigned default value 0.03 discounting costs, QALYs others. Ongoing items look backward last time updated performing discounting accumulation. means user necessarily need keep updating value, add value changes looking forward (e.g., o_q = utility event 1, event 2 utility change, event 3 , want make sure add o_q = utility event 3 updating utility. program automatically look back event 1). Note previous versions package backward default, now switched forward. using accum_backwards = TRUE, mandatory user use modify_item modify_item_seq event reactions, standard assignment approach (e.g., <- 5) calculate right results, particularly presence conditional statements. important note QALYs Costs (ongoing instant per cycle) used length 1. length > 1, model expand data, instead event row, event N rows (equal length costs/qalys discount passed). means processing results data needed order provide correct results. cycle lists used, expected user declare well name variable pasted cycle_l cycle_starttime (e.g., c_default_cycle_l c_default_cycle_starttime) ensure discounting can computed using cycles, cycle_l cycle length, cycle_starttime starting time variable started counting. Optionally, max_cycles must also added (maximum number cycles, set equal NA). debug = TRUE export log file timestamp error main working directory. Note using mode without modify_item modify_item_seq may lead inaccuracies assignments done non-standard ways, AST may catch relevant assignments (e.g., assigment like assign(paste(\"x_\",),5) loop identified, unless using modify_item(_seq)). continue_on_error skip current simulation (continue rest patient-arms) TRUE. Note make progress bar correct, set patients expected run .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run the simulation — run_sim","text":"","code":"library(magrittr) common_all_inputs <-add_item( util.sick = 0.8, util.sicker = 0.5, cost.sick = 3000, cost.sicker = 7000, cost.int = 1000, coef_noint = log(0.2), HR_int = 0.8, drc = 0.035, #different values than what's assumed by default drq = 0.035, random_seed_sicker_i = sample.int(100000,5,replace = FALSE) )  common_pt_inputs <- add_item(death= max(0.0000001,rnorm(n=1, mean=12, sd=3)))   unique_pt_inputs <- add_item(fl.sick = 1,                              q_default = util.sick,                              c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})                                init_event_list <-  add_tte(arm=c(\"noint\",\"int\"), evts = c(\"sick\",\"sicker\",\"death\") ,input={   sick <- 0   sicker <- draw_tte(1,dist=\"exp\",    coef1=coef_noint, beta_tx = ifelse(arm==\"int\",HR_int,1),     seed = random_seed_sicker_i[i])    })     evt_react_list <- add_reactevt(name_evt = \"sick\",              input = {}) %>%   add_reactevt(name_evt = \"sicker\",                input = {                  modify_item(list(q_default = util.sicker,                                   c_default = cost.sicker + if(arm==\"int\"){cost.int}else{0},                                   fl.sick = 0))                 }) %>%   add_reactevt(name_evt = \"death\",                input = {                  modify_item(list(q_default = 0,                                   c_default = 0,                                    curtime = Inf))                 })                  util_ongoing <- \"q_default\" cost_ongoing <- \"c_default\"                             run_sim(arm_list=c(\"int\",\"noint\"), common_all_inputs = common_all_inputs, common_pt_inputs = common_pt_inputs, unique_pt_inputs = unique_pt_inputs, init_event_list = init_event_list, evt_react_list = evt_react_list, util_ongoing_list = util_ongoing, cost_ongoing_list = cost_ongoing, npats = 2, n_sim = 1, psa_bool = FALSE, ipd = 1) #> Analysis number: 1 #> Simulation number: 1 #> Time to run simulation 1: 0.04s #> Time to run analysis 1: 0.04s #> Total time to run: 0.05s #> [[1]] #> [[1]][[1]] #> [[1]][[1]]$sensitivity_name #> [1] \"\" #>  #> [[1]][[1]]$arm_list #> [1] \"int\"   \"noint\" #>  #> [[1]][[1]]$total_lys #>      int    noint  #> 9.046874 9.046874  #>  #> [[1]][[1]]$total_qalys #>      int    noint  #> 6.207438 6.181151  #>  #> [[1]][[1]]$total_costs #>      int    noint  #> 49921.64 41225.25  #>  #> [[1]][[1]]$total_lys_undisc #>      int    noint  #> 10.89866 10.89866  #>  #> [[1]][[1]]$total_qalys_undisc #>      int    noint  #> 7.501176 7.474146  #>  #> [[1]][[1]]$total_costs_undisc #>      int    noint  #> 59831.36 49293.10  #>  #> [[1]][[1]]$c_default #>      int    noint  #> 49921.64 41225.25  #>  #> [[1]][[1]]$c_default_undisc #>      int    noint  #> 59831.36 49293.10  #>  #> [[1]][[1]]$q_default #>      int    noint  #> 6.207438 6.181151  #>  #> [[1]][[1]]$q_default_undisc #>      int    noint  #> 7.501176 7.474146  #>  #> [[1]][[1]]$merged_df #>     evtname    evttime  prevtime pat_id    arm total_lys total_qalys #>      <char>      <num>     <num>  <int> <char>     <num>       <num> #>  1:    sick  0.0000000 0.0000000      1    int 10.339480    8.271584 #>  2:   death 12.7779512 0.0000000      1    int 10.339480    8.271584 #>  3:    sick  0.0000000 0.0000000      2    int  7.754267    4.143293 #>  4:  sicker  0.9010175 0.0000000      2    int  7.754267    4.143293 #>  5:   death  9.0193725 0.9010175      2    int  7.754267    4.143293 #>  6:    sick  0.0000000 0.0000000      1  noint 10.339480    8.271584 #>  7:   death 12.7779512 0.0000000      1  noint 10.339480    8.271584 #>  8:    sick  0.0000000 0.0000000      2  noint  7.754267    4.090719 #>  9:  sicker  0.7208140 0.0000000      2  noint  7.754267    4.090719 #> 10:   death  9.0193725 0.7208140      2  noint  7.754267    4.090719 #>     total_costs total_costs_undisc total_qalys_undisc total_lys_undisc #>           <num>              <num>              <num>            <num> #>  1:    41357.92           51111.80          10.222361        12.777951 #>  2:    41357.92           51111.80          10.222361        12.777951 #>  3:    58485.35           68550.91           4.779991         9.019372 #>  4:    58485.35           68550.91           4.779991         9.019372 #>  5:    58485.35           68550.91           4.779991         9.019372 #>  6:    31018.44           38333.85          10.222361        12.777951 #>  7:    31018.44           38333.85          10.222361        12.777951 #>  8:    51432.07           60252.35           4.725930         9.019372 #>  9:    51432.07           60252.35           4.725930         9.019372 #> 10:    51432.07           60252.35           4.725930         9.019372 #>            lys     qalys     costs lys_undisc qalys_undisc costs_undisc #>          <num>     <num>     <num>      <num>        <num>        <num> #>  1: 10.3394801 8.2715841 41357.920 12.7779512   10.2223609    51111.805 #>  2:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  3:  0.8871965 0.7097572  3548.786  0.9010175    0.7208140     3604.070 #>  4:  6.8670706 3.4335353 54936.565  8.1183550    4.0591775    64946.840 #>  5:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  6: 10.3394801 8.2715841 31018.440 12.7779512   10.2223609    38333.854 #>  7:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  8:  0.7119504 0.5695603  2135.851  0.7208140    0.5766512     2162.442 #>  9:  7.0423168 3.5211584 49296.218  8.2985585    4.1492793    58089.910 #> 10:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>     c_default q_default c_default_undisc q_default_undisc   nexttime simulation #>         <num>     <num>            <num>            <num>      <num>      <int> #>  1: 41357.920 8.2715841        51111.805       10.2223609 12.7779512          1 #>  2:     0.000 0.0000000            0.000        0.0000000 12.7779512          1 #>  3:  3548.786 0.7097572         3604.070        0.7208140  0.9010175          1 #>  4: 54936.565 3.4335353        64946.840        4.0591775  9.0193725          1 #>  5:     0.000 0.0000000            0.000        0.0000000  9.0193725          1 #>  6: 31018.440 8.2715841        38333.854       10.2223609 12.7779512          1 #>  7:     0.000 0.0000000            0.000        0.0000000 12.7779512          1 #>  8:  2135.851 0.5695603         2162.442        0.5766512  0.7208140          1 #>  9: 49296.218 3.5211584        58089.910        4.1492793  9.0193725          1 #> 10:     0.000 0.0000000            0.000        0.0000000  9.0193725          1 #>     sensitivity #>           <int> #>  1:           1 #>  2:           1 #>  3:           1 #>  4:           1 #>  5:           1 #>  6:           1 #>  7:           1 #>  8:           1 #>  9:           1 #> 10:           1 #>  #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"Run simulations parallel mode (simulation level)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"","code":"run_sim_parallel(   arm_list = c(\"int\", \"noint\"),   sensitivity_inputs = NULL,   common_all_inputs = NULL,   common_pt_inputs = NULL,   unique_pt_inputs = NULL,   init_event_list = NULL,   evt_react_list = evt_react_list,   util_ongoing_list = NULL,   util_instant_list = NULL,   util_cycle_list = NULL,   cost_ongoing_list = NULL,   cost_instant_list = NULL,   cost_cycle_list = NULL,   other_ongoing_list = NULL,   other_instant_list = NULL,   npats = 500,   n_sim = 1,   psa_bool = NULL,   sensitivity_bool = FALSE,   sensitivity_names = NULL,   n_sensitivity = 1,   ncores = 1,   input_out = NULL,   ipd = 1,   timed_freq = NULL,   debug = FALSE,   accum_backwards = FALSE,   continue_on_error = FALSE,   seed = NULL )"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"arm_list vector names interventions evaluated simulation sensitivity_inputs list sensitivity inputs change within sensitivity similar fashion common_all_inputs, etc common_all_inputs list inputs common across patients change within simulation common_pt_inputs list inputs change across patients affected intervention unique_pt_inputs list inputs change across intervention init_event_list list initial events event times. initial events given, \"Start\" event time 0 created automatically evt_react_list list event reactions util_ongoing_list Vector QALY named variables accrued ongoing basis (discounted using drq) util_instant_list Vector QALY named variables accrued instantaneously event (discounted using drq) util_cycle_list Vector QALY named variables accrued cycles (discounted using drq) cost_ongoing_list Vector cost named variables accrued ongoing basis (discounted using drc) cost_instant_list Vector cost named variables accrued instantaneously event (discounted using drc) cost_cycle_list Vector cost named variables accrued cycles (discounted using drc) other_ongoing_list Vector named variables accrued ongoing basis (discounted using drq) other_instant_list Vector named variables accrued instantaneously event (discounted using drq) npats number patients simulated (simulate npats * length(arm_list)) n_sim number simulations run per sensitivity psa_bool boolean determine PSA conducted. n_sim > 1 psa_bool = FALSE, differences simulations due sampling sensitivity_bool boolean determine Scenarios/DSA conducted. sensitivity_names vector scenario/DSA names can used select right sensitivity (e.g., c(\"Scenario_1\", \"Scenario_2\")). parameter \"sens_name_used\" created corresponds one used iteration. n_sensitivity Number sensitivity analysis (DSA Scenarios) run. interacted sensitivity_names argument null (n_sensitivityitivity = n_sensitivity * length(sensitivity_names)). DSA, many parameters . scenario, 1. ncores number cores use parallel computing input_out vector variables returned output data frame ipd Integer taking value 0 IPD data returned, 1 full IPD data returned, 2 IPD data aggregating events timed_freq NULL, produce timed outputs. Otherwise number (e.g., every 1 year) debug TRUE, generate log file accum_backwards TRUE, ongoing accumulators count backwards (.e., current value applied previous update). FALSE, current value applied current event next time updated. TRUE, user must use modify_item modify_item_seq results incorrect. continue_on_error TRUE, error  patient stage attempt continue next simulation (works n_sim /n_sensitivity > 1, patient level) seed Starting seed used whole analysis. null, set 1 default.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"list lists analysis results","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"function slightly different run_sim. run_sim allows run single-core. run_sim_parallel allows use multiple-core simulation level, making efficient large number simulations relative run_sim (e.g.,  PSA). Event ties processed order declared within init_event_list argument (evts argument within first sublist object). , program automatically adds sequence 0 (number events - 1) times 1e-10 add event times selecting event minimum time. time selected relatively small yet small ignored .min (see .Machine details) list protected objects used user input names global environment avoid risk overwriting follows: c(\"arm\", \"arm_list\", \"categories_for_export\", \"cur_evtlist\", \"curtime\", \"evt\", \"\", \"prevtime\", \"sens\", \"simulation\", \"sens_name_used\",\"list_env\",\"uc_lists\",\"npats\",\"ipd\"). engine uses L'Ecuyer-CMRG random number generator. Note ncores > 1, results per simulation exactly replicable using run_sim_parallel (seeds automatically transformed seven integer seeds -.e, L'Ecuyer-CMRG seeds-) Note random seeds set unique category (.e., patient level, patient-arm level, etc.) drc drq parameters passed within sensitivity common_all input lists, assigned default value 0.03 discounting costs, QALYs others. Ongoing items look backward last time updated performing discounting accumulation. means user necessarily need keep updating value, add value changes looking forward (e.g., o_q = utility event 1, event 2 utility change, event 3 , want make sure add o_q = utility event 3 updating utility. program automatically look back event 1). Note previous versions package backward default, now switched forward. using accum_backwards = TRUE, mandatory user use modify_item modify_item_seq event reactions, standard assignment approach (e.g., <- 5) calculate right results, particularly presence conditional statements. cycle lists used, expected user declare well name variable pasted cycle_l cycle_starttime (e.g., c_default_cycle_l c_default_cycle_starttime) ensure discounting can computed using cycles, cycle_l cycle length, cycle_starttime starting time variable started counting. Optionally,  max_cycles must also added (maximum number cycles, set equal NA). debug = TRUE export log file timestamp error main working directory. Note using mode without modify_item modify_item_seq may lead inaccuracies assignments done non-standard ways, AST may catch relevant assignments (e.g., assigment like assign(paste(\"x_\",),5) loop identified, unless using modify_item()). continue_on_error set FALSE, export analysis level inputs due parallel engine (use single-engine inputs) continue_on_error skip current simulation (continue rest patient-arms) TRUE. Note make progress bar correct, set patients expected run .","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/run_sim_parallel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run simulations in parallel mode (at the simulation level) — run_sim_parallel","text":"","code":"library(magrittr) common_all_inputs <-add_item( util.sick = 0.8, util.sicker = 0.5, cost.sick = 3000, cost.sicker = 7000, cost.int = 1000, coef_noint = log(0.2), HR_int = 0.8, drc = 0.035, #different values than what's assumed by default drq = 0.035, random_seed_sicker_i = sample.int(100000,5,replace = FALSE) )  common_pt_inputs <- add_item(death= max(0.0000001,rnorm(n=1, mean=12, sd=3)))   unique_pt_inputs <- add_item(fl.sick = 1,                              q_default = util.sick,                              c_default = cost.sick + if(arm==\"int\"){cost.int}else{0})                                init_event_list <-  add_tte(arm=c(\"noint\",\"int\"), evts = c(\"sick\",\"sicker\",\"death\") ,input={   sick <- 0   sicker <- draw_tte(1,dist=\"exp\",    coef1=coef_noint, beta_tx = ifelse(arm==\"int\",HR_int,1),    seed = random_seed_sicker_i[i])    })     evt_react_list <- add_reactevt(name_evt = \"sick\",              input = {}) %>%   add_reactevt(name_evt = \"sicker\",                input = {                  modify_item(list(q_default = util.sicker,                                   c_default = cost.sicker + if(arm==\"int\"){cost.int}else{0},                                   fl.sick = 0))                 }) %>%   add_reactevt(name_evt = \"death\",                input = {                  modify_item(list(q_default = 0,                                   c_default = 0,                                    curtime = Inf))                 })                  util_ongoing <- \"q_default\" cost_ongoing <- \"c_default\"                             run_sim_parallel(arm_list=c(\"int\",\"noint\"), common_all_inputs = common_all_inputs, common_pt_inputs = common_pt_inputs, unique_pt_inputs = unique_pt_inputs, init_event_list = init_event_list, evt_react_list = evt_react_list, util_ongoing_list = util_ongoing, cost_ongoing_list = cost_ongoing, npats = 2, n_sim = 1, psa_bool = FALSE, ipd = 1, ncores = 1) #> Analysis number: 1 #> Loading required package: foreach #> Simulation number: 1 #> Time to run analysis 1: 0.92s #> Total time to run: 0.92s #> [[1]] #> [[1]][[1]] #> [[1]][[1]]$sensitivity_name #> [1] \"\" #>  #> [[1]][[1]]$arm_list #> [1] \"int\"   \"noint\" #>  #> [[1]][[1]]$total_lys #>      int    noint  #> 9.046874 9.046874  #>  #> [[1]][[1]]$total_qalys #>      int    noint  #> 6.207438 6.181151  #>  #> [[1]][[1]]$total_costs #>      int    noint  #> 49921.64 41225.25  #>  #> [[1]][[1]]$total_lys_undisc #>      int    noint  #> 10.89866 10.89866  #>  #> [[1]][[1]]$total_qalys_undisc #>      int    noint  #> 7.501176 7.474146  #>  #> [[1]][[1]]$total_costs_undisc #>      int    noint  #> 59831.36 49293.10  #>  #> [[1]][[1]]$c_default #>      int    noint  #> 49921.64 41225.25  #>  #> [[1]][[1]]$c_default_undisc #>      int    noint  #> 59831.36 49293.10  #>  #> [[1]][[1]]$q_default #>      int    noint  #> 6.207438 6.181151  #>  #> [[1]][[1]]$q_default_undisc #>      int    noint  #> 7.501176 7.474146  #>  #> [[1]][[1]]$merged_df #>     evtname    evttime  prevtime pat_id    arm total_lys total_qalys #>      <char>      <num>     <num>  <int> <char>     <num>       <num> #>  1:    sick  0.0000000 0.0000000      1    int 10.339480    8.271584 #>  2:   death 12.7779512 0.0000000      1    int 10.339480    8.271584 #>  3:    sick  0.0000000 0.0000000      2    int  7.754267    4.143293 #>  4:  sicker  0.9010175 0.0000000      2    int  7.754267    4.143293 #>  5:   death  9.0193725 0.9010175      2    int  7.754267    4.143293 #>  6:    sick  0.0000000 0.0000000      1  noint 10.339480    8.271584 #>  7:   death 12.7779512 0.0000000      1  noint 10.339480    8.271584 #>  8:    sick  0.0000000 0.0000000      2  noint  7.754267    4.090719 #>  9:  sicker  0.7208140 0.0000000      2  noint  7.754267    4.090719 #> 10:   death  9.0193725 0.7208140      2  noint  7.754267    4.090719 #>     total_costs total_costs_undisc total_qalys_undisc total_lys_undisc #>           <num>              <num>              <num>            <num> #>  1:    41357.92           51111.80          10.222361        12.777951 #>  2:    41357.92           51111.80          10.222361        12.777951 #>  3:    58485.35           68550.91           4.779991         9.019372 #>  4:    58485.35           68550.91           4.779991         9.019372 #>  5:    58485.35           68550.91           4.779991         9.019372 #>  6:    31018.44           38333.85          10.222361        12.777951 #>  7:    31018.44           38333.85          10.222361        12.777951 #>  8:    51432.07           60252.35           4.725930         9.019372 #>  9:    51432.07           60252.35           4.725930         9.019372 #> 10:    51432.07           60252.35           4.725930         9.019372 #>            lys     qalys     costs lys_undisc qalys_undisc costs_undisc #>          <num>     <num>     <num>      <num>        <num>        <num> #>  1: 10.3394801 8.2715841 41357.920 12.7779512   10.2223609    51111.805 #>  2:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  3:  0.8871965 0.7097572  3548.786  0.9010175    0.7208140     3604.070 #>  4:  6.8670706 3.4335353 54936.565  8.1183550    4.0591775    64946.840 #>  5:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  6: 10.3394801 8.2715841 31018.440 12.7779512   10.2223609    38333.854 #>  7:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>  8:  0.7119504 0.5695603  2135.851  0.7208140    0.5766512     2162.442 #>  9:  7.0423168 3.5211584 49296.218  8.2985585    4.1492793    58089.910 #> 10:  0.0000000 0.0000000     0.000  0.0000000    0.0000000        0.000 #>     c_default q_default c_default_undisc q_default_undisc   nexttime simulation #>         <num>     <num>            <num>            <num>      <num>      <int> #>  1: 41357.920 8.2715841        51111.805       10.2223609 12.7779512          1 #>  2:     0.000 0.0000000            0.000        0.0000000 12.7779512          1 #>  3:  3548.786 0.7097572         3604.070        0.7208140  0.9010175          1 #>  4: 54936.565 3.4335353        64946.840        4.0591775  9.0193725          1 #>  5:     0.000 0.0000000            0.000        0.0000000  9.0193725          1 #>  6: 31018.440 8.2715841        38333.854       10.2223609 12.7779512          1 #>  7:     0.000 0.0000000            0.000        0.0000000 12.7779512          1 #>  8:  2135.851 0.5695603         2162.442        0.5766512  0.7208140          1 #>  9: 49296.218 3.5211584        58089.910        4.1492793  9.0193725          1 #> 10:     0.000 0.0000000            0.000        0.0000000  9.0193725          1 #>     sensitivity #>           <int> #>  1:           1 #>  2:           1 #>  3:           1 #>  4:           1 #>  5:           1 #>  6:           1 #>  7:           1 #>  8:           1 #>  9:           1 #> 10:           1 #>  #>  #>"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"Create iterator based sens current iteration within scenario (DSA)","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"","code":"sens_iterator(sens, n_sensitivity)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"sens current analysis iterator n_sensitivity total number analyses run","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"Integer iterator based number sensitivity analyses run total iterator","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"situation like DSA, two (low high) scenarios run, sens go 1 n_sensitivity*2. However, ideal parameter selector may depend knowing parameter order (.e., 1, 2, 3...), means resetting counter back 1 sens reaches n_sensitivity (multiple n_sensitivity) needed.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/sens_iterator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an iterator based on sens of the current iteration within a scenario (DSA) — sens_iterator","text":"","code":"sens_iterator(5,20) #> [1] 5 sens_iterator(25,20) #> [1] 5"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_det.html","id":null,"dir":"Reference","previous_headings":"","what":"Deterministic results for a specific treatment — summary_results_det","title":"Deterministic results for a specific treatment — summary_results_det","text":"Deterministic results specific treatment","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_det.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deterministic results for a specific treatment — summary_results_det","text":"","code":"summary_results_det(out = results[[1]][[1]], arm = NULL, wtp = 50000)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_det.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deterministic results for a specific treatment — summary_results_det","text":"final_output data frame list object returned run_sim() arm reference treatment calculation incremental outcomes wtp Willingness pay INMB","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_det.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deterministic results for a specific treatment — summary_results_det","text":"dataframe absolute costs, LYs, QALYs, ICER ICUR intervention","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_det.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deterministic results for a specific treatment — summary_results_det","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))   summary_results_det(res[[1]][[1]],arm=\"int\") #>                        int     noint #> costs             49921.64  41225.25 #> dcosts                0.00   8696.38 #> lys                   9.05      9.05 #> dlys                  0.00      0.00 #> qalys                 6.21      6.18 #> dqalys                0.00      0.03 #> ICER                    NA       Inf #> ICUR                    NA 330825.35 #> INMB                    NA  -7382.03 #> costs_undisc      59831.36  49293.10 #> dcosts_undisc         0.00  10538.25 #> lys_undisc           10.90     10.90 #> dlys_undisc           0.00      0.00 #> qalys_undisc          7.50      7.47 #> dqalys_undisc         0.00      0.03 #> ICER_undisc             NA       Inf #> ICUR_undisc             NA 389864.98 #> INMB_undisc             NA  -9186.73 #> c_default         49921.64  41225.25 #> dc_default            0.00   8696.38 #> c_default_undisc  59831.36  49293.10 #> dc_default_undisc     0.00  10538.25 #> q_default             6.21      6.18 #> dq_default            0.00      0.03 #> q_default_undisc      7.50      7.47 #> dq_default_undisc     0.00      0.03"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sens.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of sensitivity outputs for a treatment — summary_results_sens","title":"Summary of sensitivity outputs for a treatment — summary_results_sens","text":"Summary sensitivity outputs treatment","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of sensitivity outputs for a treatment — summary_results_sens","text":"","code":"summary_results_sens(out = results, arm = NULL, wtp = 50000)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of sensitivity outputs for a treatment — summary_results_sens","text":"list object returned run_sim() arm reference treatment calculation incremental outcomes wtp Willingness pay INMB","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of sensitivity outputs for a treatment — summary_results_sens","text":"data frame sensitivity output per arm","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of sensitivity outputs for a treatment — summary_results_sens","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))   summary_results_sens(res,arm=\"int\") #>        arm analysis analysis_name          variable #>     <char>    <int>        <char>            <fctr> #>  1:    int        1                           costs #>  2:  noint        1                           costs #>  3:    int        1                          dcosts #>  4:  noint        1                          dcosts #>  5:    int        1                             lys #>  6:  noint        1                             lys #>  7:    int        1                            dlys #>  8:  noint        1                            dlys #>  9:    int        1                           qalys #> 10:  noint        1                           qalys #> 11:    int        1                          dqalys #> 12:  noint        1                          dqalys #> 13:    int        1                            ICER #> 14:  noint        1                            ICER #> 15:    int        1                            ICUR #> 16:  noint        1                            ICUR #> 17:    int        1                            INMB #> 18:  noint        1                            INMB #> 19:    int        1                    costs_undisc #> 20:  noint        1                    costs_undisc #> 21:    int        1                   dcosts_undisc #> 22:  noint        1                   dcosts_undisc #> 23:    int        1                      lys_undisc #> 24:  noint        1                      lys_undisc #> 25:    int        1                     dlys_undisc #> 26:  noint        1                     dlys_undisc #> 27:    int        1                    qalys_undisc #> 28:  noint        1                    qalys_undisc #> 29:    int        1                   dqalys_undisc #> 30:  noint        1                   dqalys_undisc #> 31:    int        1                     ICER_undisc #> 32:  noint        1                     ICER_undisc #> 33:    int        1                     ICUR_undisc #> 34:  noint        1                     ICUR_undisc #> 35:    int        1                     INMB_undisc #> 36:  noint        1                     INMB_undisc #> 37:    int        1                       c_default #> 38:  noint        1                       c_default #> 39:    int        1                      dc_default #> 40:  noint        1                      dc_default #> 41:    int        1                c_default_undisc #> 42:  noint        1                c_default_undisc #> 43:    int        1               dc_default_undisc #> 44:  noint        1               dc_default_undisc #> 45:    int        1                       q_default #> 46:  noint        1                       q_default #> 47:    int        1                      dq_default #> 48:  noint        1                      dq_default #> 49:    int        1                q_default_undisc #> 50:  noint        1                q_default_undisc #> 51:    int        1               dq_default_undisc #> 52:  noint        1               dq_default_undisc #>        arm analysis analysis_name          variable #>                                value #>                               <char> #>  1:          49,922 (49,922; 49,922) #>  2:          41,225 (41,225; 41,225) #>  3:                         0 (0; 0) #>  4:             8,696 (8,696; 8,696) #>  5:                9.05 (9.05; 9.05) #>  6:                9.05 (9.05; 9.05) #>  7:                         0 (0; 0) #>  8:                         0 (0; 0) #>  9:                6.21 (6.21; 6.21) #> 10:                6.18 (6.18; 6.18) #> 11:                         0 (0; 0) #> 12:             0.026 (0.026; 0.026) #> 13:                     NaN (NA; NA) #> 14:                   Inf (Inf; Inf) #> 15:                     NaN (NA; NA) #> 16:       330,825 (330,825; 330,825) #> 17:                     NaN (NA; NA) #> 18:          -7,382 (-7,382; -7,382) #> 19:          59,831 (59,831; 59,831) #> 20:          49,293 (49,293; 49,293) #> 21:                         0 (0; 0) #> 22:          10,538 (10,538; 10,538) #> 23:                10.9 (10.9; 10.9) #> 24:                10.9 (10.9; 10.9) #> 25:                         0 (0; 0) #> 26:                         0 (0; 0) #> 27:                   7.5 (7.5; 7.5) #> 28:                7.47 (7.47; 7.47) #> 29:                         0 (0; 0) #> 30:             0.027 (0.027; 0.027) #> 31:                     NaN (NA; NA) #> 32:                   Inf (Inf; Inf) #> 33:                     NaN (NA; NA) #> 34:       389,865 (389,865; 389,865) #> 35:                     NaN (NA; NA) #> 36:          -9,187 (-9,187; -9,187) #> 37: 49,921.64 (49,921.64; 49,921.64) #> 38: 41,225.25 (41,225.25; 41,225.25) #> 39:                         0 (0; 0) #> 40: 8,696.381 (8,696.381; 8,696.381) #> 41: 59,831.36 (59,831.36; 59,831.36) #> 42:    49,293.1 (49,293.1; 49,293.1) #> 43:                         0 (0; 0) #> 44: 10,538.25 (10,538.25; 10,538.25) #> 45:                6.21 (6.21; 6.21) #> 46:                6.18 (6.18; 6.18) #> 47:                         0 (0; 0) #> 48:             0.026 (0.026; 0.026) #> 49:                   7.5 (7.5; 7.5) #> 50:                7.47 (7.47; 7.47) #> 51:                         0 (0; 0) #> 52:             0.027 (0.027; 0.027) #>                                value"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of PSA outputs for a treatment — summary_results_sim","title":"Summary of PSA outputs for a treatment — summary_results_sim","text":"Summary PSA outputs treatment","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of PSA outputs for a treatment — summary_results_sim","text":"","code":"summary_results_sim(out = results[[1]], arm = NULL, wtp = 50000)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of PSA outputs for a treatment — summary_results_sim","text":"output_sim data frame list object returned run_sim() arm reference treatment calculation incremental outcomes wtp Willingness pay INMB","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of PSA outputs for a treatment — summary_results_sim","text":"data frame mean 95% CI absolute costs, LYs, QALYs, ICER ICUR intervention PSA samples","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/summary_results_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of PSA outputs for a treatment — summary_results_sim","text":"","code":"res <- list(list(list(sensitivity_name = \"\", arm_list = c(\"int\", \"noint\" ), total_lys = c(int = 9.04687362556945, noint = 9.04687362556945 ), total_qalys = c(int = 6.20743830697466, noint = 6.18115138126336 ), total_costs = c(int = 49921.6357486899, noint = 41225.2544659378 ), total_lys_undisc = c(int = 10.8986618377039, noint = 10.8986618377039 ), total_qalys_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), total_costs_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), c_default = c(int = 49921.6357486899, noint = 41225.2544659378 ), c_default_undisc = c(int = 59831.3573929783, noint = 49293.1025437205 ), q_default = c(int = 6.20743830697466, noint = 6.18115138126336 ), q_default_undisc = c(int = 7.50117621700097, noint = 7.47414569286751 ), merged_df = list(simulation = 1L, sensitivity = 1L))))   summary_results_sim(res[[1]],arm=\"int\") #>                                                int #> costs                      49,922 (49,922; 49,922) #> dcosts                                    0 (0; 0) #> lys                              9.05 (9.05; 9.05) #> dlys                                      0 (0; 0) #> qalys                            6.21 (6.21; 6.21) #> dqalys                                    0 (0; 0) #> ICER                                  NaN (NA; NA) #> ICUR                                  NaN (NA; NA) #> INMB                                  NaN (NA; NA) #> costs_undisc               59,831 (59,831; 59,831) #> dcosts_undisc                             0 (0; 0) #> lys_undisc                       10.9 (10.9; 10.9) #> dlys_undisc                               0 (0; 0) #> qalys_undisc                        7.5 (7.5; 7.5) #> dqalys_undisc                             0 (0; 0) #> ICER_undisc                           NaN (NA; NA) #> ICUR_undisc                           NaN (NA; NA) #> INMB_undisc                           NaN (NA; NA) #> c_default         49,921.64 (49,921.64; 49,921.64) #> dc_default                                0 (0; 0) #> c_default_undisc  59,831.36 (59,831.36; 59,831.36) #> dc_default_undisc                         0 (0; 0) #> q_default                        6.21 (6.21; 6.21) #> dq_default                                0 (0; 0) #> q_default_undisc                    7.5 (7.5; 7.5) #> dq_default_undisc                         0 (0; 0) #>                                              noint #> costs                      41,225 (41,225; 41,225) #> dcosts                        8,696 (8,696; 8,696) #> lys                              9.05 (9.05; 9.05) #> dlys                                      0 (0; 0) #> qalys                            6.18 (6.18; 6.18) #> dqalys                        0.026 (0.026; 0.026) #> ICER                                Inf (Inf; Inf) #> ICUR                    330,825 (330,825; 330,825) #> INMB                       -7,382 (-7,382; -7,382) #> costs_undisc               49,293 (49,293; 49,293) #> dcosts_undisc              10,538 (10,538; 10,538) #> lys_undisc                       10.9 (10.9; 10.9) #> dlys_undisc                               0 (0; 0) #> qalys_undisc                     7.47 (7.47; 7.47) #> dqalys_undisc                 0.027 (0.027; 0.027) #> ICER_undisc                         Inf (Inf; Inf) #> ICUR_undisc             389,865 (389,865; 389,865) #> INMB_undisc                -9,187 (-9,187; -9,187) #> c_default         41,225.25 (41,225.25; 41,225.25) #> dc_default        8,696.381 (8,696.381; 8,696.381) #> c_default_undisc     49,293.1 (49,293.1; 49,293.1) #> dc_default_undisc 10,538.25 (10,538.25; 10,538.25) #> q_default                        6.18 (6.18; 6.18) #> dq_default                    0.026 (0.026; 0.026) #> q_default_undisc                 7.47 (7.47; 7.47) #> dq_default_undisc             0.027 (0.027; 0.027)"},{"path":"https://jsanchezalv.github.io/WARDEN/reference/tte.df.html","id":null,"dir":"Reference","previous_headings":"","what":"Example TTE IPD data — tte.df","title":"Example TTE IPD data — tte.df","text":"example TTE IPD data example_ipd file","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/tte.df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example TTE IPD data — tte.df","text":"","code":"tte.df"},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/reference/tte.df.html","id":"tte-df","dir":"Reference","previous_headings":"","what":"tte.df","title":"Example TTE IPD data — tte.df","text":"data frame 1000 rows 8 columns: USUBJID Patient ID ARMCD, ARM Arm code variables PARAMCD, PARAM Parameter AVAL, AVALCD Values interest CNSR Censored observation?","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/reference/tte.df.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example TTE IPD data — tte.df","text":"Simulated FlexsurvPlus package using sim_adtte(seed = 821, rho = 0, beta_1a = log(0.6), beta_1b = log(0.6), beta_pd = log(0.2))","code":""},{"path":[]},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-121","dir":"Changelog","previous_headings":"","what":"WARDEN 1.2.1","title":"WARDEN 1.2.1","text":"CRAN release: 2025-06-19 Discounting now correctly allocates drq drc depending output. inputs use drc.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-120","dir":"Changelog","previous_headings":"","what":"WARDEN 1.2.0","title":"WARDEN 1.2.0","text":"CRAN release: 2025-06-11 Speed gains rewritten internal compute_outputs function. Implemented “random_stream” function (using method similar R6) facilitate careful handling random numbers.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-110","dir":"Changelog","previous_headings":"","what":"WARDEN 1.1.0","title":"WARDEN 1.1.0","text":"Added “add_item2”, allows incorporate expressions directly instead list, faster consistent “add_tte” “add_react_evt”. Engine now fully utilizes environment slightly faster analysis loading inputs.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-10","dir":"Changelog","previous_headings":"","what":"WARDEN 1.0","title":"WARDEN 1.0","text":"CRAN release: 2025-05-28 Major update: now engine uses environments instead lists, allows user remove “modify_item” “modify_item_seq” code, improving running speed 20-40% Secondary changes accommodate update applied throughout (extract reactions, debug mode). Debug mode now uses abstract syntax tree capture assignments, can limited presence dynamic code assignments. sens_iterator function added facilitate looping DSA multiple scenarios single model run. See input selectors vignette website example.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-0993","dir":"Changelog","previous_headings":"","what":"WARDEN 0.99.3","title":"WARDEN 0.99.3","text":"CRAN release: 2025-04-04 Minor fix run_sim_parallel ensure compatibility future package (“=T” instead “=TRUE”) Added BugsReport link Description","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-0992","dir":"Changelog","previous_headings":"","what":"WARDEN 0.99.2","title":"WARDEN 0.99.2","text":"Added qgamma_mse function Added two articles website explaining detail WARDEN use sobol sequences","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-0991","dir":"Changelog","previous_headings":"","what":"WARDEN 0.99.1","title":"WARDEN 0.99.1","text":"CRAN release: 2024-12-13 CRAN feedback implemented, including changes documentation: runif_stream function removed due violation CRAN policy global environment modification. suggested user employs different methods (e.g., pre-drawing random numbers) Now user allowed select starting seed analysis","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-099","dir":"Changelog","previous_headings":"","what":"WARDEN 0.99","title":"WARDEN 0.99","text":"Now debug continue_on_error work stages, simulations CRAN preparation changes","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-098","dir":"Changelog","previous_headings":"","what":"WARDEN 0.98","title":"WARDEN 0.98","text":"Repository now public, Github Website set Website references now split topic Added auxiliary functions extract items events reactions easily see interconections models","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-097","dir":"Changelog","previous_headings":"","what":"WARDEN 0.97","title":"WARDEN 0.97","text":"Update based validation comments Gabriel Modified conditional quantile functions weibull llogistic better match default R stats behavior Set License GPL >=3","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-096","dir":"Changelog","previous_headings":"","what":"WARDEN 0.96","title":"WARDEN 0.96","text":"Update based validation comments Gabriel. Renamed conditional quantile functions consistency.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-095","dir":"Changelog","previous_headings":"","what":"WARDEN 0.95","title":"WARDEN 0.95","text":"Seeds used default changed guarantee uniqueness Added possibility continuing next simulation error (occurs patient/arm level, statics/structural loading level) Debug mode now exports log even simulation stops due error. combined continue error, continue export log timestamp","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-094","dir":"Changelog","previous_headings":"","what":"WARDEN 0.94","title":"WARDEN 0.94","text":"Added possibility accumulating outputs continuously backward forward using accum_backward option run_sim run_sim_parallel","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-093","dir":"Changelog","previous_headings":"","what":"WARDEN 0.93","title":"WARDEN 0.93","text":"Conditional quantile functions added adjusted Luck adjustment function added instructions user","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-092","dir":"Changelog","previous_headings":"","what":"WARDEN 0.92","title":"WARDEN 0.92","text":"Progress bar added parallel standard computing model use progress bar batch mode quarto document, make sure add knitr options knitr: opts_chunk: R.options: progressr.enable: true","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-091","dir":"Changelog","previous_headings":"","what":"WARDEN 0.91","title":"WARDEN 0.91","text":"Debug mode exports txt file","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-09","dir":"Changelog","previous_headings":"","what":"WARDEN 0.9","title":"WARDEN 0.9","text":"Warning, commit change previous results. Sensitivity-level simulaton-level seeds moved outside input loading loop caused correlation inputs loaded stages.","code":""},{"path":"https://jsanchezalv.github.io/WARDEN/news/index.html","id":"warden-05","dir":"Changelog","previous_headings":"","what":"WARDEN 0.5","title":"WARDEN 0.5","text":"Initial set-news file Summary inputs overhauled provide INMB WTP argument Summary now can also provided across analyses quickly obtain DSA/scenario analysis results summarized","code":""}]
